---
title: "Track and field"
output: html_document
date: "2025-07-11"
---

```{r setup, include=FALSE}
library(readr)
library(tibble)
library(jsonlite)
library(tidyverse)
library(dplyr)
library(tibble)
library(shiny)
library(refund)
library(face)
library(fields)
library(trelliscope)
library(ggplot2)
library(aws.s3)
library(digest)
library(vetiver)
library(pins)
library(mclust)
bucket <- Sys.getenv("S3_BUCKET")
prefix <- Sys.getenv("S3_PREFIX")
```

```{r}
Olympics_data <- read_csv("../data/track and field data/olympics_data.csv", show_col_types = F) %>%
  janitor::clean_names() %>% 
  separate_wider_delim(date, delim = "–", names = c("start", "end")) %>%
  separate_wider_delim(cols = event, names = c("gender", "event"), delim = " ",
                           too_many = "merge") %>%
  filter(str_detect(event, "Wheelchair", negate = TRUE)) %>% 
  mutate(
        # Manually fixed Aminata CAMARA's age
    birth_date = if_else(name == "Aminata CAMARA", "06 DEC 1973", birth_date),
    gender = if_else(gender == "Men's", "Men", "Women"),
    across(c(birth_date, end),  ~as.Date(format(
    as.Date(., format = "%d %b %Y"), "%Y-%m-%d"))),
    age = year(end) - year(birth_date),
         games = factor(games, ordered = TRUE,
                        levels = c("The XXXII Olympic Games",
                                   "The XXXI Olympic Games",
                                   "The XXX Olympic Games",
                                   "The XXIX Olympic Games",
                                   "The XXVIII Olympic Games",
                                   "The XXVII Olympic Games",
                                   "The XXVI Olympic Games"
                        ),
                        labels = c("Tokyo '20", "Rio '16", "London '12", 
                                   "Beijing '08", "Athens '04", "Sydney '00",
                                   "Atlanta '96")),
    event_type = case_match(
      event,
      c("100 Metres", "200 Metres", "400 Metres", "400 Metres Hurdles", "100 Metres Hurdles", "110 Metres Hurdles") ~ "Sprints",
      c("800 Metres", "1500 Metres", "3000 Metres Steeplechase") ~ "Middle Distance",
      c("5000 Metres", "10,000 Metres") ~ "Long Distance",
      c("Heptathlon", "Decathlon") ~ "Combined Events",
      c("High Jump", "Long Jump", "Triple Jump", "Pole Vault") ~ "Jumps",
      c("Shot Put", "Discus Throw", "Hammer Throw", "Javelin Throw", "Javelin Throw (old)") ~ "Throws",
      c("10 Kilometres Race Walk", "20 Kilometres Race Walk", "50 Kilometres Race Walk", "Marathon") ~ "Road Races",
      .default = "Other"
    ),
         event_category = if_else(str_detect(event, "Metres|Walk|Wheelchair") |event %in% c("Marathon"), "Track", "Field")
         ) %>% 
  mutate(event = if_else(event == "Javelin Throw (old)", "Javelin Throw", event),
         games_year = year(end)) %>% rename("nationality" = nat)

# load career progression data and identify athletes who are still active
Career_progression <- read_csv("../data/track and field data/career_progression (2).csv", show_col_types = F) %>% 
  distinct() |> 
  mutate(date = parse_date_time(date, orders = c("%d %b %Y", "%d-%b-%y"))) %>%
  mutate(retired = if_else(max(year) <= 2022, TRUE, FALSE),
         training_age = year - min(year) + 1,
         .by = c("athlete_link", "event")) 

# find the seasons best performances of each athlete
athlete_bests <-
  Career_progression %>%  inner_join(
    Olympics_data %>%  filter(!is.na(birth_date)) %>%
      distinct(birth_date, athlete_links, event, event_type, .keep_all = T) %>%
      dplyr::select(name, birth_date, athlete_links, event, nationality, event_type, 
             event_category, gender, games_year),
    by = c("athlete_link" = "athlete_links", "event")
  ) %>%  
  dplyr::mutate(age_years = year(date) - year(birth_date), 
         age_days = as.double(
           difftime(
             date, birth_date,units = "days"
           )
         ),
         performance = str_remove_all(performance, "h") # I will count hand timed results as legitimate
         ) %>%
    mutate(mark = if_else(
      event_category == "Track",
      as.numeric(
        difftime(
          lubridate::parse_date_time2(performance, orders = c("%H:%M:%S", "%M:%S:00", "%M:%OS", "%OS"), exact = T),
          lubridate::parse_date_time2("0", orders ="S"),
          units = "secs"
        )
      ), parse_number(performance)),
      # the below accounts for edge cases that lubridate can't parse, like a 62s 400MH
      mark = if_else(is.na(mark), parse_number(performance), mark)
      ) %>%
    mutate(
      best_performance = case_when(
        event_category == "Track" & mark == min(mark, na.rm = T) ~ T, # we want the lowest time
        event_category == "Field" & mark == max(mark, na.rm = T) ~ T, # we want the furthest/highest performance
        .default = F
      ),
      percent_off_peak = if_else(event_category == "Track", abs((mark - min(mark, na.rm = T))/mark), 
                                 abs((mark - max(mark, na.rm = T))/mark)),
      olympic_year = if_else(year %in% c(seq(1980, 2016, 4), 2021), TRUE, FALSE),
      .by = c("athlete_link", "event")
    ) %>% 
   # remove duplicate seasons bests
  dplyr::slice_max(with_ties = FALSE, n = 1, order_by = age_days, by = c("event", "year",  "athlete_link"))


```

```{r}
raw_json <- read_json("../data/track and field data/iaaf-2025.json", simplifyVector = FALSE)

# Convert list of lists to a flat tibble
iaaf_table <- tibble::tibble(
  gender = sapply(raw_json, `[[`, "gender"),
  event = sapply(raw_json, `[[`, "event"),
  mark = sapply(raw_json, `[[`, "mark"),
  points = sapply(raw_json, `[[`, "points")
)
athlete_bests_clean <- athlete_bests |> 
  mutate(
    gender = tolower(gender),
    event = case_when(
      event == "100 Metres" ~ "100m",
      event == "200 Metres" ~ "200m",
      event == "400 Metres" ~ "400m",
      event == "800 Metres" ~ "800m",
      event == "1500 Metres" ~ "1500m",
      event == "5000 Metres" ~ "5000m",
      event == "10,000 Metres" ~ "10000m",
      event == "Marathon" ~ "Road Marathon",
      event == "Triple Jump" ~ "TJ",
      event == "Long Jump" ~ "LJ",
      event == "High Jump" ~ "HJ",
      event == "Shot Put" ~ "SP",
      event == "Discus Throw" ~ "DT",
      event == "Hammer Throw" ~ "HT",
      event == "Javelin Throw" ~ "JT",
      event == "Decathlon" ~ "Dec.",
      event == "Heptathlon" ~ "Hept.",
      event == "Pole Vault" ~ "PV",
      event == "10 Kilometres Race Walk" ~ "10,000mW",
      event == "50 Kilometres Race Walk" ~ "50,000mW",
      event == "20 Kilometres Race Walk" ~ "20,000mW",
      event == "100 Metres Hurdles" ~ "100mH",
      event == "110 Metres Hurdles" ~ "110mH",
      event == "400 Metres Hurdles" ~ "400mH",
      event == "3000 Metres Steeplechase" ~ "3000m SC",
      TRUE ~ event
    )
  )

# join iaaf_table with athlete_bests and get full dataset with result points
round_decimals <- function(x, digits = 2) {
  round(x * 10^digits) / 10^digits}


athlete_bests_points <- 
  athlete_bests_clean |>
    left_join(iaaf_table, join_by(gender, event, closest(mark <= mark))) |> 
  replace_na(list(points = 0))

```

```{r}
# Filter out missing points athletes and rename for clarity
fd_data <- athlete_bests_points |> 
  filter(!is.na(points), !is.na(age_years)) |> 
  mutate(id = paste(athlete_link, event)) |> 
  dplyr::select(athlete_id = id,
         performance_age = age_years,
         iaaf_score = points)
fd_data_shiny <- athlete_bests_points |> 
  filter(!is.na(points), !is.na(age_years))
#ggplot
p <- ggplot(fd_data_shiny, aes(x = age_years)) +
  geom_histogram(bins = 30, fill = "orange", color = "white", alpha = 0.8) +
  labs(
    title = "Distribution of Performance Ages",
    x = "Performance Age (years)",
    y = "Count"
  ) +
  theme_minimal(base_size = 13) +
  theme(legend.position = "none",
        plot.title = element_text(hjust = 0.5))

ggsave("performance_age_histogram.svg", plot = p, width = 8, height = 5, dpi = 300)



#use face to conduct sparse FDA
top_10_ids <- fd_data |>
  count(athlete_id, sort = TRUE) |>
slice_head(n = 10) |>
 pull(athlete_id)

fd_data_top10 <- fd_data |>
  filter(athlete_id %in% top_10_ids)

id <- fd_data_top10$athlete_id
uid <- unique(id)
face_input <- data.frame(
  y = fd_data_top10$iaaf_score,
  argvals = fd_data_top10$performance_age,
  subj = id)

Sample <- which(uid == "https://worldathletics.org/athletes/norway/svein-inge-valvik-014215542 DT")

fit_face <- face.sparse(face_input, argvals.new = seq(11, 58, by = 1))
#create a data double
data.h <- face_input
tnew <- fit_face$argvals.new
#prepare data for prediction
seq <- seq(11, 58, by = 1)
k <- length(seq)
for(i in Sample){
  sel <- which(id == uid[i])
  #dati <- fd_data_top10[sel,] 
  

dati <- fd_data_top10[sel, ] |> 
  dplyr::transmute(y = iaaf_score,
         argvals = performance_age,
         subj = athlete_id)

# Create the prediction dataframe
dati_pred <- data.frame(
  y       = rep(NA, nrow(dati) + k),
  argvals = c(rep(NA, nrow(dati)), seq),
  subj    = rep(dati$subj[1], nrow(dati) + k)
)

dati_pred[1:nrow(dati), ] <- dati

yhat <- predict(fit_face, dati_pred)


Ord  <- (nrow(dati) + 1):(nrow(dati) + k)

#Plot
plot(dati$argvals, dati$y,
     xlab = "Performance Age (years)",
     ylab = "IAAF score",
     pch = 19, col = "blue",
     xlim = range(seq),
     ylim = range(c(dati$y, yhat$y.pred[Ord]), na.rm = TRUE),
     bty = "n")

lines(seq, yhat$y.pred[Ord], col = "red",  lwd = 2)
lines(seq, yhat$y.pred[Ord] + 1.96 * yhat$se.pred[Ord], col = "red", lty = 2)
lines(seq, yhat$y.pred[Ord] - 1.96 * yhat$se.pred[Ord], col = "red", lty = 2)
lines(seq, fit_face$mu.new, col = "black", lwd = 2)

}

#extract mean, covariance, variance, correlation function, and eigenfunctions
#Smooth marginal mean
m <- fit_face$mu.new
#Smooth covariance
Cov <- fit_face$Chat.new
#Pointwise covariance
Cov_diag <- diag(Cov)
#Smooth correlation 
Cor <- fit_face$Cor.new
#Pointwise prediction intervals
m_p_2sd <- m + 2 * sqrt(Cov_diag)
m_m_2sd <- m - 2 * sqrt(Cov_diag)
#Smooth eigenfunctions 
eigenf <- fit_face$eigenfunctions
#Smooth eigenvalues 
eigenv <- fit_face$eigenvalues

#first 3 eigenfunctions
par(mar = c(4.5, 4.5, 0, 2))
col_me <- c("cornflowerblue", "aquamarine3", "coral1")

plot(1, type = "n", xlab = "Performance Age (years)", ylab = "",
     xlim = range(tnew), ylim = range(eigenf), bty = "n")

for(i in 1:3){
  lines(tnew, eigenf[,i], col = col_me[i], lwd = 3)
}

legend("topright", c("PC1", "PC2", "PC3"), 
       col = col_me, lty = 1, bty = "n", lwd = 3)
```


```{r}
#compute world class standard and take mean of men and women
wac_standards <- tribble(
  ~Men, ~Event, ~Women,
  "10.00", "100m", "11.07",
  "20.16", "200m", "22.57",
  "44.85", "400m", "50.75",
  "1:44.50", "800m", "1:59.00",
  "3:33.00", "1500m", "4:01.50",
  "13:01.00", "5000m / 5km road", "14:50.00",
  "27:00.00", "10,000m / 10km road", "30:20.00",
  "2:06:30", "Marathon", "2:23:30",
  "8:15.00", "3000m SC", "9:18.00",
  "13.27", "110mH / 100mH", "12.73",
  "48.50", "400m H", "54.65",
  "2.33", "High Jump", "1.97",
  "5.82", "Pole Vault", "4.73",
  "8.27", "Long Jump", "6.86",
  "17.22", "Triple Jump", "14.55",
  "21.50", "Shot Put", "18.80",
  "67.50", "Discus Throw", "64.50",
  "78.20", "Hammer Throw", "74.00",
  "85.50", "Javelin Throw", "64.00",
  NA, "Heptathlon", "6500", #points 1174
  "8550", "Decathlon", NA, #1212
  "1:19:20", "20km Race Walk", "1:29:00",
  "2:28:00", "35km Race Walk", "2:48:00")

wac_standards <- wac_standards |> 
  mutate(Event = case_match(
    Event,
    "5000m / 5km road"       ~ "5000m",
    "10,000m / 10km road"    ~ "10000m",
    "110mH / 100mH"          ~ "110mH",  
    "400m H"                 ~ "400mH",
    "High Jump"              ~ "HJ",
    "Pole Vault"             ~ "PV",
    "Long Jump"              ~ "LJ",
    "Triple Jump"            ~ "TJ",
    "Shot Put"               ~ "SP",
    "Discus Throw"           ~ "DT",
    "Hammer Throw"           ~ "HT",
    "Javelin Throw"          ~ "JT",
    "20km Race Walk"         ~ "20,000mW",
    "35km Race Walk"         ~ "35,000mW",
    "Marathon"               ~ "Road Marathon",
    "Heptathlon"             ~ "Hept.",
    "Decathlon"              ~ "Dec.",
    .default = Event
  ))

#convert time to seconds
parse_mark_to_seconds <- function(mark_vec) {
  sapply(mark_vec, function(mark) {
    if (is.na(mark)) return(NA_real_)
    parts <- unlist(strsplit(mark, ":"))
    parts <- as.numeric(parts)
    if (length(parts) == 3) {
      # HH:MM:SS
      return(parts[1]*3600 + parts[2]*60 + parts[3])
    } else if (length(parts) == 2) {
      # MM:SS
      return(parts[1]*60 + parts[2])
    } else {
      # Assume plain seconds
      return(as.numeric(mark))
    }
  })
}

wac_long <- wac_standards |> 
  pivot_longer(
    cols = c(Men, Women),
    names_to = "gender",
    values_to = "mark"
  ) |> 
  mutate(mark = parse_mark_to_seconds(mark), 
         gender = tolower(gender), 
         Event = case_when(
           Event == "110mH" & gender == "women" ~ "100mH",
          TRUE ~ Event))


wac_points <- 
  wac_long |>
    left_join(iaaf_table, join_by(gender, Event == event, closest(mark <= mark))) |> 
  replace_na(list(points = 0)) 
wac_points <- wac_points |> 
  mutate(points = case_when(
    Event == "Hept." & gender == "women" ~ 1174,
    Event == "Dec." & gender == "men" ~ 1212,
    TRUE ~ points
  ))
#take mean points by gender
mean_points_by_gender <- wac_points |>
  group_by(gender) |>
  summarise(mean_points = mean(points, na.rm = TRUE)) |> 
  deframe()

```

```{r}
# predict aging curves on full dataset
# Filter out missing points athletes and rename for clarity
fd_data <- athlete_bests_points |> 
  filter(!is.na(points), !is.na(age_years)) |> 
  mutate(id = paste(athlete_link, event)) |> 
  dplyr::select(athlete_id = id,
         performance_age = age_years,
         iaaf_score = points)

id <- fd_data$athlete_id
uid <- unique(id)
face_input <- data.frame(
  y = fd_data$iaaf_score,
  argvals = fd_data$performance_age,
  subj = id)
#Fit sparse FPCA
fit_face <- face.sparse(face_input, argvals.new = seq(11, 58, by = 1))
# saveRDS(fit_face, "fit_face.rds")
# aws.s3::put_object(
#   file   = "fit_face.rds",
#   object = "projects/stat468/models/fit_face.rds",
#   bucket = Sys.getenv("S3_BUCKET")
# )

#create a data double
data.h <- face_input
tnew <- fit_face$argvals.new
#prepare data for prediction
seq <- seq(11, 58, by = 1)
k <- length(seq)
Sample <- c(5, 8, 12, 20)  # Customize based on your data

# Set up 2x2 panel
# par(mfrow = c(2, 2), mar = c(4.5, 4.5, 3, 2))


for(i in 1:4){
  print(uid[Sample[i]])
  sel <- which(id == uid[Sample[i]])
  dati <- fd_data[sel, ] |> 
  mutate(y = iaaf_score,
       argvals = performance_age,
        subj = athlete_id) |> 
  dplyr::select(y,argvals, subj)

if (nrow(dati) == 0) {
  message("Skipping subject ", uid[Sample[i]], " — no data.")
  next}

# Create the prediction dataframe
dati_pred <- data.frame(
  y       = rep(NA, nrow(dati) + k),
  argvals = c(rep(NA, nrow(dati)), seq),
  subj    = rep(dati$subj[1], nrow(dati) + k)
)


dati_pred[1:nrow(dati), ] <- dati

yhat <- predict(fit_face, dati_pred)


Ord  <- (nrow(dati) + 1):(nrow(dati) + k)

#Plot individual aging curves
plot(dati$argvals, dati$y,
     xlab = "Performance Age (years)",
     ylab = "IAAF score",
     pch = 19, col = "blue",
     xlim = range(seq),
     ylim = range(c(dati$y, yhat$y.pred[Ord]), na.rm = TRUE),
     bty = "n")

lines(seq, yhat$y.pred[Ord], col = "red",  lwd = 2)
lines(seq, yhat$y.pred[Ord] + 1.96 * yhat$se.pred[Ord], col = "red", lty = 2)
lines(seq, yhat$y.pred[Ord] - 1.96 * yhat$se.pred[Ord], col = "red", lty = 2)
lines(seq, fit_face$mu.new, col = "black", lwd = 2)

# Add WAC mean horizontal lines for both genders
abline(h = mean_points_by_gender["men"], col = "blue", lty = 3, lwd = 2)
abline(h = mean_points_by_gender["women"], col = "red", lty = 3, lwd = 2)

}

#extract mean, covariance, variance, correlation function, and eigenfunctions
#Smooth marginal mean
m <- fit_face$mu.new
#Smooth covariance
Cov <- fit_face$Chat.new
#Pointwise covariance
Cov_diag <- diag(Cov)
#Smooth correlation 
Cor <- fit_face$Cor.new
#Pointwise prediction intervals
m_p_2sd <- m + 2 * sqrt(Cov_diag)
m_m_2sd <- m - 2 * sqrt(Cov_diag)
#Smooth eigenfunctions 
eigenf <- fit_face$eigenfunctions
#Smooth eigenvalues 
eigenv <- fit_face$eigenvalues

#first 3 eigenfunctions
par(mar = c(4.5, 4.5, 0, 2))
col_me <- c("cornflowerblue", "aquamarine3", "coral1")
#plot PC's
plot(1, type = "n", xlab = "Performance Age (years)", ylab = "",
     xlim = range(tnew), ylim = range(eigenf), bty = "n")

for(i in 1:3){
  lines(tnew, eigenf[,i], col = col_me[i], lwd = 3)
}

legend("topright", c("PC1", "PC2", "PC3"), 
       col = col_me, lty = 1, bty = "n", lwd = 3)

par(mfrow = c(1, 1))
plot(1, type = "n", axes = FALSE, xlab = "", ylab = "")  # empty plot
legend("center", 
       legend = c("Predicted Aging Curve", "95% CI", "Population Mean Aging Curve", 
                  "World Class Standard Mean (Men)", "World Class Standard Mean (Women)"),
       col = c("red", "red", "black", "blue", "red"),
       lty = c(1, 2, 1, 3, 3),
       lwd = 2, bty = "n")
```


```{r}
#imfunPCA
source("lmcensor.r")
source("funs_censor.r")
meanfit_original <- readRDS("mean.rds")
library(fda)
library(dplyr)
library(purrr)
library(tidyr)
# choose a grid 
timegrid <- seq(11, 58, by = 2)

# build a modest B-spline basis
spline_basis <- create.bspline.basis(
  rangeval = c(min(timegrid), max(timegrid)),
  nbasis   = 6,
  norder   = 4
)

# make it visible to functions that expect it globally
assign("spline_basis", spline_basis, inherits = TRUE)


# fd_data: athlete_id, performance_age, iaaf_score
stopifnot(all(c("athlete_id","performance_age","iaaf_score") %in% names(fd_data)))

#Grid and global threshold
timegrid <- seq(11, 58, by = 1)
c_star_global <- quantile(fd_data$iaaf_score, 0.25, na.rm = TRUE)

#Per-athlete collapse
by_ath <- fd_data %>%
  arrange(athlete_id, performance_age) %>%
  group_by(athlete_id) %>%
  summarise(
    t_obs    = list(performance_age),
    y_obs    = list(iaaf_score),
    last_age = max(performance_age, na.rm = TRUE),
    .groups  = "drop"
  )

#Build lists for imFunPCA demo functions
observed   <- vector("list", nrow(by_ath))
timepoints <- vector("list", nrow(by_ath))
delta      <- vector("list", nrow(by_ath))
ath_ids    <- by_ath$athlete_id

for (i in seq_len(nrow(by_ath))) {
  tt <- timegrid
  yy <- rep(NA_real_, length(tt))
  cs <- c_star_global

#place observed points onto grid (average duplicates per age)
  obs_df <- tibble(t = by_ath$t_obs[[i]], y = by_ath$y_obs[[i]]) %>%
    filter(!is.na(t), !is.na(y)) %>%
    group_by(t) %>% summarise(y = mean(y), .groups = "drop")

  idx <- match(obs_df$t, tt, nomatch = NA_integer_)
  if (any(!is.na(idx))) yy[idx[!is.na(idx)]] <- obs_df$y[!is.na(idx)]

#right-tail censor ages strictly greater than last observed age
  is_obs  <- !is.na(yy)
  is_cens <- tt > by_ath$last_age[i]
  yy[is_cens] <- cs

  keep <- is_obs | is_cens
  observed[[i]]   <- yy[keep]
  timepoints[[i]] <- tt[keep]
  delta[[i]]      <- as.integer(is_cens[keep])  # 0 = observed, 1 = censored
}


# make targets for the demo's <<- assignments
sigma <- 1



# Spline basis (keep modest)
spline_basis <- create.bspline.basis(rangeval = c(min(timegrid), max(timegrid)),
                                     nbasis = 6, norder = 4)
assign("spline_basis", spline_basis, inherits = TRUE)  # demo expects this global

# Mean via censored likelihood
meanfit <- findmean(observed = observed, timepoints = timepoints, delta = delta,
                    minit = 6, threshold = 1e-5)
mu_fd <- meanfit$pc_fit

# Center observed series by estimated mean
observedcenter <- lapply(seq_along(observed), function(i) {
  (observed[[i]] - eval.fd(timepoints[[i]], mu_fd))[, 1]
})
# PC1
set.seed(1)
pc1s <- first_FPC(rnorm(spline_basis$nbasis),
                  observed = observedcenter, timepoints = timepoints, delta = delta,
                  threshold = 1e-2, maxit = 30)
pc1_fd <- pc1s$pc_fit
scores_pc1 <- as.numeric(pc1s$sfit)  # α_{i1}


# PC2 conditional on PC1
lmcensor_orig <- lmcensor
lmcensor <- function(y, X, delta, cmat = 0, ...) {
  # If cmat is not a single numeric 0, force unconstrained path
  # (avoids the buggy 'if (cmat != 0)' matrix check inside the original)
  if (is.matrix(cmat) || (length(cmat) != 1)) cmat <- 0
  lmcensor_orig(y, as.matrix(X), delta, cmat, ...)
}
set.seed(2)
pc2s <- third_FPC_conditional(rnorm(spline_basis$nbasis), pc_index = 2,
                              observed = observedcenter, timepoints = timepoints, 
                              delta = delta,betalist = list(pc1s$beta), 
                              threshold = 2e-2, maxit = 30)
pc2_fd <- pc2s$pc_fit
scores_pc2 <- pc2s$sfit[, ncol(pc2s$sfit)]  # α_{i2}

# PC3 conditional on PC1 & PC2
set.seed(3)
pc3s <- third_FPC_conditional(rnorm(spline_basis$nbasis), pc_index = 3,
                              observed = observedcenter, timepoints = timepoints, delta = delta,
                              betalist = list(pc1s$beta, pc2s$beta), threshold = 2e-2, maxit = 30)
pc3_fd <- pc3s$pc_fit
scores_pc3 <- pc3s$sfit[, ncol(pc3s$sfit)]  # α_{i3}
scores_imfun <- cbind(PC1 = scores_pc1, PC2 = scores_pc2, PC3 = scores_pc3)
rownames(scores_imfun) <- ath_ids
pc_scores <- scores_imfun[complete.cases(scores_imfun), , drop = FALSE]  # <- use this downstream


# What do we actually have?
cat("pc1s names:", paste(names(pc1s), collapse=", "), "\n")
cat("pc2s names:", paste(names(pc2s), collapse=", "), "\n")
cat("pc3s names:", paste(names(pc3s), collapse=", "), "\n")

beta1 <- pc1s$beta; beta2 <- pc2s$beta; beta3 <- pc3s$beta
str(beta1); str(beta2); str(beta3)

# Guard: stop early if any beta is missing/non-numeric
stopifnot(is.numeric(beta1), is.numeric(beta2), is.numeric(beta3))



```
```{r}
#number of pcs

#Collect available PC objects from the workspace
pc_names <- paste0("pc", 1:10, "s")             # up to 10; adjust if needed
pc_names <- pc_names[sapply(pc_names, exists)]  # keep only those that exist
stopifnot(length(pc_names) >= 1)

pc_list <- lapply(pc_names, get)

#Extract score vectors robustly
# - For PC1 (first_FPC), sfit is often a vector or 1-col matrix
# - For PC>=2 (third_FPC_conditional), sfit is a matrix; the LAST column are the current PC's scores
extract_scores <- function(pcobj) {
  s <- pcobj$sfit
  if (is.null(dim(s))) {
    as.numeric(s)
  } else {
    as.numeric(s[, ncol(s)])
  }
}

scores_list <- lapply(pc_list, extract_scores)

#Eigenvalues = variance of scores (eigenfunctions are L2-normalized)
eigvals <- sapply(scores_list, function(v) stats::var(v, na.rm = TRUE))
# guard against any non-finite values
keep <- is.finite(eigvals) & eigvals > 0
eigvals <- eigvals[keep]
pc_labels <- paste0("PC", seq_along(eigvals))

#PVE + cumulative PVE
pve <- eigvals / sum(eigvals)
cum_pve <- cumsum(pve)

#Plots
op <- par(mfrow = c(1, 2))
plot(seq_along(eigvals), eigvals, type = "b", pch = 19, xaxt = "n",
     xlab = "Principal Component", ylab = "Eigenvalue (Var of scores)",
     main = "Scree Plot (imFunPCA)")
axis(1, at = seq_along(eigvals), labels = pc_labels)

plot(seq_along(cum_pve), cum_pve, type = "b", pch = 19, xaxt = "n",
     ylim = c(0, 1),
     xlab = "Principal Component", ylab = "Cumulative Variance Explained",
     main = "Cumulative PVE (imFunPCA)")
axis(1, at = seq_along(cum_pve), labels = pc_labels)
abline(h = 0.80, lty = 2, col = "grey40")
abline(h = 0.90, lty = 2, col = "grey40")
par(op)

#Simple suggestion: smallest K hitting 90% cumulative variance
target <- 0.90
k_90 <- which(cum_pve >= target)[1]
message(sprintf("Suggested K at %.0f%% cum. variance: %d (i.e., %s)",
                target*100, k_90, paste0("PC", k_90)))

```







```{r}
# plot of imfun pca
# we assume these exist from your imFunPCA prep:
# observed, timepoints, delta, ath_ids, pc1s, pc2s, pc3s

n <- length(observed)
stopifnot(length(ath_ids) == n)

# helper: count observed points per athlete
n_obs <- vapply(delta, function(d) sum(d == 0L), integer(1))

# PC1: first_FPC usually returns an sfit for everyone you passed in
scores1_full <- rep(NA_real_, n)
scores1_full[] <- as.numeric(pc1s$sfit)  # same order as inputs

# PC2: only athletes with >2 observed points are kept
keep2 <- which(n_obs > 2)
scores2_full <- rep(NA_real_, n)
scores2_full[keep2] <- pc2s$sfit[, ncol(pc2s$sfit)]

# PC3: only athletes with >3 observed points are kept
keep3 <- which(n_obs > 3)
scores3_full <- rep(NA_real_, n)
if (exists("pc3s")) {
  scores3_full[keep3] <- pc3s$sfit[, ncol(pc3s$sfit)]
}

# Assemble matrix; include only PCs you actually have
scores_imfun <- cbind(PC1 = scores1_full,
                      PC2 = scores2_full)
if (exists("pc3s")) scores_imfun <- cbind(scores_imfun, PC3 = scores3_full)

# CRITICAL: set rownames to athlete IDs (exactly once, after expansion)
rownames(scores_imfun) <- ath_ids

#plot of imfun pca 1
# scores_imfun  (rownames = athlete_id, columns PC1..PC3)
# observed, timepoints, delta, ath_ids (from the imFunPCA input builder)
# timegrid <- seq(11, 58, by = 1)

predict_imfun_curve <- function(athlete_id, t = seq(11, 58, 1),
                                PCs = list(pc1_fd, pc2_fd, pc3_fd),
                                scores = scores_imfun,
                                mu = mu_fd) {
  if (!(athlete_id %in% rownames(scores))) {
    stop("athlete_id not found in scores_imfun rownames.")
  }
  # evaluate mean and PCs on t
  mu_t  <- as.numeric(eval.fd(t, mu))
  Psi   <- sapply(PCs, function(fdobj) as.numeric(eval.fd(t, fdobj)))  # |t| x M

  # get athlete scores (vector length M)
  a_i <- as.numeric(scores[athlete_id, seq_len(ncol(Psi)), drop = TRUE])

  # reconstruction
  yhat <- mu_t + as.vector(Psi %*% a_i)

  list(t = t, mu = mu_t, yhat = yhat, scores = a_i, Psi = Psi)
}

##plot a single athlete
library(ggplot2)

plot_imfun_athlete <- function(athlete_id,
                               show_mean = TRUE,
                               show_censored = FALSE,
                               t = seq(11, 58, 1)) {
  pred <- predict_imfun_curve(athlete_id, t = t)

  # pull this athlete's raw points (observed vs censored) if you built those lists
  idx <- match(athlete_id, ath_ids)
  obs_df <- NULL
  if (!is.na(idx)) {
    obs_df <- data.frame(
      t  = timepoints[[idx]],
      y  = observed[[idx]],
      d  = delta[[idx]]  # 0 observed, 1 censored (left-censored at threshold)
    )
  }

  df <- data.frame(t = pred$t, yhat = pred$yhat, mu = pred$mu)

  g <- ggplot(df, aes(t, yhat)) +
    geom_line(size = 1.2) +
    labs(x = "Performance age", y = "IAAF score",
         title = paste("imFunPCA predicted aging curve —", athlete_id)) +
    theme_minimal(base_size = 12) +
    coord_cartesian(ylim = c(0, NA))

  if (show_mean) {
    g <- g + geom_line(aes(y = mu), linetype = 2)
  }
  if (!is.null(obs_df)) {
    # observed points as solid circles; censored (threshold) as triangles
    g <- g +
      geom_point(data = subset(obs_df, d == 0), aes(t, y), inherit.aes = FALSE) 
    
    if (show_censored) {
      g <- g +
      geom_point(data = subset(obs_df, d == 1), aes(t, y),
                 inherit.aes = FALSE, shape = 24)
    }
  }
  g
}

# Example:
plot_imfun_athlete( "https://worldathletics.org/athletes/zimbabwe/julia-sakara-014325374 1500m")
```

```{r}
# plot both imfunpca and sparse.fpca
#Build row-aligned scores_imfun
# Later PCs are fit on fewer athletes; expand back to all athletes and fill NAs
stopifnot(exists("observed"), exists("delta"), exists("ath_ids"))
n <- length(observed)
stopifnot(length(ath_ids) == n)

# how many observed points per athlete
n_obs <- vapply(delta, function(d) sum(d == 0L), integer(1))

# PC1: everyone in training order
scores1_full <- rep(NA_real_, n)
scores1_full[] <- as.numeric(pc1s$sfit)

# PC2: only athletes with >2 observed points
scores2_full <- rep(NA_real_, n)
scores2_full[which(n_obs > 2)] <- pc2s$sfit[, ncol(pc2s$sfit)]

# PC3: >3 observed points
scores3_full <- rep(NA_real_, n)
if (exists("pc3s")) {
  scores3_full[which(n_obs > 3)] <- pc3s$sfit[, ncol(pc3s$sfit)]
}

# Assemble (only PCs that exist)
scores_imfun <- cbind(PC1 = scores1_full, PC2 = scores2_full)
if (exists("pc3s")) scores_imfun <- cbind(scores_imfun, PC3 = scores3_full)

# Set rownames ONCE here
rownames(scores_imfun) <- ath_ids

# pc1_fd <- readRDS("../pc1_fd.rds")
# #print(pc1_fd)
# pc2_fd <- readRDS("../pc2_fd.rds")
# #print(pc2_fd)
# pc3_fd <- readRDS("../pc3_fd.rds")
# #print(pc3_fd)
# scores_imfun <- readRDS("../scores_imfun.rds")
# if (!is.data.frame(scores_imfun)) scores_imfun <- as.data.frame(scores_imfun)
# #print(scores_imfun)
# mu_fd <- readRDS("../mu_fd.rds")

## 1) Helpers

# quick finder for IDs
find_athlete_id <- function(keyword) {
  grep(keyword, rownames(scores_imfun), value = TRUE, ignore.case = TRUE)
}

# auto-collect fd PCs you actually have: pc1_fd, pc2_fd, ...
get_available_pc_fds <- function(max_k = 10) {
  pc_names <- paste0("pc", 1:max_k, "_fd")
  pcs_have <- pc_names[sapply(pc_names, exists)]
  lapply(pcs_have, get)
}

## 2) Predict imFunPCA curve

predict_imfun_curve <- function(athlete_id,
                                t = seq(11, 58, 1),
                                PCs = NULL,
                                scores = scores_imfun,
                                mu = mu_fd) {
  if (is.null(PCs)) PCs <- get_available_pc_fds()
  stopifnot(length(PCs) >= 1)
  stopifnot(athlete_id %in% rownames(scores))

  mu_t <- as.numeric(eval.fd(t, mu))
  Psi  <- sapply(PCs, function(fdobj) as.numeric(eval.fd(t, fdobj)))
  M    <- ncol(Psi)

  sc_cols <- intersect(colnames(scores), paste0("PC", seq_len(M)))
  a_i <- as.numeric(scores[athlete_id, sc_cols, drop = TRUE])
  if (length(a_i) < M) a_i <- c(a_i, rep(0, M - length(a_i)))
  a_i[is.na(a_i)] <- 0

  yhat <- mu_t + as.vector(Psi %*% a_i)
  list(t = t, yhat = yhat, mu = mu_t)
}


## 3) Predict sparse FPCA (face.sparse) curve
predict_face_curve <- function(athlete_id, t = seq(11, 58, 1)) {
  stopifnot(exists("fit_face"), exists("face_input"))
  di <- subset(face_input, subj == athlete_id)
  if (nrow(di) == 0) stop("athlete_id not found in face_input$subj")

  k <- length(t)
  dati_pred <- data.frame(
    y       = c(di$y, rep(NA_real_, k)),
    argvals = c(di$argvals, t),
    subj    = rep(athlete_id, nrow(di) + k)
  )
  ph  <- predict(fit_face, dati_pred)
  ord <- (nrow(di) + 1):(nrow(di) + k)
  list(t = t,
       yhat = as.numeric(ph$y.pred[ord]),
       se   = as.numeric(ph$se.pred[ord]))
}


## 4) Plot: imFunPCA only (safe horizon)

library(ggplot2)

plot_imfun_athlete <- function(athlete_id,
                               t = NULL,
                               buffer_years = 2,
                               show_mean = TRUE) {
  # choose sensible horizon (last observed + buffer)
  idx <- match(athlete_id, ath_ids)
  if (is.null(t) && !is.na(idx)) {
    last_obs <- suppressWarnings(max(timepoints[[idx]][delta[[idx]] == 0], na.rm = TRUE))
    if (is.finite(last_obs)) t <- seq(11, min(58, last_obs + buffer_years), 1)
  }
  if (is.null(t)) t <- seq(11, 58, 1)

  pred <- predict_imfun_curve(athlete_id, t = t)
  df   <- data.frame(t = pred$t, yhat = pred$yhat, mu = pred$mu)

  pts <- if (!is.na(idx)) data.frame(t = timepoints[[idx]],
                                     y = observed[[idx]],
                                     d = delta[[idx]]) else NULL

  g <- ggplot(df, aes(t, yhat)) +
    geom_line(size = 1.2) +
    labs(x = "Performance age", y = "IAAF score",
         title = paste("imFunPCA predicted aging curve —", athlete_id)) +
    theme_minimal(base_size = 12) +
    coord_cartesian(ylim = c(0, NA))
  if (show_mean) g <- g + geom_line(aes(y = mu), linetype = 2)
  if (!is.null(pts)) {
    g <- g +
      geom_point(data = subset(pts, d == 0), aes(t, y), inherit.aes = FALSE) +
      geom_point(data = subset(pts, d == 1), aes(t, y), inherit.aes = FALSE, shape = 24)
  }
  g
}

## 5) Plot: overlay imFunPCA vs sparse FPCA (+ CI)

plot_both_methods <- function(athlete_id,
                              t = NULL,
                              buffer_years = 2,
                              show_mean = TRUE,
                              show_censored = FALSE,
                              show_face_ci = TRUE) {
  # horizon
  idx <- match(athlete_id, ath_ids)
  if (is.null(t) && !is.na(idx)) {
    last_obs <- suppressWarnings(max(timepoints[[idx]][delta[[idx]] == 0], na.rm = TRUE))
    if (is.finite(last_obs)) t <- seq(11, min(58, last_obs + buffer_years), 1)
  }
  if (is.null(t)) t <- seq(11, 58, 1)

  imf <- predict_imfun_curve(athlete_id, t = t)
  fac <- predict_face_curve(athlete_id, t = t)

  df <- data.frame(
    t = t,
    y_imfun = imf$yhat,
    y_face  = fac$yhat,
    mu      = imf$mu,
    face_lo = fac$yhat - 1.96 * fac$se,
    face_hi = fac$yhat + 1.96 * fac$se
  )

  pts <- if (!is.na(idx)) data.frame(t = timepoints[[idx]],
                                     y = observed[[idx]],
                                     d = delta[[idx]]) else NULL

  g <- ggplot(df, aes(t, y_imfun)) +
    geom_line(size = 1.1, "orange") +                                    # imFunPCA (solid)
    geom_line(aes(y = y_face), col = "blue", linetype = 2, linewidth = 1) +  # face.sparse (dashed)
    labs(x = "Performance age (years)", y = "IAAF score",
         title = paste("Aging curve — imFunPCA vs sparse FPCA:", athlete_id),
         subtitle = "Solid = imFunPCA (censor-aware); Dashed = sparse FPCA") +
    theme_minimal(base_size = 12) +
    coord_cartesian(ylim = c(0, NA))

  # if (show_face_ci) {
  #   g <- g + geom_ribbon(aes(x = t, ymin = face_lo, ymax = face_hi),
  #                        alpha = 0.15, inherit.aes = FALSE)
  # }
  # if (show_mean) {
  #   g <- g + geom_line(aes(y = mu), linetype = 3)
  # }
  if (!is.null(pts)) {
    g <- g +
      geom_point(data = subset(pts, d == 0), aes(t, y), inherit.aes = FALSE) 
    
    if (show_censored) {
        g <- g +
        geom_point(data = subset(obs_df, d == 1), aes(t, y),
                   inherit.aes = FALSE, shape = 24)
    }
  }
  g
}


## 6) Scree + cumulative PVE (auto-detect PCs actually have)

scree_imfun <- function(pc_objs = NULL) {
  if (is.null(pc_objs)) {
    pc_names <- paste0("pc", 1:10, "s")
    pc_names <- pc_names[sapply(pc_names, exists)]
    pc_objs  <- lapply(pc_names, get)
  }
  stopifnot(length(pc_objs) >= 1)

  # extract scores robustly: PC1 vector, PC>=2 last column
  extract_scores <- function(pcobj) {
    s <- pcobj$sfit
    if (is.null(dim(s))) as.numeric(s) else as.numeric(s[, ncol(s)])
  }
  scores_list <- lapply(pc_objs, extract_scores)

  eigvals <- sapply(scores_list, function(v) stats::var(v, na.rm = TRUE))
  keep    <- is.finite(eigvals) & eigvals > 0
  eigvals <- eigvals[keep]

  pve <- eigvals / sum(eigvals)
  cum <- cumsum(pve)

  op <- par(mfrow = c(1, 2))
  plot(seq_along(eigvals), eigvals, type = "b", pch = 19,
       xlab = "Principal Component", ylab = "Eigenvalue (Var of scores)",
       main = "Scree Plot (imFunPCA)")
  axis(1, at = seq_along(eigvals), labels = paste0("PC", seq_along(eigvals)))

  plot(seq_along(cum), cum, type = "b", pch = 19, ylim = c(0, 1),
       xlab = "Principal Component", ylab = "Cumulative Variance Explained",
       main = "Cumulative PVE")
  abline(h = 0.80, lty = 2, col = "grey40")
  abline(h = 0.90, lty = 2, col = "grey40")
  axis(1, at = seq_along(cum), labels = paste0("PC", seq_along(cum)))
  par(op)

  k90 <- which(cum >= 0.90)[1]
  msg <- if (length(k90)) sprintf("Suggested K at 90%% cum. variance: %d (PC%d)", k90, k90)
         else "Could not reach 90% with available PCs."
  message(msg)
  invisible(list(eigenvalues = eigvals, pve = pve, cum_pve = cum, k90 = k90))
}
# Find IDs quickly
find_athlete_id("https://worldathletics.org/athletes/zimbabwe/tavanda-chiwira-014256472 400m")

# Plot imFunPCA only
plot_imfun_athlete("https://worldathletics.org/athletes/zimbabwe/tavanda-chiwira-014256472 400m")

# Overlay imFunPCA vs sparse FPCA (with 95% CI ribbon for face.sparse)
plot_both_methods("https://worldathletics.org/athletes/zimbabwe/tavanda-chiwira-014256472 400m",t = seq(11, 58, 1),           # <- force full 11–58
  show_face_ci = TRUE,
  show_mean = TRUE) +
  theme_minimal()

# Scree + cumulative PVE and suggested K
scree_imfun()

plot_both_methods("https://worldathletics.org/athletes/india/sreeshankar-14734673 LJ",t = seq(11, 58, 1),           # <- force full 11–58
  show_face_ci = TRUE,
  show_mean = TRUE) +
  theme_minimal()

```






```{r}
#cluster the whole population based on percent change
# set up
id <- fd_data$athlete_id
uid <- unique(id)
#set the grid where to predict
seq <- seq(11, 58, by = 1)
k <- length(seq)
n <- length(uid)
# Set the predicted percent change in IAAF points matrix: one fewer column since we lose first value
PercentChange_mat <- matrix(NA, nrow = n, ncol = k - 1)

# loop over each athlete, predict every curve
for(i in 1:n){
  sel <- which(id == uid[i])
  dati <- fd_data[sel, ] |>
    mutate(y = iaaf_score,
              argvals = performance_age,
              subj = athlete_id) |> 
    dplyr::select(y, argvals,subj)
 
#if (nrow(dati) == 0) next
  
dati_pred <- data.frame(y = rep(NA, nrow(dati) + k),
                          argvals = c(rep(NA, nrow(dati)), seq),
                          subj = rep(dati$subj[1], nrow(dati) + k)
  )
  
  dati_pred[1:nrow(dati), ] <- dati
  yhat <- predict(fit_face, dati_pred)
#Extract just the predictions on the grid  
  Ord <- (nrow(dati) + 1):(nrow(dati) + k)
  raw <- yhat$y.pred[Ord]

# Check if prediction is valid
if (all(is.na(raw)) || any(raw[-1] == 0, na.rm = TRUE)) next

# Compute percent change: (current - previous)/previous * 100
pc <- c(NA, diff(raw) / head(raw, -1)) * 100

# Save to matrix, dropping the initial NA
PercentChange_mat[i, ] <- pc[-1]
}

# conduct clustering of predicted functions from fpca sparse(k-means clustering)
set.seed(20240805)
cl_kmeans <- kmeans(PercentChange_mat, centers = 7, nstart = 100, iter.max = 1000, algorithm = "Lloyd")
cl_ind <- cl_kmeans$cluster
cl_cen <- cl_kmeans$centers

# plot the predicted aging curves together with the estimated clustering as well as centers of the clusters
par(mar = c(4, 4, 1, 1))
colset <- c("#E69A8DFF", "#F6D55C", "#2A9D8F", "#5F4B8BFF", "orange", "blue", "red","grey")
plot(NULL, xlim = range(seq), ylim = c(-20, 20),
     xlab = "Performance Age (years)", ylab = "Percent Change in IAAF Score", bty = "n")

for(i in 1:n){
  lines(seq[-1], PercentChange_mat[i,], col = colset[cl_ind[i]])
}

for(j in 1:7){
  lines(seq[-1], cl_cen[j,], col = "black", lwd = 3)
}
legend("topright", legend = paste("Cluster", 1:7),
       col = colset, lty = 1, lwd = 2, bty = "n")


```


```{r}
#number of clusters
# 0) Build 3D PC scores from your PercentChange_mat
X <- PercentChange_mat
row_ok  <- rowSums(!is.finite(X)) == 0 # (is.finite covers NA/NaN/Inf)
X <- X[row_ok, , drop = FALSE]
row_var <- apply(X, 1, var)
X <- X[row_var > 0, , drop = FALSE]
stopifnot(nrow(X) > 5)

pcs <- prcomp(X, center = TRUE, scale. = TRUE)
pc_scores <- pcs$x[, 1:3, drop = FALSE]

# 1) Actual SSE over k = 1..Kmax
set.seed(468)
Kmax <- min(15, nrow(pc_scores) - 1)
actual_sse <- sapply(1:Kmax, function(k) {
  kmeans(pc_scores, centers = k, nstart = 25, iter.max = 1000, algorithm = "Lloyd")$tot.withinss
})

# 2) Run 25 permutations (shuffle each PC column)
set.seed(468)  # reproducible permutations
n_perm <- 25
perm_sse_mat <- matrix(NA_real_, nrow = n_perm, ncol = Kmax)
for (i in 1:n_perm) {
  perm_data <- apply(pc_scores, 2, sample)
  perm_sse_mat[i, ] <- sapply(1:Kmax, function(k) {
    kmeans(perm_data, centers = k, nstart = 25, iter.max = 1000, algorithm = "Lloyd")$tot.withinss
  })
}

# 3) Figure 9-style: Actual vs 25 Random Runs (log scale)
matplot(1:Kmax, t(log(perm_sse_mat)), type = "l", lty = 1,
        col = adjustcolor("red", alpha.f = 0.25),
        xlab = "Number of Clusters (k)", ylab = "log(Within-Group SSE)",
        main = "Actual log(SSE) vs 25 Random Runs")
lines(1:Kmax, log(actual_sse), col = "blue", lwd = 2)
legend("topright", c("Actual", "Random runs"),
       col = c("blue", adjustcolor("red", 0.6)), lty = 1, lwd = c(2,1), bty = "n")

# 4) Figure 10-style: gaps vs min/mean of random
diff_min  <- actual_sse - apply(perm_sse_mat, 2, min)
diff_mean <- actual_sse - colMeans(perm_sse_mat)
yl <- range(c(diff_min, diff_mean))

par(mfrow = c(1, 2))
plot(1:Kmax, diff_min,  type = "b", pch = 16, ylim = yl,
     xlab = "k", ylab = "Actual SSE - Min(Random SSE)",
     main = "Gap vs Min of Random", bty = "n"); abline(h = 0, lty = 3)
plot(1:Kmax, diff_mean, type = "b", pch = 16, ylim = yl,
     xlab = "k", ylab = "Actual SSE - Mean(Random SSE)",
     main = "Gap vs Mean of Random", bty = "n"); abline(h = 0, lty = 3)
par(mfrow = c(1, 1))

# Highlight suggested k (max gap)
k_min  <- which.max(diff_min)
k_mean <- which.max(diff_mean)

par(mfrow = c(1, 2))
plot(1:Kmax, diff_min,  type = "b", pch = 16, ylim = yl,
     xlab = "k", ylab = "Actual SSE - Min(Random SSE)",
     main = sprintf("Gap vs Min (best k=%d)", k_min), bty = "n"); abline(h = 0, lty = 3)
points(k_min, diff_min[k_min], pch = 21, bg = "gold", cex = 1.4)

plot(1:Kmax, diff_mean, type = "b", pch = 16, ylim = yl,
     xlab = "k", ylab = "Actual SSE - Mean(Random SSE)",
     main = sprintf("Gap vs Mean (best k=%d)", k_mean), bty = "n"); abline(h = 0, lty = 3)
points(k_mean, diff_mean[k_mean], pch = 21, bg = "gold", cex = 1.4)
par(mfrow = c(1, 1))

```






```{r}
# CLuster by event type based on iaaf-point percent change
#install.packages("svglite")
# Filter and structure the dataset
fd_data_by_event <- athlete_bests_points |> 
  filter(!is.na(points), !is.na(age_years)) |> 
  mutate(
    athlete_id = paste(athlete_link, event),
    performance_age = age_years,
    iaaf_score = points,
    event_type = case_match(
       event,
      c("100m", "200m", "400 Metres", "400m", "400mH", "100mH", "110mH") ~ "Sprints",
      c("800m", "1500m", "3000m SC") ~ "Middle Distance",
      c("5000m", "10000m") ~ "Long Distance",
      c("Hept.", "Dec.") ~ "Combined Events",
      c("HJ", "LJ", "TJ", "PV") ~ "Jumps",
      c("SP", "DT", "HT", "JT") ~ "Throws",
      c("10,000mW", "20,000mW", "50,000mW", "Road Marathon") ~ "Road Races")
  ) |> 
  dplyr::select(athlete_id, performance_age, iaaf_score, event_type)
#choose events
event_types <- unique(fd_data_by_event$event_type)
cluster_results <- list()
for (evtype in event_types) {
  message("Processing: ", evtype)

  fd_sub <- fd_data_by_event |> filter(event_type == evtype)

  id_by_event <- fd_sub$athlete_id
  uid_by_event <- unique(id_by_event)
  seq <- seq(11, 58, by = 1)
  k_by_event <- length(seq)
  n_by_event <- length(uid_by_event)

PercentChange_mat_byevent <- matrix(NA, nrow = n_by_event, ncol = k_by_event - 1)

  for (i in 1:n_by_event) {
    sel_byevent <- which(id_by_event == uid_by_event[i])
    dati <- fd_sub[sel_byevent, ] |>
      transmute(y = iaaf_score, argvals = performance_age, subj = athlete_id)
if (nrow(dati) == 0) next 
    dati_pred <- data.frame(
      y = rep(NA, nrow(dati) + k_by_event),
      argvals = c(rep(NA, nrow(dati)), seq),
      subj = rep(dati$subj[1], nrow(dati) + k_by_event)
    )

    dati_pred[1:nrow(dati), ] <- dati
    yhat <- predict(fit_face, dati_pred)
    Ord <- (nrow(dati) + 1):(nrow(dati) + k_by_event)
    raw <- yhat$y.pred[Ord]

    if (all(is.na(raw)) || any(raw[-1] == 0, na.rm = TRUE)) next

    pc <- c(NA, diff(raw) / head(raw, -1)) * 100
    PercentChange_mat_byevent[i, ] <- pc[-1]
  }

# Remove rows with NA before clustering
  complete_rows <- complete.cases(PercentChange_mat_byevent)
  clean_mat <- PercentChange_mat_byevent[complete_rows, ]

  set.seed(20240805)
  cl_kmeans <- kmeans(clean_mat, centers = 7, nstart = 25)

  cluster_results[[evtype]] <- list(
    clusters = cl_kmeans$cluster,
    centers = cl_kmeans$centers,
    ids = uid_by_event[complete_rows],
    data = clean_mat
  )

#ggplot
  fn <- sprintf("clustering_plot_%s.svg", gsub("\\s+", "_", evtype))
  svglite::svglite(fn, width = 9, height = 6)
  
  colset <- c("#E69A8DFF", "#F6D55C", "#2A9D8F", "#5F4B8BFF",
              "#1f77b4", "#ff7f0e", "red")
  
  colset_trans <- adjustcolor(colset, alpha.f = 0.15)
  
  par(mar = c(4, 4, 1, 1))
  plot(NULL, xlim = range(seq[-1]), ylim = c(-20, 20),
       xlab = "Performance Age (years)", ylab = "Percent Change in World Athletics Score",
       main = paste("Clustered Aging Curves for", evtype), bty = "n")

  for (i in 1:nrow(clean_mat)) {
    lines(seq[-1], clean_mat[i,], col = colset_trans[cl_kmeans$cluster[i]])
  }

  for (j in 1:7) {
    lines(seq[-1], cl_kmeans$centers[j,], col = colset[j], lwd = 3)
  }

  
  legend("topright", legend = paste("Cluster", 1:7),
         col = colset, lty = 1, lwd = 2, bty = "n")
  
  legend("bottomright",
       legend = c("Transparent = individual aging curves", 
                  "Dark = cluster mean curve"),
       bty = "n", cex = 0.8)
  dev.off() 
}
```


```{r}
## plot for poster
library(dplyr)
library(tidyr)
library(ggplot2)
library(rlang)

# --- Prep: classify events & keep only Middle Distance -----------------------
fd_data_by_event <- athlete_bests_points |>
  filter(!is.na(points), !is.na(age_years)) |>
  mutate(
    athlete_id = paste(athlete_link, event),
    performance_age = age_years,
    iaaf_score = points,
    event_type = dplyr::case_match(
      event,
      c("100m","200m","400 Metres","400m","400mH","100mH","110mH") ~ "Sprints",
      c("800m","1500m","3000m SC") ~ "Middle Distance",
      c("5000m","10000m") ~ "Long Distance",
      c("Hept.","Dec.") ~ "Combined Events",
      c("HJ","LJ","TJ","PV") ~ "Jumps",
      c("SP","DT","HT","JT") ~ "Throws",
      c("10,000mW","20,000mW","50,000mW","Road Marathon") ~ "Road Races",
      .default = NA_character_
    )
  ) |>
  dplyr::select(athlete_id, performance_age, iaaf_score, event_type)

fd_sub <- fd_data_by_event |> filter(event_type == "Middle Distance")

# --- Build percent-change matrix on a common age grid ------------------------
seq_age <- seq(11, 58, by = 1)
k_by_event <- length(seq_age)

id_by_event <- fd_sub$athlete_id
uid_by_event <- unique(id_by_event)
n_by_event <- length(uid_by_event)

PercentChange_mat <- matrix(NA_real_, nrow = n_by_event, ncol = k_by_event - 1)

for (i in seq_len(n_by_event)) {
  sel <- which(id_by_event == uid_by_event[i])
  dati <- fd_sub[sel, ] |>
    transmute(y = iaaf_score, argvals = performance_age, subj = athlete_id)

  if (nrow(dati) == 0) next

  # Predict onto regular grid using your fitted FPCA model 'fit_face'
  newdat <- data.frame(
    y = rep(NA_real_, nrow(dati) + k_by_event),
    argvals = c(rep(NA_real_, nrow(dati)), seq_age),
    subj = rep(dati$subj[1], nrow(dati) + k_by_event)
  )
  newdat[seq_len(nrow(dati)), ] <- dati

  yhat <- predict(fit_face, newdat)
  ord <- (nrow(dati) + 1):(nrow(dati) + k_by_event)
  raw <- yhat$y.pred[ord]

  if (all(is.na(raw)) || any(raw[-1] == 0, na.rm = TRUE)) next

  pc <- c(NA, diff(raw) / head(raw, -1)) * 100
  PercentChange_mat[i, ] <- pc[-1]  # drop the first NA to match k_by_event-1
}

# Keep complete rows
complete_rows <- complete.cases(PercentChange_mat)
clean_mat <- PercentChange_mat[complete_rows, , drop = FALSE]
ids_keep <- uid_by_event[complete_rows]

# --- K-means clustering ------------------------------------------------------
set.seed(20240805)
k_clusters <- 7
cl_kmeans <- kmeans(clean_mat, centers = k_clusters, nstart = 25)

# --- Tidy data for ggplot: athletes + mean curves ----------------------------
# Athlete curves (long format)
colnames(clean_mat) <- as.character(seq_age[-1])  # name columns by age
ath_df <- as.data.frame(clean_mat)
ath_df$athlete_id <- ids_keep
ath_df$cluster <- factor(cl_kmeans$cluster, levels = 1:k_clusters)

ath_long <- ath_df |>
  pivot_longer(
    cols = all_of(as.character(seq_age[-1])),
    names_to = "performance_age",
    values_to = "pct_change"
  ) |>
  mutate(
    performance_age = as.numeric(performance_age),
    type = "Athlete"
  )

# Cluster mean curves (centers)
centers_df <- as.data.frame(cl_kmeans$centers)
colnames(centers_df) <- as.character(seq_age[-1])
centers_df$cluster <- factor(seq_len(k_clusters), levels = 1:k_clusters)

mean_long <- centers_df |>
  pivot_longer(
    cols = all_of(as.character(seq_age[-1])),
    names_to = "performance_age",
    values_to = "pct_change"
  ) |>
  mutate(
    performance_age = as.numeric(performance_age),
    type = "Mean"
  )

plot_data <- bind_rows(ath_long, mean_long)

# --- Plot with ggplot2 -------------------------------------------------------
cluster_colors <- c("#E69A8DFF", "#F6D55C", "#2A9D8F", "#5F4B8BFF",
                    "#1f77b4", "#ff7f0e", "#9467bd")

p <- ggplot(plot_data, aes(x = performance_age, y = pct_change,
                           group = interaction(athlete_id, type))) +
  # athlete curves (lighter)
  geom_line(data = subset(plot_data, type == "Athlete"),
            aes(color = cluster, alpha = type, size = type)) +
  # mean curves (bold)
  geom_line(data = subset(plot_data, type == "Mean"),
            aes(color = cluster, alpha = type, size = type)) +
  scale_color_manual(values = cluster_colors, name = "Cluster") +
  scale_alpha_manual(
    name = "Curve Type",
    values = c(Athlete = 0.25, Mean = 1.0)
  ) +
  scale_size_manual(
    name = "Curve Type",
    values = c(Athlete = 0.3, Mean = 1.1)
  ) +
  labs(
    title = "Clustering Aging Curves for Middle Distance",
    x = "Performance Age (years)",
    y = "Percent Change in IAAF Score (%)"
  ) +
  theme_minimal(base_size = 13) +
  theme(
    plot.title = element_text(hjust = 0.5)
  )

# Print or save
print(p)
# ggsave("middle_distance_clusters_percent_change.svg", plot = p, width = 9, height = 6, dpi = 300)

```



```{r}
# Function for predict one athlete for shiny app
predict_sparse<- function(x_id, fit_model) {
  # initial dataframe
  id <- fd_data$athlete_id
  uid <- unique(id)
  
  # ages where we predict the score
  seq <- 11:58
  # preprare data used for prediction
  k <- length(seq)
  data <- data.frame(y=fd_data$iaaf_score, argvals = fd_data$performance_age, subj = fd_data$athlete_id)
  data.h <- data
  sel <- which(id == x_id)
  dati <- data.h[sel,]

  #Create the data frame for prediction
  dati_pred <- data.frame(y = rep(NA, nrow(dati) + k),
                          argvals = c(rep(NA, nrow(dati)), seq),
                          subj = rep(dati$subj[1], nrow(dati) + k ))
  
  #Fill the first part of the data set with the observations for the subject that will be predicted
  dati_pred[1:nrow(dati),] <- dati
  #Produce the predictions for subject i
  yhat2 <- predict(fit_face, dati_pred)
  
  yhat2$y.pred[Ord]
}

x_ids <-c("https://worldathletics.org/athletes/zimbabwe/tavanda-chiwira-014256472 400m",
"https://worldathletics.org/athletes/zimbabwe/sharon-tavengwa-014325382 Road Marathon",
"https://worldathletics.org/athletes/zimbabwe/ngonidzashe-makusha-014256500 LJ",
"https://worldathletics.org/athletes/zimbabwe/julia-sakara-014325374 1500m",
"https://worldathletics.org/athletes/afghanistan/kimia-yousofi-14811449 100m")
for(x_id in x_ids){
  prediction=predict_sparse(x_id, fit_face)
  plot(11:58,prediction, ylim = c(200,1600))
  points(fd_data[which(fd_data$athlete_id == x_id),]$performance_age, fd_data[which(fd_data$athlete_id == x_id),]$iaaf_score, col = "blue", pch = 19)
}


# AWS credentials should be set via environment variables or AWS config
# Do not hardcode credentials in code!
# Sys.setenv(
#   AWS_ACCESS_KEY_ID = "YOUR_ACCESS_KEY_HERE",
#   AWS_SECRET_ACCESS_KEY = "YOUR_SECRET_KEY_HERE",
#   AWS_DEFAULT_REGION = "us-east-1",
#   S3_BUCKET = "stat-468-model",
#   S3_PREFIX = "projects/stat468/data",
#   EC2_PUBLIC_IP = "3.86.47.56"
# )
```




```{r}
# plot for poster
library(ggplot2)
library(dplyr)

if ("theme" %in% ls()) rm(theme)

# Filter only Middle Distance athletes
fd_middle <- fd_data_by_event %>%
  filter(event_type == "Middle Distance")

# chosen 14 athlete IDs
chosen_ids <- c(
  "https://worldathletics.org/athletes/germany/nils-schumann-014194195 800m", "https://worldathletics.org/athletes/great-britain-ni/kelly-holmes-014275347 800m", "https://worldathletics.org/athletes/kenya/david-rudisha-014209691 800m",
  "https://worldathletics.org/athletes/kenya/david-rudisha-014209691 800m", "https://worldathletics.org/athletes/kenya/emmanuel-kipkurui-korir-14755084 800m", "https://worldathletics.org/athletes/kenya/pamela-jelimo-014289015 800m",
  "https://worldathletics.org/athletes/kenya/wilfred-bungei-014207448 800m", "https://worldathletics.org/athletes/mozambique/maria-de-lurdes-mutola-014291362 800m", "https://worldathletics.org/athletes/norway/vebjorn-rodal-014215450 800m",
  "https://worldathletics.org/athletes/russia/svetlana-masterkova-014298569 800m", "https://worldathletics.org/athletes/russia/yuriy-borzakovskiy-014221887 800m", "https://worldathletics.org/athletes/south-africa/caster-semenya-14330057 800m",
  "https://worldathletics.org/athletes/south-africa/caster-semenya-14330057 800m", "https://worldathletics.org/athletes/united-states/athing-mu-14708132 800m")

fd_sample <- fd_middle %>%
  filter(athlete_id %in% chosen_ids)

# Scatter plot (single facet for Middle Distance)
p <- ggplot(fd_sample, aes(x = performance_age, y = iaaf_score, color = athlete_id)) +
  geom_point(alpha = 0.7) +
  labs(x = "Performance Age (years)",
       y = "World Athletics points",
       title = "Observed data points for Middle Distance (800m World Champions)",
subtitle = "Each point is an observed data point; colors distinguish different athletes") +
  theme_minimal(base_size = 13) +
  theme(legend.position = "none") +
  scale_x_continuous(limits = c(11, 36))

ggsave("middle_distance_scatter.svg", plot = p, width = 8, height = 5, dpi = 300)


```
