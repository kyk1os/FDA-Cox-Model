---
title: "Functional Cox Regression for Time-to-Event Prediction: Learning Phase-Specific Effects from Longitudinal Trajectories"
author: "Kyle Ye"
format:
  pdf:
    toc: false
    number-sections: true
    keep-tex: false
  html:
    toc: true
    toc-depth: 3
    code-fold: false
    code-tools: true
    embed-resources: true
execute:
  echo: true
  warning: false
  message: false
---

```{r setup, include=FALSE}
# Create clean output directory structure FIRST
dir.create("output", showWarnings = FALSE)
dir.create("output/images", showWarnings = FALSE, recursive = TRUE)
dir.create("output/tables", showWarnings = FALSE, recursive = TRUE)

# Now set knitr options with the directories already created
knitr::opts_chunk$set(
  echo = TRUE, 
  warning = FALSE, 
  message = FALSE,
  fig.width = 10,
  fig.height = 6,
  fig.path = "output/images/",
  dev = "pdf",  # Always save as PDF (vector graphics) for LaTeX compatibility
  dpi = 300
)

# ============================================================
# HELPER FUNCTIONS (moved here to be available in all chunks)
# ============================================================

# Trapezoid quadrature weights
make_trap_weights <- function(s) {
  n <- length(s)
  if (n < 2) stop("Need at least 2 points for trapezoid weights")
  
  h <- diff(s)
  # FIX: Check for uniform grid (tolerance 1e-10 for floating point)
  if (max(h) - min(h) > 1e-10) {
    stop("Non-uniform grid detected: update trapezoid weights formula")
  }
  
  h <- h[1]  # Use first interval (all equal)
  w <- rep(h, n)
  w[1] <- h/2
  w[n] <- h/2
  w
}

# Robust C-index computation
compute_cindex <- function(risk, time, status) {
  ok <- is.finite(risk) & is.finite(time) & !is.na(status)
  risk <- risk[ok]
  time <- time[ok]
  status <- status[ok]
  
  if (length(risk) < 2L) return(NA_real_)
  if (sum(status == 1L) < 2L) return(NA_real_)
  if (length(unique(time)) < 2L) return(NA_real_)
  
  # CRITICAL: concordance() expects higher values = longer survival
  # But Cox risk scores have higher risk = shorter survival
  # So we negate the risk to get correct C-index
  out <- try(survival::concordance(Surv(time, status) ~ I(-risk)), silent = TRUE)
  if (inherits(out, "try-error")) return(NA_real_)
  out$concordance
}

# Reconstruct subject-level eta from GAM (Convention A)
build_eta_from_gam <- function(gam_fit, long_df, 
                                scalar_terms = c("career_length", "log_n_obs"),
                                weight_col = "w") {
  if (nrow(long_df) == 0) return(numeric(0))
  subjects <- sort(unique(long_df$subject_id))
  
  term_mat <- predict(gam_fit, newdata = long_df, type = "terms")
  const <- attr(term_mat, "constant")
  if (is.null(const)) const <- 0
  term_names <- colnames(term_mat)
  
  scalar_cols <- intersect(scalar_terms, term_names)
  func_cols <- setdiff(term_names, scalar_cols)
  
  if (length(func_cols) > 0 && !(weight_col %in% names(long_df))) {
    stop("Weight column '", weight_col, "' not found in long_df.")
  }
  
  scalar_effect <- if (length(scalar_cols) > 0) {
    rowSums(term_mat[, scalar_cols, drop = FALSE])
  } else {
    rep(0, nrow(term_mat))
  }
  
  func_effect <- if (length(func_cols) > 0) {
    rowSums(term_mat[, func_cols, drop = FALSE]) * long_df[[weight_col]]
  } else {
    rep(0, nrow(term_mat))
  }
  
  scalar_agg <- aggregate(scalar_effect ~ subject_id, data = long_df, FUN = mean)
  func_agg <- aggregate(func_effect ~ subject_id, data = long_df, FUN = sum)
  
  scalar_vec <- setNames(rep(0, length(subjects)), subjects)
  func_vec <- setNames(rep(0, length(subjects)), subjects)
  
  scalar_vec[as.character(scalar_agg$subject_id)] <- scalar_agg$scalar_effect
  func_vec[as.character(func_agg$subject_id)] <- func_agg$func_effect
  
  const + unname(scalar_vec[as.character(subjects)]) + 
    unname(func_vec[as.character(subjects)])
}

# ============================================================
# EXPORT UTILITIES
# Functions to save tables and figures for manuscript
# ============================================================

# Export table as PDF image to output/tables/
export_table <- function(data, name, description = "") {
  tryCatch({
    suppressPackageStartupMessages({
      library(gridExtra)
      library(grid)
    })
    
    # Convert data to nice looking table
    # Round numeric columns to 3 decimal places for cleaner display
    data_display <- data
    numeric_cols <- sapply(data_display, is.numeric)
    data_display[numeric_cols] <- lapply(data_display[numeric_cols], function(x) round(x, 3))
    
    # Create table grob with custom theme
    table_grob <- tableGrob(data_display, rows = NULL,
                            theme = ttheme_default(
                              base_size = 10,
                              core = list(fg_params = list(hjust = 0, x = 0.05),
                                         bg_params = list(fill = c("white", "grey95"))),
                              colhead = list(fg_params = list(fontface = "bold"),
                                           bg_params = list(fill = "steelblue"))
                            ))
    
    # Add title if description provided
    if (description != "") {
      title_grob <- textGrob(description, gp = gpar(fontface = "bold", fontsize = 12))
      table_grob <- arrangeGrob(title_grob, table_grob, nrow = 2, heights = c(0.1, 0.9))
    }
    
    # Calculate appropriate dimensions based on table size
    n_cols <- ncol(data_display)
    n_rows <- nrow(data_display)
    width <- min(14, max(8, n_cols * 1.5))
    height <- min(10, max(4, n_rows * 0.3 + 1))
    
    # Save as PDF only (vector format for papers)
    pdf(paste0("output/tables/", name, ".pdf"), 
        width = width, height = height)
    grid.draw(table_grob)
    dev.off()
    
    cat("✓ Exported table:", name, ".pdf → output/tables/\n")
  }, error = function(e) {
    cat("  Warning: Could not export table:", e$message, "\n")
  })
  
  invisible(data)
}

# Export plot as PDF to output/images/
export_plot <- function(filename, plot = last_plot(), 
                       width = 10, height = 6, dpi = 300) {
  # Save as PDF only (vector graphics for papers)
  ggsave(paste0("output/images/", filename, ".pdf"), 
         plot = plot, width = width, height = height, device = "pdf")
  
  cat("✓ Exported plot:", filename, ".pdf → output/images/\n")
  invisible(plot)
}
```

```{r repro-check, include=FALSE}
# ============================================================
# REPRODUCIBILITY CHECK
# Verify environment is properly set up before rendering
# ============================================================

# Check required packages
required_pkgs <- c(
  "tidyverse", "dplyr", "ggplot2", "tidyr",
  "lubridate", "janitor", "knitr", "digest", "readr",
  "survival", "survminer", "splines", "mgcv",
  "randomForestSRC", "viridis", "gridExtra", "patchwork",
  "RColorBrewer"  # Used indirectly by scale_*_brewer()
)

missing_pkgs <- required_pkgs[!sapply(required_pkgs, function(pkg) {
  requireNamespace(pkg, quietly = TRUE)
})]

if (length(missing_pkgs) > 0) {
  stop("Missing required packages: ", paste(missing_pkgs, collapse = ", "),
       "\nPlease install them before rendering:\n",
       "install.packages(c('", paste(missing_pkgs, collapse = "', '"), "'))")
}

# Check data file exists
if (!file.exists("fda_data.csv")) {
  stop("Required data file 'fda_data.csv' not found in working directory.")
}

cat("✓ All required packages available\n")
cat("✓ Data file exists\n")
cat("✓ Environment check passed\n\n")
```



# Step 1: Data Preparation

```{r packages}
suppressPackageStartupMessages({
  library(tidyverse)
  library(lubridate)
  library(janitor)
  library(knitr)
  library(digest)
})
```

---

```{r load-data}
raw <- readr::read_csv(
  "fda_data.csv",
  col_types = cols(
    results_by_year = col_integer(),
    date = col_character(),
    discipline = col_character(),
    result_score = col_double(),
    mark = col_character(),
    athlete_id = col_character(),
    athlete_link = col_character(),
    race = col_character()  # Add race column for unique identification
  ),
  show_col_types = FALSE
) %>% 
  clean_names() %>%
  
  rename(
    year = results_by_year,
    event = discipline,
    performance = mark
  )

# Basic data summary
cat("\n=== RAW DATA SUMMARY (NEW DATASET) ===\n")
cat("Total observations:", nrow(raw), "\n")
cat("Note: Each row represents a result from a competition (athlete_id, event, race, date)\n")
cat("Date range:", min(raw$year, na.rm = TRUE), "-", max(raw$year, na.rm = TRUE), "\n")
cat("Unique athletes:", n_distinct(raw$athlete_id), "\n")
cat("Unique events:", n_distinct(raw$event), "\n")
cat("Missing values per column:\n")
print(colSums(is.na(raw)))
```

```{r data-quality-checks}
cat("\n=== DATA QUALITY CHECKS ===\n")

# Check for duplicate records
# A row is uniquely identified by (date, event, athlete_id, race)
duplicates <- raw %>% 
  group_by(date, event, athlete_id, race) %>% 
  filter(n() > 1) %>% 
  nrow()
cat("Duplicate records (by date, event, athlete_id, race):", duplicates, "\n")
cat("  Note: This should be ~10k, not 170k (per PhD mentor verification)\n")

# Check year distribution
cat("\nYear distribution (first 10 years):\n")
print(head(table(raw$year), 10))

# Sample of events (disciplines)
cat("\nSample of unique events (first 15):\n")
print(head(sort(unique(raw$event)), 15))

# Check result_score availability
cat("\nResult score summary:\n")
cat("  Non-zero scores:", sum(raw$result_score > 0, na.rm = TRUE), "\n")
cat("  Zero scores (DNF/DNS):", sum(raw$result_score == 0, na.rm = TRUE), "\n")
cat("  Mean result_score:", round(mean(raw$result_score, na.rm = TRUE), 1), "\n")
```

---

# Data Transformation

## Parse Dates and Create Athlete IDs

```{r parse-dates-ids}

# New dataset has date in "DD MMM YYYY" format and athlete_id already provided

df <- raw %>%
  mutate(
    # FIX: Explicitly set locale to avoid parsing failures on non-English systems
    date_parsed = readr::parse_date(date, format = "%d %b %Y", locale = readr::locale("en")),
    athlete_id = as.character(athlete_id),
    event_clean = str_squish(event)
  )
```

## Filter for Official Olympic Events

```{r filter-olympic-events}
# ============================================================
# FILTER: Keep only official Olympic individual events
# Per PhD mentor: "refer to the peaks and primes code to see
# the list of official Olympic events. There should only be like 42."
# Reference: peaks-and-primes.Rmd line 104-113
# ============================================================
# Note: PhD's list has 26 unique event names, but ~42-47 when
# counting Men's and Women's versions separately (gender-specific).
# We filter by event names (not gender-specific in our data structure).
# ============================================================

cat("\n=== FILTERING FOR OFFICIAL OLYMPIC EVENTS ===\n")
cat("Total observations before filter:", nrow(df), "\n")

# Official Olympic individual track & field events
# From peaks-and-primes.Rmd (PhD's official reference code)
olympic_events <- c(
  # Sprints (6 events)
  "100 Metres", "200 Metres", "400 Metres",
  "100 Metres Hurdles",  # Women
  "110 Metres Hurdles",  # Men  
  "400 Metres Hurdles",
  
  # Middle Distance (3 events)
  "800 Metres", "1500 Metres", "3000 Metres Steeplechase",
  
  # Long Distance (2 events)
  "5000 Metres", "10,000 Metres",
  
  # Combined Events (2 events)
  "Heptathlon",   # Women
  "Decathlon",    # Men
  
  # Jumps (4 events)
  "High Jump", "Long Jump", "Triple Jump", "Pole Vault",
  
  # Throws (5 events)
  "Shot Put", "Discus Throw", "Hammer Throw", "Javelin Throw",
  "Javelin Throw (old)",  # Historical
  
  # Road Races (4 events)
  "10 Kilometres Race Walk", 
  "20 Kilometres Race Walk",
  "50 Kilometres Race Walk",  # Men only (historical)
  "Marathon"
)

cat("Official Olympic events (from PhD's peaks-and-primes.Rmd):", length(olympic_events), "\n")

# Apply filter
df_before_filter <- df
df <- df %>% filter(event_clean %in% olympic_events)

cat("\nFilter results:\n")
cat("  Original:", nrow(df_before_filter), "observations\n")
cat("  Retained:", nrow(df), "observations (", 
    round(100 * nrow(df) / nrow(df_before_filter), 1), "%)\n")
cat("  Excluded:", nrow(df_before_filter) - nrow(df), "observations (", 
    round(100 * (nrow(df_before_filter) - nrow(df)) / nrow(df_before_filter), 1), "%)\n")

# Verify exclusions (relays and wheelchairs should be automatically excluded)
relays_remaining <- df %>% 
  filter(str_detect(tolower(event_clean), "relay")) %>% 
  nrow()
wheelchair_remaining <- df %>% 
  filter(str_detect(tolower(event_clean), "wheelchair")) %>% 
  nrow()

cat("\nVerification:\n")
cat("  Relay events:", relays_remaining, 
    ifelse(relays_remaining == 0, "✓ (not in official list)\n", "✗ ERROR!\n"))
cat("  Wheelchair events:", wheelchair_remaining, 
    ifelse(wheelchair_remaining == 0, "✓ (not in official list)\n", "✗ ERROR!\n"))

# Show retained events
cat("\nOlympic events present in dataset:\n")
events_in_data <- df %>% 
  distinct(event_clean) %>% 
  arrange(event_clean) %>%
  pull(event_clean)

cat("  Total:", length(events_in_data), "of", length(olympic_events), "possible\n")
for(ev in events_in_data) {
  cat("    •", ev, "\n")
}

# Check if any official events are missing from data
missing_events <- setdiff(olympic_events, events_in_data)
if(length(missing_events) > 0) {
  cat("\n  Events in official list but NOT in dataset:\n")
  for(ev in missing_events) {
    cat("    ○", ev, "\n")
  }
}
```

## Categorize Events into Families

```{r event-families}
# Function to categorize events into broad families
# NOTE: Per PhD mentor feedback:
#   - Separate jumps from throws (different biomechanics/training)
#   - Combine hurdles with sprints (both are speed-based, short distance)
#   - Relays excluded (already filtered out - focus on individual events only)
to_event_family <- function(ev) {
  ev <- tolower(ev)
  # Remove commas before extracting distance (e.g., "10,000" -> "10000")
  ev_clean <- str_replace_all(ev, ",", "")
  d <- suppressWarnings(as.numeric(stringr::str_extract(ev_clean, "\\d{2,5}")))
  case_when(
    # Combined events
    str_detect(ev, "decathlon|heptathlon|pentathlon") ~ "Combined",
    
    # Field events - SEPARATE jumps from throws (per PhD mentor)
    # Jumps: vertical/horizontal jumps and vaults
    str_detect(ev, "jump|vault") ~ "Jumps",
    
    # Throws: shot put, discus, javelin, hammer, weight
    str_detect(ev, "throw|shot|discus|javelin|hammer") ~ "Throws",
    
    # Road/walking
    str_detect(ev, "walk|marathon|road") ~ "Road",
    
    # Separate steeplechase BEFORE distance check
    str_detect(ev, "steeple") ~ "Long", 
    
    # Hurdles - MERGE with Sprint (per PhD mentor)
    # Rationale: Both are speed-based, short-distance events
    # Even though hurdles require technical skill, they're fundamentally sprints
    str_detect(ev, "hurdle") ~ "Sprint",
    
    # Distance events by meters (after steeplechase check)
    str_detect(ev, "mile") ~ "Middle",
    str_detect(ev, "metre|meter") & !is.na(d) & d >= 3000 ~ "Long",
    str_detect(ev, "metre|meter") & !is.na(d) & d >= 800 ~ "Middle",
    str_detect(ev, "metre|meter") & !is.na(d) & d <= 400 ~ "Sprint",
    
    # NOTE: Relay logic removed - relays filtered out in previous step
    # Keeping only individual Olympic events per PhD mentor
    
    TRUE ~ "Unknown"
  )
}

df <- df %>% mutate(event_family = to_event_family(event_clean))

# Summary of event families
cat("\n=== EVENT FAMILY DISTRIBUTION ===\n")
family_summary <- df %>% 
  count(event_family, sort = TRUE) %>%
  mutate(percent = round(n / sum(n) * 100, 1))
print(family_summary)

# Verify no Unknown events (should be 0 since we only kept Olympian events)
unknown_count <- sum(df$event_family == "Unknown", na.rm = TRUE)
if (unknown_count > 0) {
  cat("\nWARNING:", unknown_count, "observations with Unknown event_family\n")
  cat("This shouldn't happen - check event classification logic!\n")
  unknown_events <- df %>% 
    filter(event_family == "Unknown") %>%
    distinct(event_clean)
  print(unknown_events)
}

cat("\nTotal Olympian-Individual-Event observations classified:", sum(family_summary$n), "\n")
```

## Parse and Unify Performance Metrics

```{r parse-performance}
# Filter out invalid scores (0 = DNF/DNS)
df <- df %>%
  mutate(
    # Use result_score directly (already standardized, higher = better)
    score_unified = result_score,
    # Keep raw performance mark for reference
    raw_value = result_score,
    unit = "result_score"
  ) %>%
  filter(!is.na(result_score), result_score > 0)

cat("\n=== EVENT-LEVEL DATA (After Filtering) ===\n")
cat("Total event-level observations:", nrow(df), "\n")

# --- MAIN ANALYSIS CHOICE ---
# Construct YEARLY season-best observations (one row per athlete-event-year).
# This matches the paper definition of Y_ij = annual season-best and yields
# a yearly longitudinal series suitable for fitting X_i(s).
df_events <- df

df_yearly <- df_events %>%
  group_by(athlete_id, event_clean, event_family, year) %>%
  # FIX: First count events in the year, then select season-best
  mutate(n_events_year = n()) %>%
  slice_max(order_by = score_unified, n = 1, with_ties = FALSE) %>%
  transmute(
    athlete_id, event_clean, event_family, year,
    score_unified = score_unified,
    result_score = score_unified,
    performance, date_parsed, n_events_year
  ) %>%
  ungroup()

# From here onward, `df` refers to YEARLY season-best observations (main analysis).
df <- df_yearly

# ============================================================
# SANITY CHECKS: Verify yearly season-best data integrity
# ============================================================

# Check 1: Uniqueness - one row per (athlete_id, event_clean, year)
n_unique_keys <- nrow(unique(df[c("athlete_id", "event_clean", "year")]))
stopifnot(
  "df_yearly has duplicate (athlete_id, event_clean, year) combinations!" = 
    nrow(df) == n_unique_keys
)

# Check 2: Years are integers and non-missing
stopifnot(

  "Some years are missing!" = !any(is.na(df$year)),
  "Years should be integers!" = all(df$year == as.integer(df$year))
)

cat("\n=== YEARLY SEASON-BEST DATA (Main Analysis) ===\n")
cat("=" %>% rep(70) %>% paste(collapse = ""), "\n")
cat("REPRODUCIBILITY NOTE (for manuscript):\n")
cat("  Total yearly observations:", nrow(df), "\n")
cat("  This is the exact count reported in the paper (347,625)\n")
cat("=" %>% rep(70) %>% paste(collapse = ""), "\n")
cat("Raw event-level rows:", nrow(df_events), "\n")
cat("Compression ratio:", round(nrow(df_events) / nrow(df), 2), ":1\n")

# Summary statistics
yearly_stats <- df %>%
  group_by(athlete_id, event_clean) %>%
  summarise(n_years = n(), .groups = "drop")

cat("\nYears observed per athlete-event:\n")
cat("  Mean:", round(mean(yearly_stats$n_years), 2), "\n")
cat("  Median:", median(yearly_stats$n_years), "\n")
cat("  Min:", min(yearly_stats$n_years), "| Max:", max(yearly_stats$n_years), "\n")

cat("\nMean events per athlete-year (n_events_year):\n")
cat("  Mean:", round(mean(df$n_events_year, na.rm = TRUE), 2), "\n")
cat("  Median:", median(df$n_events_year, na.rm = TRUE), "\n")

cat("\n=== SAMPLE YEARLY SEASON-BEST SCORES ===\n")
sample_parsed <- df %>%
  group_by(event_family) %>%
  slice_sample(n = 2) %>%
  select(event_family, event_clean, year, performance, result_score, score_unified, n_events_year) %>%
  ungroup()
print(sample_parsed)

cat("\nResult score distribution:\n")
cat("  Min:", min(df$score_unified, na.rm = TRUE), "\n")
cat("  Median:", median(df$score_unified, na.rm = TRUE), "\n")
cat("  Mean:", round(mean(df$score_unified, na.rm = TRUE), 1), "\n")
cat("  Max:", max(df$score_unified, na.rm = TRUE), "\n")
```

---

# Career Metrics Calculation

**Main analysis choice (to match the paper):** Although the raw dataset is event-level and dense, we **collapse to yearly season-best** (one value per athlete–event–year). This yields trajectories \(Y_{ij}\) that represent annual “best-of-season” performance and avoids overweighting athletes who compete more frequently within a year.

## Calculate Career Age and Peak Year

```{r career-metrics}
# Calculate career progression metrics
career <- df %>%
  arrange(athlete_id, event_clean, year, date_parsed) %>%
  group_by(athlete_id, event_clean, event_family) %>%
  mutate(
    first_year = min(year, na.rm = TRUE),
    last_year = max(year, na.rm = TRUE),
    career_length = last_year - first_year,
    career_age = year - first_year,
    # Number of YEARLY observations (years observed) for this athlete-event
    n_observations = n(),
    # Peak is first occurrence of career-best performance
    career_max = max(score_unified, na.rm = TRUE),
    is_peak_row = score_unified == career_max,
    peak_year = suppressWarnings(min(year[is_peak_row], na.rm = TRUE))
  ) %>% 
  ungroup()

# Summary statistics
cat("\n=== CAREER METRICS SUMMARY ===\n")
career_summary <- career %>%
  group_by(athlete_id, event_clean) %>%
  summarise(
    career_length = first(career_length),
    n_observations = first(n_observations),
    time_to_peak = first(peak_year) - first(first_year),
    .groups = "drop"
  )

cat("Career length (years):\n")
print(summary(career_summary$career_length))

cat("\nYearly observations per athlete-event:\n")
print(summary(career_summary$n_observations))

cat("\nTime to peak (years):\n")
print(summary(career_summary$time_to_peak))
```

## Visualize Career Metrics

```{r visualize-careers, fig.height=8}
# Distribution of career lengths
p1 <- ggplot(career_summary, aes(x = career_length)) +
  geom_histogram(binwidth = 1, fill = "steelblue", alpha = 0.7) +
  labs(
    title = "Distribution of Career Lengths",
    x = "Career Length (years)",
    y = "Count"
  ) +
  theme_minimal()

# Distribution of time to peak
p2 <- ggplot(career_summary, aes(x = time_to_peak)) +
  geom_histogram(binwidth = 1, fill = "coral", alpha = 0.7) +
  labs(
    title = "Distribution of Time to Peak Performance",
    x = "Years to Peak",
    y = "Count"
  ) +
  theme_minimal()

# Distribution by event family
p3 <- career %>%
  group_by(athlete_id, event_family) %>%
  summarise(time_to_peak = first(peak_year) - first(first_year), .groups = "drop") %>%
  ggplot(aes(x = event_family, y = time_to_peak, fill = event_family)) +
  geom_boxplot(alpha = 0.7) +
  labs(
    title = "Time to Peak by Event Family",
    x = "Event Family",
    y = "Years to Peak"
  ) +
  theme_minimal() +
  theme(legend.position = "none", axis.text.x = element_text(angle = 45, hjust = 1))

# Combine plots
library(gridExtra)
grid.arrange(p1, p2, p3, nrow = 3)
```

---

# Prepare Analysis-Ready Datasets

## Survival Analysis Dataset

```{r survival-dataset}
# Create survival analysis input (one row per athlete-event)
# CENSORING LOGIC (fixed cutoff per PhD coworker definition):
# - Retired athletes: haven't competed since 2023 (last_year < 2023)
# - Active athletes: competed in 2023 or later (last_year >= 2023)
# - Athletes still competing at/after cutoff = CENSORED (still active)
# - Athletes who stopped before cutoff = UNCENSORED (retired, peak known)

# Fixed censoring cutoff (per coworker requirement)
# Note: Data contains years up to 2025, but we use 2023 as the active/retired threshold
cutoff_year <- 2023

surv_ready_temp <- career %>%
  group_by(athlete_id, event_clean, event_family) %>%
  summarise(
    first_year = first(first_year),
    last_year = first(last_year),
    peak_year = first(peak_year),
    .groups = "drop"
  ) %>%
  mutate(
    # CENSORING: Athletes competing at/after cutoff are censored (still active)
    # Athletes whose last competition was before cutoff are uncensored (retired)
    event_status = if_else(last_year >= cutoff_year, 0, 1),
    # For censored athletes, use last_year as time; for uncensored, use peak_year
    time_to_peak = if_else(event_status == 0, 
                           last_year - first_year,  # Censored at last observation
                           peak_year - first_year)  # Event at peak (known)
  )

# Count before filtering
n_before_filter <- nrow(surv_ready_temp)

# Apply final filter: remove pathological cases where time_to_peak < 0
surv_ready <- surv_ready_temp %>% filter(time_to_peak >= 0)

# Count after filtering
n_after_filter <- nrow(surv_ready)
n_excluded <- n_before_filter - n_after_filter

cat("\n=== CENSORING SETUP (per PhD coworker definition) ===\n")
cat("Data range: 2007 -", max(career$year, na.rm = TRUE), "\n")
cat("Censoring cutoff (fixed):", cutoff_year, "\n")
cat("  Athletes competing in", cutoff_year, "+ (2023/2024/2025) = CENSORED (still active)\n")
cat("  Athletes last seen before", cutoff_year, "(≤2022) = UNCENSORED (retired)\n\n")

cat("=" %>% rep(70) %>% paste(collapse = ""), "\n")
cat("DATA QUALITY FILTERING:\n")
cat("  Before filtering (all athlete-event pairs):", n_before_filter, "\n")
cat("  Excluded (time_to_peak < 0, pathological cases):", n_excluded, "\n")
cat("  After filtering (final dataset):", n_after_filter, "\n")
cat("=" %>% rep(70) %>% paste(collapse = ""), "\n\n")

cat("=" %>% rep(70) %>% paste(collapse = ""), "\n")
cat("REPRODUCIBILITY NOTE (for manuscript):\n")
cat("  N_AE (unique athlete-event combinations):", nrow(surv_ready), "\n")
cat("  This is the FINAL count after all data quality filters\n")
cat("  This should match the number reported in the paper (67,977)\n")
cat("  Definition: unique (athlete_id, event_clean) pairs with valid\n")
cat("              career trajectories (time_to_peak >= 0)\n")
cat("=" %>% rep(70) %>% paste(collapse = ""), "\n\n")
cat("UNCENSORED (retired, peak known):", sum(surv_ready$event_status == 1), 
    sprintf("(%.1f%%)", 100 * mean(surv_ready$event_status == 1)), "\n")
cat("CENSORED (still active):", sum(surv_ready$event_status == 0),
    sprintf("(%.1f%%)", 100 * mean(surv_ready$event_status == 0)), "\n")
cat("Events with time_to_peak = 0 (peak in first year):", 
    sum(surv_ready$time_to_peak == 0), "\n\n")

# Detailed censoring breakdown by last competition year
cat("=== CENSORING BREAKDOWN BY LAST YEAR ===\n")
censoring_by_year <- surv_ready %>%
  group_by(last_year, event_status) %>%
  summarise(n = n(), .groups = "drop") %>%
  arrange(desc(last_year))
cat("Last 5 years:\n")
print(censoring_by_year %>% filter(last_year >= 2021) %>% arrange(desc(last_year)))

cat("\nVerification:\n")
cat("  ✓ All athletes with last_year >= 2023 should be censored (event_status=0)\n")
cat("  ✓ All athletes with last_year < 2023 should be uncensored (event_status=1)\n")
verify_2023_plus <- surv_ready %>% filter(last_year >= 2023)
verify_2022_minus <- surv_ready %>% filter(last_year < 2023)
cat("  Athletes 2023+: all censored?", all(verify_2023_plus$event_status == 0), 
    sprintf("(%d athletes)\n", nrow(verify_2023_plus)))
cat("  Athletes ≤2022: all uncensored?", all(verify_2022_minus$event_status == 1), 
    sprintf("(%d athletes)\n", nrow(verify_2022_minus)))
```

## FDA Longitudinal Dataset

```{r fda-dataset}
# Create FDA-ready longitudinal dataset
# Standardize within athlete-event to preserve curve shape
df_long <- df %>%
  # Normalize career timeline first
  group_by(athlete_id, event_clean) %>%
  mutate(
    first_year = min(year), 
    last_year = max(year),
    # Career phase: 0 = career start, 1 = career end
    career_phase = (year - first_year) / pmax(last_year - first_year, 1)
  ) %>%
  # Standardize within each athlete-event (NOT across all events!)
  # This preserves: curve shape, convexity, fluctuations, trajectory patterns
  mutate(
    m = mean(score_unified, na.rm = TRUE),
    s = sd(score_unified, na.rm = TRUE),
    # Handle single-observation careers (sd=0 or NA)
    s = ifelse(is.na(s) | s == 0, 1, s),
    score_raw_centered = score_unified - m,
    score_std = score_raw_centered / s
  ) %>%
  select(-m, -s) %>%  # Remove temporary variables
  ungroup()

# Sanity check: career_phase should be in [0, 1]
stopifnot(
  "career_phase has values < 0!" = all(df_long$career_phase >= -1e-9),
  "career_phase has values > 1!" = all(df_long$career_phase <= 1 + 1e-9)
)

cat("Total observations:", nrow(df_long), "\n")
cat("Career phase range:", range(df_long$career_phase), "\n")
cat("Standardization: Within athlete-event (preserves curve shape)\n")
```

---

# Sample Size Analysis

```{r sample-sizes}
cat("\n=== SAMPLE SIZE ANALYSIS ===\n")

# By event family
family_counts <- surv_ready %>% 
  count(event_family, name = "n_individuals") %>% 
  arrange(desc(n_individuals)) %>%
  mutate(percent = round(n_individuals / sum(n_individuals) * 100, 1))

cat("\nIndividuals by Event Family:\n")
print(family_counts)

# By specific event (top 25)
event_counts <- surv_ready %>% 
  count(event_clean, event_family, name = "n_individuals") %>% 
  arrange(desc(n_individuals)) %>%
  head(25)

cat("\nTop 25 Events by Number of Individuals:\n")
print(event_counts)

# Check for events with too few observations
min_threshold <- 30
small_events <- surv_ready %>%
  count(event_clean) %>%
  filter(n < min_threshold)

if (nrow(small_events) > 0) {
  cat("\n", nrow(small_events), 
      "events have fewer than", min_threshold, "individuals\n")
  cat("Consider filtering or grouping these events.\n")
}
```

```{r sample-size-viz}
# Visualize sample sizes
ggplot(family_counts, aes(x = reorder(event_family, n_individuals), 
                          y = n_individuals, fill = event_family)) +
  geom_col(alpha = 0.7) +
  geom_text(aes(label = n_individuals), hjust = -0.2) +
  coord_flip() +
  labs(
    title = "Number of Athletes by Event Family",
    x = "Event Family",
    y = "Number of Athlete-Event Combinations"
  ) +
  theme_minimal() +
  theme(legend.position = "none")
```

---

# Data Splitting by Event Family

```{r split-data}
# Split datasets by event family for family-specific modeling
# This is not actually splitting the data but organizing it

cat("\n=== ORGANIZING DATA BY EVENT FAMILY ===\n")

# Get unique event families (excluding Unknown if present)
event_families <- surv_ready %>%
  filter(event_family != "Unknown") %>%
  pull(event_family) %>%
  unique()

cat("Event families for modeling:", paste(event_families, collapse = ", "), "\n")

# Note: We keep surv_ready and df_long as unified datasets
# Splitting by family can be done in the modeling phase
# This provides more flexibility
```

---

## Summary

```{r summary}
cat("\n========================================\n")
cat("   DATA PROCESSING SUMMARY              \n")
cat("========================================\n\n")

cat("Input Data:\n")
cat("  - Raw observations:", nrow(raw), "\n")
cat("  - Unique athletes:", n_distinct(raw$athlete_id), "\n")
cat("  - Date range:", min(raw$year, na.rm = TRUE), "-", max(raw$year, na.rm = TRUE), "\n\n")

cat("Processed Data:\n")
cat("  - Valid observations:", nrow(df_long), "\n")
cat("  - Athlete-event combinations:", nrow(surv_ready), "\n")
cat("  - Event families:", n_distinct(surv_ready$event_family), "\n")
cat("  - Specific events:", n_distinct(surv_ready$event_clean), "\n\n")

cat("Key Metrics:\n")
cat("  - Avg career length:", round(mean(career_summary$career_length), 1), "years\n")
cat("  - Avg time to peak:", round(mean(career_summary$time_to_peak), 1), "years\n")
cat("  - Avg observations per athlete-event:", 
    round(mean(career_summary$n_observations), 1), "\n\n")
```

\newpage

# Step 2: Exploratory Analysis

This section performs exploratory survival analysis and visualization of functional predictors to understand the timing of peak performance across different athletic events.

## Kaplan-Meier Analysis for Time-to-Peak

### Overall Cohort Description

```{r km-setup}
# Check for required packages (do not install - environment must be prepared)
required_packages <- c("survival", "survminer")
for(pkg in required_packages) {
  if(!requireNamespace(pkg, quietly = TRUE)) {
    stop("Package '", pkg, "' is required but not installed. Please install it before rendering.")
  }
}

suppressPackageStartupMessages({
  library(survival)
  library(survminer)
})

cat("\n=== COHORT DESCRIPTION ===\n")
cat("Total athlete-event combinations:", nrow(surv_ready), "\n")
cat("Number of unique athletes:", n_distinct(surv_ready$athlete_id), "\n")
cat("Number of events:", n_distinct(surv_ready$event_clean), "\n")
cat("Number of event families:", n_distinct(surv_ready$event_family), "\n\n")

# Censoring information
cat("Censoring Status:\n")
cat("  - Events observed (peak reached):", sum(surv_ready$event_status == 1), "\n")
cat("  - Censored cases:", sum(surv_ready$event_status == 0), "\n")
cat("  - Censoring rate:", round(mean(surv_ready$event_status == 0) * 100, 1), "%\n\n")

# Time-to-peak distribution
cat("Time-to-Peak Summary:\n")
print(summary(surv_ready$time_to_peak))
```

### Kaplan-Meier Curves: Overall and by Event Family

```{r km-overall, fig.height=6}
# Fit Kaplan-Meier for overall cohort
km_fit_overall <- survfit(Surv(time_to_peak, event_status) ~ 1, data = surv_ready)

# Summary statistics
km_summary <- summary(km_fit_overall)
median_peak <- summary(km_fit_overall)$table["median"]
ci_lower <- summary(km_fit_overall)$table["0.95LCL"]
ci_upper <- summary(km_fit_overall)$table["0.95UCL"]

cat("\n=== KAPLAN-MEIER RESULTS (Overall) ===\n")
cat("Median time to peak:", median_peak, "years\n")
cat("95% CI: [", ci_lower, ",", ci_upper, "]\n\n")


# Plot overall K-M curve
ggsurvplot(
  km_fit_overall,
  data = surv_ready,
  conf.int = TRUE,
  risk.table = TRUE,
  risk.table.height = 0.25,
  title = "Kaplan-Meier Curve: Time to Peak Performance (Overall)",
  xlab = "Years Since Career Start",
  ylab = "Probability of Peaking After",
  legend = "none",
  ggtheme = theme_minimal()
)
```

```{r km-by-family, fig.height=8}
# Fit K-M by event family
km_fit_family <- survfit(Surv(time_to_peak, event_status) ~ event_family, 
                          data = surv_ready)

# Summary by family
cat("\n=== MEDIAN TIME TO PEAK BY EVENT FAMILY ===\n")
km_table <- summary(km_fit_family)$table
print(km_table[, c("median", "0.95LCL", "0.95UCL")])

# Plot K-M curves by family
ggsurvplot(
  km_fit_family,
  data = surv_ready,
  conf.int = TRUE,
  pval = TRUE,
  risk.table = TRUE,
  risk.table.height = 0.3,
  title = "Time to Peak Performance by Event Family",
  xlab = "Years Since Career Start",
  ylab = "Probability of Peaking After",
  legend.title = "Event Family",
  legend.labs = levels(factor(surv_ready$event_family)),
  ggtheme = theme_minimal(),
  palette = "Set2"
)

# Log-rank test for differences between families
log_rank_test <- survdiff(Surv(time_to_peak, event_status) ~ event_family, 
                           data = surv_ready)
cat("\nLog-rank test for differences between event families:\n")
print(log_rank_test)
```

## Functional Predictors: Career Progression Curves

### Mean Curves by Event Family

```{r mean-curves, fig.height=8}
# Calculate mean curves and variability by event family
# FIX: Bin career_phase to avoid jagged lines (raw career_phase has many unique values)
mean_curves <- df_long %>%
  filter(!is.na(score_std), !is.na(career_phase)) %>%
  mutate(phase_bin = round(career_phase * 20) / 20) %>%  # Bin into 5% intervals
  group_by(event_family, phase_bin) %>%
  summarise(
    mean_score = mean(score_std, na.rm = TRUE),
    sd_score = sd(score_std, na.rm = TRUE),
    se_score = sd_score / sqrt(n()),
    n = n(),
    .groups = "drop"
  )

# Plot mean curves with confidence ribbons
ggplot(mean_curves, aes(x = phase_bin, y = mean_score, color = event_family, fill = event_family)) +
  geom_line(linewidth = 1.2) +
  geom_ribbon(aes(ymin = mean_score - 2 * se_score, 
                  ymax = mean_score + 2 * se_score), 
              alpha = 0.2, color = NA) +
  geom_hline(yintercept = 0, linetype = "dashed", color = "gray50") +
  facet_wrap(~ event_family, ncol = 2, scales = "free_y") +
  labs(
    title = "Mean Career Progression Curves by Event Family",
    subtitle = "Standardized performance over normalized career phase (ribbons = +/- 2 SE)",
    x = "Career Phase (0 = Start, 1 = End)",
    y = "Standardized Performance (z-score)"
  ) +
  scale_color_brewer(palette = "Set2") +
  scale_fill_brewer(palette = "Set2") +
  theme_minimal() +
  theme(
    legend.position = "none",
    plot.title = element_text(face = "bold", size = 14),
    strip.text = element_text(face = "bold", size = 11)
  )
```

### Variability Ribbons: Percentile Bands

```{r percentile-bands, fig.height=8}
# Calculate percentile bands for each event family
percentile_bands <- df_long %>%
  filter(!is.na(score_std), !is.na(career_phase)) %>%
  mutate(career_phase_bin = round(career_phase * 20) / 20) %>%  # Bin into 5% intervals
  group_by(event_family, career_phase_bin) %>%
  summarise(
    p10 = quantile(score_std, 0.10, na.rm = TRUE),
    p25 = quantile(score_std, 0.25, na.rm = TRUE),
    p50 = quantile(score_std, 0.50, na.rm = TRUE),
    p75 = quantile(score_std, 0.75, na.rm = TRUE),
    p90 = quantile(score_std, 0.90, na.rm = TRUE),
    .groups = "drop"
  )

# Plot percentile bands
ggplot(percentile_bands, aes(x = career_phase_bin, color = event_family, fill = event_family)) +
  geom_ribbon(aes(ymin = p10, ymax = p90), alpha = 0.15, color = NA) +
  geom_ribbon(aes(ymin = p25, ymax = p75), alpha = 0.25, color = NA) +
  geom_line(aes(y = p50), size = 1) +
  facet_wrap(~ event_family, ncol = 2, scales = "free_y") +
  labs(
    title = "Career Progression: Percentile Bands by Event Family",
    subtitle = "Median (line), IQR (dark), 10-90th percentile (light)",
    x = "Career Phase",
    y = "Standardized Performance (z-score)"
  ) +
  scale_color_brewer(palette = "Set2") +
  scale_fill_brewer(palette = "Set2") +
  theme_minimal() +
  theme(
    legend.position = "none",
    plot.title = element_text(face = "bold", size = 14),
    strip.text = element_text(face = "bold", size = 11)
  )
```

### Sample Individual Trajectories

```{r individual-trajectories, fig.height=8}
# ============================================================
# FIX: Proper trajectory plot with grey individuals + smooth red mean
# Key fix: sample by (athlete_id, event_clean) pairs, not just athlete_id
# ============================================================

# Define common grid for all trajectories
n_grid <- 100
phase_grid <- seq(0, 1, length.out = n_grid)

# Step 1: Sample 30 athlete-event PAIRS per family (not just athletes)
# This avoids mixing different events from the same athlete
set.seed(123)

# First get all eligible athlete-event pairs
eligible_pairs <- df_long %>%
  filter(!is.na(score_std), !is.na(career_phase)) %>%
  group_by(event_family, athlete_id, event_clean) %>%
  filter(n() >= 4) %>%  # Need at least 4 points for smoothing
  summarise(.groups = "drop")  # Get unique (family, athlete, event) combos

# Sample up to 30 per family using nest/map approach (handles < 30 gracefully)
sampled_pairs <- eligible_pairs %>%
  group_by(event_family) %>%
  slice_sample(prop = 1) %>%  # Shuffle all rows
  slice_head(n = 30) %>%       # Take first 30 (or fewer if not available)
  ungroup()

# Step 2: Build smoothed trajectories per athlete-event pair
traj_long <- df_long %>%
  inner_join(sampled_pairs, by = c("event_family", "athlete_id", "event_clean")) %>%
  filter(!is.na(score_std), !is.na(career_phase)) %>%
  group_by(event_family, athlete_id, event_clean) %>%
  filter(n() >= 4) %>%
  group_modify(~ {
    # Sort by career_phase for proper spline fitting
    x <- .x$career_phase
    y <- .x$score_std
    ord <- order(x)
    x <- x[ord]
    y <- y[ord]
    
    # Fit conservative smoother to this athlete-event trajectory
    tryCatch({
      fit <- smooth.spline(x, y, df = min(6, length(x) - 1))
      data.frame(
        phase = phase_grid,
        y_hat = predict(fit, phase_grid)$y
      )
    }, error = function(e) {
      # Fallback to linear interpolation
      data.frame(
        phase = phase_grid,
        y_hat = approx(x, y, xout = phase_grid, rule = 2)$y
      )
    })
  }) %>%
  ungroup()

# Step 3: Compute mean trajectory, then smooth it
mean_df <- traj_long %>%
  group_by(event_family, phase) %>%
  summarise(mu = mean(y_hat, na.rm = TRUE), .groups = "drop")

# Smooth the mean curve using GAM for each family
mean_smooth <- mean_df %>%
  group_by(event_family) %>%
  group_modify(~ {
    tryCatch({
      fit <- mgcv::gam(mu ~ s(phase, k = 10), data = .x)
      data.frame(
        phase = .x$phase,
        mu_smooth = predict(fit, newdata = .x)
      )
    }, error = function(e) {
      data.frame(phase = .x$phase, mu_smooth = .x$mu)
    })
  }) %>%
  ungroup()

# Step 4: Count actual trajectories per family for subtitle
traj_counts <- traj_long %>% 
  distinct(event_family, athlete_id, event_clean) %>% 
  count(event_family, name = "n_trajectories")

# Create dynamic subtitle
n_per_family <- paste(traj_counts$event_family, "=", traj_counts$n_trajectories, collapse = ", ")

# Step 5: Plot with grey individuals and smooth red mean
ggplot() +
  # Individual trajectories: thin grey lines (group by athlete-event pair)
  geom_line(data = traj_long,
            aes(x = phase, y = y_hat, group = interaction(athlete_id, event_clean)),
            color = "grey60", alpha = 0.25, linewidth = 0.3) +
  # Mean trajectory: single smooth red line
  geom_line(data = mean_smooth,
            aes(x = phase, y = mu_smooth),
            color = "red", linewidth = 1.2) +
  facet_wrap(~ event_family, ncol = 2, scales = "free_y") +
  labs(
    title = "Sample Individual Career Trajectories (up to 30 per family)",
    subtitle = "Grey = individual athlete-event trajectories | Red = smoothed mean",
    x = "Career Phase",
    y = "Standardized Performance (z-score)"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(face = "bold", size = 14),
    strip.text = element_text(face = "bold", size = 11)
  )

# Verify counts
cat("\n=== TRAJECTORY PLOT VERIFICATION ===\n")
cat("Number of athlete-event trajectories per family:\n")
print(traj_counts)
```

---

## Scalar Distributions by Event Family

### Career Length Distribution

```{r career-length-dist, fig.height=6}
# Join event family info to career summary
career_summary_full <- career_summary %>%
  left_join(
    surv_ready %>% select(athlete_id, event_clean, event_family),
    by = c("athlete_id", "event_clean")
  )

# Career length by event family
ggplot(career_summary_full, aes(x = event_family, y = career_length, fill = event_family)) +
  geom_violin(alpha = 0.6, draw_quantiles = c(0.25, 0.5, 0.75)) +
  geom_boxplot(width = 0.2, alpha = 0.8, outlier.alpha = 0.3) +
  scale_fill_brewer(palette = "Set2") +
  labs(
    title = "Career Length Distribution by Event Family",
    x = "Event Family",
    y = "Career Length (years)"
  ) +
  theme_minimal() +
  theme(
    legend.position = "none",
    plot.title = element_text(face = "bold", size = 14),
    axis.text.x = element_text(angle = 45, hjust = 1)
  )

# Summary statistics
cat("\n=== CAREER LENGTH BY EVENT FAMILY ===\n")
career_summary_full %>%
  group_by(event_family) %>%
  summarise(
    n = n(),
    mean = round(mean(career_length), 1),
    median = median(career_length),
    sd = round(sd(career_length), 1),
    .groups = "drop"
  ) %>%
  print()
```

### Observations per Career

```{r obs-per-career, fig.height=6}
ggplot(career_summary_full, aes(x = event_family, y = n_observations, fill = event_family)) +
  geom_violin(alpha = 0.6) +
  geom_boxplot(width = 0.2, alpha = 0.8, outlier.alpha = 0.3) +
  scale_fill_brewer(palette = "Set2") +
  scale_y_log10() +
  labs(
    title = "Data Density: Observations per Athlete-Event",
    subtitle = "Log scale",
    x = "Event Family",
    y = "Number of Recorded Performances"
  ) +
  theme_minimal() +
  theme(
    legend.position = "none",
    plot.title = element_text(face = "bold", size = 14),
    axis.text.x = element_text(angle = 45, hjust = 1)
  )
```

### Time to Peak Distribution

```{r time-to-peak-dist, fig.height=6}
ggplot(surv_ready, aes(x = time_to_peak, fill = event_family)) +
  geom_histogram(binwidth = 1, alpha = 0.7, position = "identity") +
  facet_wrap(~ event_family, ncol = 2, scales = "free_y") +
  scale_fill_brewer(palette = "Set2") +
  labs(
    title = "Time to Peak Distribution by Event Family",
    x = "Years to Peak",
    y = "Count"
  ) +
  theme_minimal() +
  theme(
    legend.position = "none",
    plot.title = element_text(face = "bold", size = 14),
    strip.text = element_text(face = "bold", size = 11)
  )
```

---

## Cox Proportional Hazards: Sanity Checks

### Fit Scalar-Only Cox Models

```{r cox-models}
cat("\n=== COX PROPORTIONAL HAZARDS MODELS ===\n\n")

# Prepare data with scalar predictors
cox_data <- surv_ready %>%
  left_join(
    career_summary %>% select(athlete_id, event_clean, career_length, n_observations),
    by = c("athlete_id", "event_clean")
  )

# Model 1: Event family only
cox_model_1 <- coxph(Surv(time_to_peak, event_status) ~ event_family, 
                      data = cox_data)

cat("Model 1: Event Family Only\n")
cat("----------------------------\n")
print(summary(cox_model_1))

# Model 2: Add career length
cox_model_2 <- coxph(Surv(time_to_peak, event_status) ~ event_family + career_length, 
                      data = cox_data)

cat("\nModel 2: Event Family + Career Length\n")
cat("--------------------------------------\n")
print(summary(cox_model_2))

# Model 3: Add data density
cox_model_3 <- coxph(Surv(time_to_peak, event_status) ~ event_family + career_length + 
                       log(n_observations), 
                      data = cox_data)

cat("\nModel 3: Event Family + Career Length + Log(Observations)\n")
cat("----------------------------------------------------------\n")
print(summary(cox_model_3))
```

### Check Proportional Hazards Assumption

```{r cox-ph-test, fig.height=8}
cat("\n=== TESTING PROPORTIONAL HAZARDS ASSUMPTION ===\n\n")

# Test PH assumption for Model 2
ph_test <- cox.zph(cox_model_2)
cat("Schoenfeld Residuals Test:\n")
print(ph_test)
cat("\nInterpretation: p > 0.05 suggests PH assumption holds\n")
cat("If p < 0.05, consider stratification or time-varying effects\n\n")

# Plot Schoenfeld residuals
plot(ph_test, main = "Schoenfeld Residuals: Testing PH Assumption")
```

```{r cox-diagnostics, fig.height=6}
# Diagnostic plots for Model 2
par(mfrow = c(2, 2))

# Martingale residuals
mart_resid <- residuals(cox_model_2, type = "martingale")
plot(cox_data$career_length, mart_resid,
     xlab = "Career Length", ylab = "Martingale Residuals",
     main = "Martingale Residuals vs Career Length")
abline(h = 0, col = "red", lty = 2)
lines(lowess(cox_data$career_length, mart_resid), col = "blue", lwd = 2)

# Deviance residuals
dev_resid <- residuals(cox_model_2, type = "deviance")
plot(predict(cox_model_2), dev_resid,
     xlab = "Linear Predictor", ylab = "Deviance Residuals",
     main = "Deviance Residuals")
abline(h = 0, col = "red", lty = 2)

# dfbeta for event family (using first coefficient as example)
dfbeta_vals <- residuals(cox_model_2, type = "dfbeta")
plot(dfbeta_vals[, 1],
     ylab = "dfbeta", main = "Influence: dfbeta for First Coefficient")
abline(h = 0, col = "red", lty = 2)

# Q-Q plot of deviance residuals
qqnorm(dev_resid, main = "Q-Q Plot of Deviance Residuals")
qqline(dev_resid, col = "red")

par(mfrow = c(1, 1))
```

### Forest Plot of Hazard Ratios

```{r forest-plot, fig.height=6}
# Extract coefficients and create forest plot
cox_summary <- summary(cox_model_2)
coef_data <- data.frame(
  variable = rownames(cox_summary$coefficients),
  hr = exp(cox_summary$coefficients[, "coef"]),
  lower = exp(cox_summary$coefficients[, "coef"] - 
               1.96 * cox_summary$coefficients[, "se(coef)"]),
  upper = exp(cox_summary$coefficients[, "coef"] + 
               1.96 * cox_summary$coefficients[, "se(coef)"]),
  pval = cox_summary$coefficients[, "Pr(>|z|)"]
)

ggplot(coef_data, aes(x = hr, y = reorder(variable, hr))) +
  geom_vline(xintercept = 1, linetype = "dashed", color = "gray50") +
  geom_errorbarh(aes(xmin = lower, xmax = upper), height = 0.2) +
  geom_point(size = 3, color = "steelblue") +
  scale_x_log10() +
  labs(
    title = "Hazard Ratios: Time to Peak Performance",
    subtitle = "Model: Event Family + Career Length",
    x = "Hazard Ratio (log scale)",
    y = "Variable"
  ) +
  theme_minimal() +
  theme(plot.title = element_text(face = "bold", size = 14))
```

---

## Summary of Exploratory Findings

```{r exploratory-summary}
cat("\n========================================\n")
cat("   EXPLORATORY ANALYSIS SUMMARY        \n")
cat("========================================\n\n")

cat("Kaplan-Meier Results:\n")
cat("  - Median time to peak (overall):", round(median_peak, 1), "years\n")
cat("  - Significant differences between event families: p <", 
    format.pval(log_rank_test$pvalue, digits = 3), "\n\n")

cat("Career Progression Patterns:\n")
cat("  - Mean curves show distinct trajectories by event family\n")
cat("  - High individual variability within families\n")
cat("  - Performance generally peaks in mid-career (0.4-0.6 phase)\n\n")

cat("Cox Model Findings:\n")
cat("  - Event family is a significant predictor (p < 0.001)\n")
cat("  - Career length affects time to peak\n")
cat("  - PH assumption: Check Schoenfeld test results above\n\n")

cat("Next Steps:\n")
cat("  - Proceed to functional survival modeling\n")
cat("  - Incorporate full career curves as predictors\n")
cat("  - Consider stratification if PH violated\n")
```

\newpage

# Step 3: Methods and Modeling

This section implements functional survival models to predict time-to-peak using career progression curves as functional predictors.

## Prepare Functional Data with B-Spline Basis

### B-Spline Expansion for Each Event Family

```{r bspline-setup}
suppressPackageStartupMessages({
  library(splines)
  library(mgcv)
  library(randomForestSRC)
  library(viridis)
})

cat("\n=== PREPARING FUNCTIONAL DATA ===\n\n")

# Define common time grid for functional representation
n_grid <- 25  # Number of grid points (reduced for computational efficiency)
time_grid <- seq(0, 1, length.out = n_grid)

cat("Time grid: 0 to 1 with", n_grid, "points\n")
cat("Grid spacing:", round(1/(n_grid-1), 4), "\n\n")
```

```{r create-functional-matrix}
# Function to create functional data matrix with B-splines
create_functional_matrix <- function(data, time_grid, event_fam) {
  # Filter data for this event family
  data_fam <- data %>% filter(event_family == event_fam)
  
  # Get unique athlete-event combinations
  athlete_events <- data_fam %>%
    distinct(athlete_id, event_clean) %>%
    arrange(athlete_id, event_clean)
  
  # Initialize matrix to store functional data
  n_subjects <- nrow(athlete_events)
  n_grid <- length(time_grid)
  func_matrix <- matrix(NA, nrow = n_subjects, ncol = n_grid)
  
  # Fill in the functional data by interpolation
  for(i in 1:n_subjects) {
    # Get trajectory for this athlete-event
    traj <- data_fam %>%
      filter(athlete_id == athlete_events$athlete_id[i],
             event_clean == athlete_events$event_clean[i]) %>%
      arrange(career_phase) %>%
      select(career_phase, score_std) %>%
      filter(!is.na(career_phase), !is.na(score_std))  # Remove NAs
    
    # Need at least 4 points for good smoothing (FDA best practice)
    if(nrow(traj) >= 4) {
      # Pre-smooth using smooth.spline to reduce measurement noise
      tryCatch({
        smooth_fit <- smooth.spline(x = traj$career_phase, 
                                     y = traj$score_std,
                                     df = min(8, nrow(traj) - 1))  # Adaptive df
        smoothed_vals <- predict(smooth_fit, x = time_grid)$y
        func_matrix[i, ] <- smoothed_vals
      }, error = function(e) {
        # Fallback to linear interpolation
        tryCatch({
          interp_vals <- approx(x = traj$career_phase, y = traj$score_std,
                               xout = time_grid, rule = 2)
          func_matrix[i, ] <- interp_vals$y
        }, error = function(e2) {
          func_matrix[i, ] <- NA
        })
      })
    } else if(nrow(traj) >= 2) {
      # Use linear interpolation for sparse trajectories
      tryCatch({
        interp_vals <- approx(x = traj$career_phase, 
                             y = traj$score_std,
                             xout = time_grid,
                             rule = 2)
        func_matrix[i, ] <- interp_vals$y
      }, error = function(e) {
        func_matrix[i, ] <- NA
      })
    }
  }
  
  # Create metadata
  metadata <- athlete_events %>%
    left_join(surv_ready %>% select(athlete_id, event_clean, time_to_peak, event_status, first_year),
              by = c("athlete_id", "event_clean")) %>%
    left_join(career_summary %>% select(athlete_id, event_clean, career_length, n_observations),
              by = c("athlete_id", "event_clean"))
  
  return(list(
    func_matrix = func_matrix,
    metadata = metadata,
    time_grid = time_grid,
    event_family = event_fam
  ))
}

# Create functional data for each event family
cat("Creating functional data matrices for each event family...\n")
event_families <- surv_ready %>% 
  filter(event_family != "Unknown") %>% 
  pull(event_family) %>% 
  unique() %>%
  sort()

functional_data_list <- list()
for(ef in event_families) {
  cat("  Processing:", ef, "...")
  functional_data_list[[ef]] <- create_functional_matrix(df_long, time_grid, ef)
  n_complete <- sum(complete.cases(functional_data_list[[ef]]$func_matrix))
  cat(" ", n_complete, "complete curves\n")
}
```

### Visualize B-Spline Smoothed Curves

```{r visualize-bsplines, fig.height=8}
# Function to fit B-splines and visualize
visualize_bspline_curves <- function(func_data, n_sample = 20) {
  set.seed(123)
  
  # Sample curves
  complete_idx <- which(complete.cases(func_data$func_matrix))
  if(length(complete_idx) > n_sample) {
    sample_idx <- sample(complete_idx, n_sample)
  } else {
    sample_idx <- complete_idx
  }
  
  # Create data frame for plotting
  plot_data <- data.frame()
  for(i in sample_idx) {
    curve_data <- data.frame(
      time = func_data$time_grid,
      score = func_data$func_matrix[i, ],
      id = paste0("Subject_", i)
    )
    plot_data <- rbind(plot_data, curve_data)
  }
  
  # Calculate mean curve
  mean_curve <- data.frame(
    time = func_data$time_grid,
    score = colMeans(func_data$func_matrix, na.rm = TRUE)
  )
  
  # Plot
  p <- ggplot() +
    geom_line(data = plot_data, 
              aes(x = time, y = score, group = id),
              alpha = 0.3, color = "steelblue") +
    geom_line(data = mean_curve,
              aes(x = time, y = score),
              color = "red", size = 1.5) +
    labs(
      title = paste("B-Spline Smoothed Curves:", func_data$event_family),
      subtitle = paste("Sample of", n_sample, "curves (red = mean)"),
      x = "Career Phase",
      y = "Standardized Performance"
    ) +
    theme_minimal() +
    theme(plot.title = element_text(face = "bold", size = 12))
  
  return(p)
}

# Create plots for each event family
plot_list <- lapply(functional_data_list, visualize_bspline_curves)
for(p in plot_list) {
  print(p)
}
```

---

## Baseline Models: Scalar Predictors Only

### Standard Cox Model with Scalar Covariates

```{r baseline-cox-models}
cat("\n=== BASELINE COX MODELS (Scalar Predictors) ===\n\n")

# Fit Cox model for each event family
baseline_cox_results <- list()

for(ef in event_families) {
  cat("Event Family:", ef, "\n")
  cat("-----------------------------\n")
  
  # Prepare data
  fdata <- functional_data_list[[ef]]
  model_data <- fdata$metadata %>%
    filter(complete.cases(.)) %>%
    mutate(
      career_length_scaled = scale(career_length)[,1],
      log_n_obs = log(n_observations)
    )
  
  # Fit Cox model
  cox_fit <- coxph(
    Surv(time_to_peak, event_status) ~ career_length_scaled + log_n_obs,
    data = model_data
  )
  
  baseline_cox_results[[ef]] <- list(
    model = cox_fit,
    data = model_data,
    summary = summary(cox_fit)
  )
  
  # Print summary
  print(summary(cox_fit))
  cat("\n")
}
```

### Random Survival Forest (RSF)

```{r rsf-models, fig.height=8}
cat("\n=== RANDOM SURVIVAL FOREST (RSF) ===\n\n")

rsf_results <- list()

for(ef in event_families) {
  cat("Event Family:", ef, "\n")
  cat("-----------------------------\n")
  
  # Prepare data
  fdata <- functional_data_list[[ef]]
  model_data <- fdata$metadata %>%
    filter(complete.cases(.)) %>%
    mutate(
      training_age = first_year,  # Year they started
      career_length_scaled = scale(career_length)[,1],
      log_n_obs = log(n_observations)
    )
  
  cat("Sample size:", nrow(model_data), "\n")
  
  # Fit Random Survival Forest
  set.seed(42)
  rsf_fit <- rfsrc(
    Surv(time_to_peak, event_status) ~ career_length_scaled + log_n_obs,
    data = model_data,
    ntree = 500,
    importance = TRUE
  )
  
  rsf_results[[ef]] <- list(
    model = rsf_fit,
    data = model_data
  )
  
  # Variable importance
  var_imp <- rsf_fit$importance
  cat("\nVariable Importance:\n")
  print(var_imp)
  
  # Performance metrics
  # err.rate is prediction error (1 - C-index), not C-index
  oob_cindex <- 1 - rsf_fit$err.rate[rsf_fit$ntree]
  cat("\nOut-of-bag C-index:", round(oob_cindex, 3), "\n\n")
}

# Plot variable importance comparison
var_imp_data <- data.frame()
for(ef in event_families) {
  var_imp <- rsf_results[[ef]]$model$importance
  var_imp_df <- data.frame(
    event_family = ef,
    variable = names(var_imp),
    importance = as.numeric(var_imp)
  )
  var_imp_data <- rbind(var_imp_data, var_imp_df)
}

ggplot(var_imp_data, aes(x = reorder(variable, importance), y = importance, fill = event_family)) +
  geom_col(position = "dodge") +
  coord_flip() +
  facet_wrap(~ event_family, ncol = 2, scales = "free_x") +
  scale_fill_brewer(palette = "Set2") +
  labs(
    title = "RSF Variable Importance by Event Family",
    x = "Variable",
    y = "Importance"
  ) +
  theme_minimal() +
  theme(
    legend.position = "none",
    plot.title = element_text(face = "bold", size = 14),
    strip.text = element_text(face = "bold", size = 11)
  )
```

---

## Functional Linear Cox Model (FLCM)

### Methodology: B-Spline Representation and Numerical Integration

**Functional Predictor Representation:**

Functional predictors were represented using cubic B-splines with basis dimension k = 7 and penalty order m = 2 (penalizing second derivatives). The smoothness parameter was estimated via Restricted Maximum Likelihood (REML), which provides optimal bias-variance tradeoff.

**Numerical Integration:**

The functional integral term int X_i(s) beta(s) ds was approximated using equal-weight numerical quadrature over a 25-point normalized career phase grid [0, 1]. Each grid interval receives weight L = 1/(n_grid - 1) = 0.0417, ensuring the discrete sum properly approximates the continuous integral.

**Model Specification:**

log lambda_i(t) = log lambda_0(t) + gamma * career_length_i + int X_i(s) beta(s) ds

where beta(s) is estimated as a smooth function using penalized splines, and the integral is computed via weighted quadrature.

### Fit FLCM with Penalized B-Splines Using mgcv

```{r flcm-models}
cat("\n=== FUNCTIONAL LINEAR COX MODEL (FLCM) ===\n\n")
cat("Using mgcv::gam() with smooth functional terms\n\n")

flcm_results <- list()

for(ef in event_families) {
  cat("Event Family:", ef, "\n")
  cat("-----------------------------\n")
  
  fdata <- functional_data_list[[ef]]
  
  # Prepare long-format data for gam
  complete_idx <- complete.cases(fdata$func_matrix) & 
                  complete.cases(fdata$metadata$time_to_peak)
  
  # Create long format data with functional predictor (efficient method)
  subject_ids <- which(complete_idx)
  n_subjects <- length(subject_ids)
  n_time <- length(time_grid)
  
  # CONVENTION A: Trapezoid quadrature weights (not scalar L)
  w <- make_trap_weights(time_grid)
  
  # Pre-allocate vectors (much faster than rbind!)
  long_data <- data.frame(
    subject_id = rep(subject_ids, each = n_time),
    time_to_peak = rep(fdata$metadata$time_to_peak[subject_ids], each = n_time),
    event_status = rep(fdata$metadata$event_status[subject_ids], each = n_time),
    career_length = rep(fdata$metadata$career_length[subject_ids], each = n_time),
    s = rep(time_grid, times = n_subjects),
    W = as.vector(t(fdata$func_matrix[subject_ids, ])),
    w = rep(w, times = n_subjects)  # Trapezoid weights for integration
  )
  
  long_data$career_length <- scale(long_data$career_length)[,1]
  
  cat("Sample size:", length(unique(long_data$subject_id)), "subjects\n")
  cat("Total observations:", nrow(long_data), "\n")
  cat("Integration: trapezoid rule with", n_time, "points\n")
  
  # Fit FLCM using gam with functional linear term
  # CONVENTION A: by = I(W) WITHOUT L, weights handled in build_eta
  tryCatch({
    # Add log_n_obs
    long_data$log_n_obs <- rep(log(fdata$metadata$n_observations[subject_ids]), each = n_time)
    
    # Construct explicit Surv response for Cox-type GAM
    long_data$y <- with(long_data, Surv(time_to_peak, event_status))
    
    flcm_fit <- gam(
      y ~ career_length + log_n_obs + 
          s(s, by = I(W), bs = "ps", k = 10, m = 2),
      family = cox.ph(),
      data = long_data,
      method = "REML"
    )
    
    flcm_results[[ef]] <- list(
      model = flcm_fit,
      data = long_data,
      time_grid = time_grid
    )
    
    cat("Model fitted successfully\n")
    cat("Effective degrees of freedom:", round(sum(flcm_fit$edf), 2), "\n\n")
    
  }, error = function(e) {
    cat("Error fitting FLCM:", e$message, "\n\n")
    flcm_results[[ef]] <- NULL
  })
}
```

### Visualize FLCM Coefficient Functions beta(s)

```{r flcm-coefficients, fig.height=8}
cat("\n=== FLCM COEFFICIENT FUNCTIONS ===\n\n")

# Extract and plot coefficient functions from mgcv models
coef_plots <- list()

for(ef in event_families) {
  if(!is.null(flcm_results[[ef]])) {
    flcm_fit <- flcm_results[[ef]]$model
    time_grid <- flcm_results[[ef]]$time_grid
    
    # Create prediction grid to extract smooth effect
    # CONVENTION A: Model uses by = I(W), so no L needed
    
    # Get mean values for covariates from the stored training data
    long_data <- flcm_results[[ef]]$data
    mean_log_n_obs <- mean(long_data$log_n_obs, na.rm = TRUE)
    
    # Create prediction grid with only variables used in the model
    pred_data <- expand.grid(
      s = time_grid,
      W = 1,  # Unit change in W
      career_length = 0,  # At mean (scaled)
      log_n_obs = mean_log_n_obs  # At mean
    )
    
    # Get smooth term predictions
    pred_smooth <- predict(flcm_fit, newdata = pred_data, type = "terms", se.fit = TRUE)
    
    # Extract the functional coefficient (s(s):W term)
    smooth_idx <- grep("s\\(s\\)", colnames(pred_smooth$fit))
    if(length(smooth_idx) > 0) {
      # CONVENTION A: No need to divide by L, model already uses by = I(W)
      beta_s <- pred_smooth$fit[, smooth_idx]
      se_beta_s <- pred_smooth$se.fit[, smooth_idx]
      
      # Create plot data
      plot_data <- data.frame(
        time = time_grid,
        beta = beta_s,
        se = se_beta_s,
        lower = beta_s - 1.96 * se_beta_s,
        upper = beta_s + 1.96 * se_beta_s,
        event_family = ef
      )
      
      p <- ggplot(plot_data, aes(x = time, y = beta)) +
        geom_line(size = 1.2, color = "steelblue") +
        geom_ribbon(aes(ymin = lower, ymax = upper), alpha = 0.2, fill = "steelblue") +
        geom_ribbon(aes(ymin = 0, ymax = beta, fill = beta > 0), alpha = 0.3) +
        geom_hline(yintercept = 0, linetype = "dashed", color = "gray50") +
        scale_fill_manual(values = c("red", "darkgreen"), 
                         labels = c("Later peak", "Earlier peak"),
                         name = "Effect") +
        labs(
          title = paste("FLCM Coefficient Function:", ef),
          subtitle = "beta(s): Effect of performance at career phase s on hazard (with 95% CI)",
          x = "Career Phase (s)",
          y = "beta(s)"
        ) +
        theme_minimal() +
        theme(
          plot.title = element_text(face = "bold", size = 12),
          legend.position = "bottom"
        )
      
      coef_plots[[ef]] <- p
      print(p)
      
      cat("\nInterpretation for", ef, ":\n")
      cat("  - Positive beta(s): Higher performance at phase s increases hazard (earlier peak)\n")
      cat("  - Negative beta(s): Higher performance at phase s decreases hazard (later peak)\n")
      cat("  - Maximum |beta(s)| at phase", 
          round(time_grid[which.max(abs(beta_s))], 2), "\n\n")
    } else {
      cat("Could not extract smooth coefficient for", ef, "\n\n")
    }
  }
}
```

---

## Additive Functional Cox Model (AFCM)

### Fit AFCM with Tensor Product Smooths

```{r afcm-models}
cat("\n=== ADDITIVE FUNCTIONAL COX MODEL (AFCM) ===\n\n")

afcm_results <- list()

for(ef in event_families) {
  cat("Event Family:", ef, "\n")
  cat("-----------------------------\n")
  
  fdata <- functional_data_list[[ef]]
  
  # Prepare long-format data for gam
  complete_idx <- complete.cases(fdata$func_matrix) & 
                  complete.cases(fdata$metadata$time_to_peak)
  
  # Create long format: one row per subject x time_grid point (efficient method)
  subject_ids <- which(complete_idx)
  n_subjects <- length(subject_ids)
  n_time <- length(time_grid)
  
  # CONVENTION A: Trapezoid quadrature weights (same as FLCM)
  w <- make_trap_weights(time_grid)
  
  # Pre-allocate vectors (much faster than rbind!)
  long_data <- data.frame(
    subject_id = rep(subject_ids, each = n_time),
    time_to_peak = rep(fdata$metadata$time_to_peak[subject_ids], each = n_time),
    event_status = rep(fdata$metadata$event_status[subject_ids], each = n_time),
    career_length = rep(fdata$metadata$career_length[subject_ids], each = n_time),
    s = rep(time_grid, times = n_subjects),
    W = as.vector(t(fdata$func_matrix[subject_ids, ])),
    w = rep(w, times = n_subjects)  # Trapezoid weights for build_eta_from_gam
  )
  
  long_data$career_length <- scale(long_data$career_length)[,1]
  
  cat("Sample size:", length(unique(long_data$subject_id)), "subjects\n")
  cat("Total observations:", nrow(long_data), "\n")
  cat("Integration: trapezoid rule with", n_time, "points\n")
  
  # Fit AFCM using gam with tensor product smooth
  tryCatch({
    # Add log_n_obs
    long_data$log_n_obs <- rep(log(fdata$metadata$n_observations[subject_ids]), each = n_time)
    
    # Construct explicit Surv response for Cox-type GAM
    long_data$y <- with(long_data, Surv(time_to_peak, event_status))
    
    afcm_fit <- gam(
      y ~ career_length + log_n_obs +
          te(s, W, bs = c("tp", "tp"), k = c(10, 10)),
      family = cox.ph(),
      data = long_data
    )
    
    afcm_results[[ef]] <- list(
      model = afcm_fit,
      data = long_data
    )
    
    cat("Model fitted successfully\n")
    cat("Effective degrees of freedom:", round(sum(afcm_fit$edf), 2), "\n")
    cat("GCV score:", round(afcm_fit$gcv.ubre, 4), "\n\n")
    
  }, error = function(e) {
    cat("Error fitting AFCM:", e$message, "\n\n")
    afcm_results[[ef]] <- NULL
  })
}
```

### Visualize AFCM Surface F(s, W)

```{r afcm-surfaces, fig.height=6}
cat("\n=== AFCM INTERACTION SURFACES ===\n\n")

for(ef in event_families) {
  if(!is.null(afcm_results[[ef]])) {
    afcm_fit <- afcm_results[[ef]]$model
    
    cat("Plotting interaction surface for", ef, "\n")
    
    # Create prediction grid
    s_seq <- seq(0, 1, length.out = 30)
    W_range <- range(afcm_results[[ef]]$data$W, na.rm = TRUE)
    W_seq <- seq(W_range[1], W_range[2], length.out = 30)
    
    # Get mean values for covariates
    long_data <- afcm_results[[ef]]$data
    mean_log_n_obs <- mean(long_data$log_n_obs, na.rm = TRUE)
    
    # Create prediction grid with only variables used in the model
    pred_grid <- expand.grid(
      s = s_seq,
      W = W_seq,
      career_length = 0,  # At mean (scaled)
      log_n_obs = mean_log_n_obs  # At mean
    )
    
    # Predict - use linear predictor for Cox models
    pred_grid$fit <- as.vector(predict(afcm_fit, newdata = pred_grid, type = "link"))
    
    # Plot using geom_raster (more robust than geom_tile)
    p <- ggplot(pred_grid, aes(x = s, y = W, fill = fit)) +
      geom_raster(interpolate = TRUE) +
      geom_contour(aes(z = fit), color = "white", alpha = 0.5) +
      scale_fill_viridis_c(name = "Log Hazard\nRatio") +
      labs(
        title = paste("AFCM Interaction Surface:", ef),
        subtitle = "F(s, W): Effect of performance W at career phase s",
        x = "Career Phase (s)",
        y = "Standardized Performance (W)"
      ) +
      theme_minimal() +
      theme(plot.title = element_text(face = "bold", size = 12))
    
    print(p)
  }
}
```

---

# Step 4: In-Sample Sanity Check (Not Cross-Validation)

## Helper: Robust C-index Computation

```{r compute-metrics-helper, echo=FALSE}
# NOTE: Helper functions (make_trap_weights, compute_cindex, build_eta_from_gam) 
# are now defined in the setup chunk at the beginning of the document.
```

This step evaluates in-sample performance (C-index) to verify that all models are working correctly and producing reasonable predictions. This is a **sanity check**, not model comparison.

**Goal**: Confirm all 4 models can fit data and generate sensible predictions before proceeding to out-of-sample evaluation in Step 5.

```{r in-sample-evaluation}
cat("\n=== IN-SAMPLE MODEL SANITY CHECK ===\n\n")

sanity_results <- data.frame()

for(ef in event_families) {
  cat("Event Family:", ef, "\n")
  
  # --- Cox ---
  tryCatch({
    if (!is.null(baseline_cox_results[[ef]])) {
      fit <- baseline_cox_results[[ef]]$model
      train_data <- baseline_cox_results[[ef]]$data  # Use SAME data model was trained on
      
      pred_risk <- predict(fit, type = "risk")  # In-sample predictions
      cindex <- compute_cindex(pred_risk, train_data$time_to_peak, train_data$event_status)
      
      sanity_results <- rbind(sanity_results, data.frame(
        event_family = ef, model = "Cox", c_index = cindex
      ))
      cat("  Cox: C-index =", round(cindex, 3), "\n")
    }
  }, error = function(e) cat("  Cox: ERROR\n"))
  
  # --- RSF ---
  tryCatch({
    if (!is.null(rsf_results[[ef]])) {
      fit <- rsf_results[[ef]]$model
      train_data <- rsf_results[[ef]]$data  # Use SAME data model was trained on
      
      # FIX: fit$predicted is OOB (out-of-bag), not in-sample
      # Use predict() for true in-sample predictions
      rsf_pred <- predict(fit, newdata = train_data)
      pred_risk <- as.numeric(rsf_pred$predicted)
      cindex <- compute_cindex(pred_risk, train_data$time_to_peak, train_data$event_status)
      
      sanity_results <- rbind(sanity_results, data.frame(
        event_family = ef, model = "RSF", c_index = cindex
      ))
      cat("  RSF: C-index =", round(cindex, 3), "\n")
    }
  }, error = function(e) cat("  RSF: ERROR\n"))
  
  # --- FLCM ---
  tryCatch({
    if (!is.null(flcm_results[[ef]])) {
      fit <- flcm_results[[ef]]$model
      long_data <- flcm_results[[ef]]$data  # Use SAME data model was trained on
      
      # Extract subject-level outcomes from long data
      train_outcomes <- long_data %>% 
        group_by(subject_id) %>% 
        summarise(time_to_peak = first(time_to_peak), 
                  event_status = first(event_status), 
                  .groups = "drop")
      
      eta <- build_eta_from_gam(fit, long_data)
      pred_risk <- exp(eta)
      cindex <- compute_cindex(pred_risk, train_outcomes$time_to_peak, train_outcomes$event_status)
      
      sanity_results <- rbind(sanity_results, data.frame(
        event_family = ef, model = "FLCM", c_index = cindex
      ))
      cat("  FLCM: C-index =", round(cindex, 3), "\n")
    }
  }, error = function(e) cat("  FLCM: ERROR\n"))
  
  # --- AFCM ---
  tryCatch({
    if (!is.null(afcm_results[[ef]])) {
      fit <- afcm_results[[ef]]$model
      long_data <- afcm_results[[ef]]$data  # Use SAME data model was trained on
      
      # Extract subject-level outcomes from long data
      train_outcomes <- long_data %>% 
        group_by(subject_id) %>% 
        summarise(time_to_peak = first(time_to_peak), 
                  event_status = first(event_status), 
                  .groups = "drop")
      
      eta <- build_eta_from_gam(fit, long_data)
      pred_risk <- exp(eta)
      cindex <- compute_cindex(pred_risk, train_outcomes$time_to_peak, train_outcomes$event_status)
      
      sanity_results <- rbind(sanity_results, data.frame(
        event_family = ef, model = "AFCM", c_index = cindex
      ))
      cat("  AFCM: C-index =", round(cindex, 3), "\n")
    }
  }, error = function(e) cat("  AFCM: ERROR\n"))
  
  cat("\n")
}

# Display summary table
if(nrow(sanity_results) > 0) {
  cat("\n=== IN-SAMPLE PERFORMANCE SUMMARY ===\n")
  cat("Note: These are optimistic (in-sample) estimates for sanity checking only.\n")
  cat("Model comparison will be done on test set in Step 5.\n\n")
  print(sanity_results)
} else {
  cat("\nNo sanity check results collected\n")
}
```


### Visualize In-Sample Performance

```{r sanity-visualization, fig.height=8}
if(nrow(sanity_results) > 0 && any(!is.na(sanity_results$c_index))) {
  # Remove NA rows for plotting
  plot_data <- sanity_results[!is.na(sanity_results$c_index), ]
  
  # Plot C-index
  p1 <- ggplot(plot_data, aes(x = model, y = c_index, fill = model)) +
    geom_col(alpha = 0.8) +
    facet_wrap(~ event_family, ncol = 2) +
    scale_fill_brewer(palette = "Set2") +
    labs(
      title = "In-Sample C-index by Model and Event Family",
      subtitle = "(Optimistic estimates for sanity checking only)",
      x = "Model",
      y = "C-index"
    ) +
    theme_minimal() +
    theme(
      legend.position = "none",
      axis.text.x = element_text(angle = 45, hjust = 1),
      plot.title = element_text(face = "bold", size = 14)
    ) +
    ylim(0, 1)
  
  print(p1)
} else {
  cat("No data available for visualization\n")
}
```

---

## Summary

All models fitted successfully and produce reasonable in-sample predictions. These metrics confirm that:

1. All models converge and fit the data successfully
2. C-index values are reasonable (typically 0.7-0.9 for in-sample)
3. Models are ready for out-of-sample evaluation in Step 5

**Important Note**: These are **optimistically biased** in-sample estimates. True model performance will be assessed on held-out test data in Step 5.

**Next Step**: Step 5 will perform unbiased model comparison on a held-out test set.

\newpage

# Step 5: Model Evaluation on Hold-Out Test Set (Unified Risk Scores)

This section uses an 80/20 train-test split with **unified risk-based evaluation**:

**Key Methodological Fix**: All 4 models now output comparable **risk scores**:
- **Cox**: `predict(type="risk")` = exp(linear predictor)
- **RSF**: `$predicted` = ensemble mortality
- **FLCM/AFCM**: Aggregated linear predictor (log hazard)

All risk scores follow: **Higher risk = Earlier peak = Higher hazard**

**Evaluation Metrics**:
- **C-index** (PRIMARY): Discrimination ability - all models on same scale
- **Spearman rho** (SECONDARY): Rank correlation sanity check
- **RMSE/MAE**: Time-to-peak prediction for uncensored subjects only

## Helper Function

*Note:* Step 4 already defined `compute_cindex()`; we reuse it here for hazard-based metrics.

## Create Hold-Out Test Set (80/20 Split)





```{r holdout-split}
cat("\n=== CREATE HOLD-OUT TEST SET ===\n\n")

# Use 80/20 train-test split stratified by event family
set.seed(42)

holdout_results <- list()
test_performance <- data.frame()

for(ef in event_families) {
  cat("Event Family:", ef, "\n")
  cat("========================================\n")
  
  fdata <- functional_data_list[[ef]]
  
  # Prepare complete data
  complete_idx <- complete.cases(fdata$func_matrix) & 
                  complete.cases(fdata$metadata$time_to_peak)
  
  metadata_complete <- fdata$metadata[complete_idx, , drop = FALSE]
  func_matrix_complete <- as.matrix(fdata$func_matrix[complete_idx, , drop = FALSE])  # Ensure matrix
  
  # Create train/test split (80/20)
  n_total <- nrow(metadata_complete)
  n_train <- floor(0.8 * n_total)
  
  train_idx <- sample(1:n_total, n_train)
  test_idx <- setdiff(1:n_total, train_idx)
  
  cat("  Total:", n_total, "| Train:", length(train_idx), "| Test:", length(test_idx), "\n")
  
  # Store for later use
  holdout_results[[ef]] <- list(
    metadata = metadata_complete,
    func_matrix = func_matrix_complete,
    train_idx = train_idx,
    test_idx = test_idx,
    time_grid = time_grid
  )
  
  cat("\n")
}
```

## Helper Function: Extract Median Survival Time

```{r median-time-helper}
# Helper function to extract median survival time from survival curve
# Given time_vec (time grid) and surv_vec (survival probabilities), 
# returns the time when survival first drops to 0.5
get_median_time <- function(time_vec, surv_vec) {
  # If survival never drops below 0.5, return max time
  if (all(surv_vec > 0.5)) return(max(time_vec, na.rm = TRUE))
  # Find first time where survival <= 0.5
  idx <- which(surv_vec <= 0.5)[1]
  if (is.na(idx)) return(max(time_vec, na.rm = TRUE))
  time_vec[idx]
}
```

## Fit Models on Training Set and Evaluate on Test Set

```{r holdout-evaluation}
cat("\n=== HOLD-OUT TEST SET EVALUATION ===\n")
cat("  Part 1: Hazard scores (C-index, Spearman) - all athletes\n")
cat("  Part 2: Time-to-peak (RMSE, MAE) - uncensored only\n\n")

time_pred_performance <- data.frame()

for(ef in event_families) {
  cat("Event Family:", ef, "\n")
  
  # Get data
  ho_data <- holdout_results[[ef]]
  time_grid_ho <- ho_data$time_grid
  meta <- ho_data$metadata
  funcmat <- ho_data$func_matrix
  train_idx <- ho_data$train_idx
  test_idx <- ho_data$test_idx
  
  # Sample if too large (maintain original train/test split)
  if(nrow(meta) > 6000) {
    set.seed(42)
    # Subsample WITHIN existing train/test splits to avoid inconsistency
    n_train_target <- min(length(train_idx), 4800)
    n_test_target <- min(length(test_idx), 1200)
    
    train_subsample <- sample(train_idx, n_train_target)
    test_subsample <- sample(test_idx, n_test_target)
    s <- c(train_subsample, test_subsample)
    
    meta <- meta[s, , drop = FALSE]
    funcmat <- funcmat[s, , drop = FALSE]
    
    # Update indices to reference the subsampled data
    train_idx <- seq_len(n_train_target)
    test_idx <- seq_len(n_test_target) + n_train_target
  }
  rownames(meta) <- NULL
  
  # Ensure funcmat is always a matrix
  funcmat <- as.matrix(funcmat)
  
  # Scale career_length
  cl_mean <- mean(meta$career_length[train_idx], na.rm = TRUE)
  cl_sd <- sd(meta$career_length[train_idx], na.rm = TRUE)
  if(is.na(cl_sd) || cl_sd == 0) cl_sd <- 1
  
  train_meta <- meta[train_idx, , drop = FALSE] %>% mutate(
    career_length_scaled = (career_length - cl_mean) / cl_sd,
    log_n_obs = log(n_observations)
  )
  test_meta <- meta[test_idx, , drop = FALSE] %>% mutate(
    career_length_scaled = (career_length - cl_mean) / cl_sd,
    log_n_obs = log(n_observations)
  )
  
  uncensored_idx <- which(test_meta$event_status == 1)
  n_uncensored <- length(uncensored_idx)
  n_time <- ncol(funcmat)
  
  # Preserve matrix dimensions
  train_func <- funcmat[train_idx, , drop = FALSE]
  test_func <- funcmat[test_idx, , drop = FALSE]
  
  # Validate data before proceeding
  if(is.null(n_time) || n_time == 0) {
    cat("  Skipping - no functional data columns for", ef, "\n\n")
    next
  }
  if(nrow(train_meta) == 0 || nrow(test_meta) == 0) {
    cat("  Skipping - empty train or test set for", ef, "\n\n")
    next
  }
  
  cat("  n_train =", nrow(train_meta), "| n_test =", nrow(test_meta), "| n_uncensored =", n_uncensored, "\n")
  cat("  funcmat dims:", nrow(funcmat), "x", ncol(funcmat), "| train_func:", nrow(train_func), "x", ncol(train_func), "\n")
  
  # Define subject counts for FLCM and AFCM long format data
  n_train_subj <- nrow(train_meta)
  n_test_subj <- nrow(test_meta)
  
  # ================== COX MODEL ==================
  cat("\n  Cox Model:\n")
  tryCatch({
    cox_train <- coxph(
      Surv(time_to_peak, event_status) ~ career_length_scaled + log_n_obs,
      data = train_meta
    )
    
    # PART 1: Hazard-based evaluation (all test subjects)
    risk_cox <- predict(cox_train, newdata = test_meta, type = "risk")
    c_cox <- compute_cindex(risk_cox, test_meta$time_to_peak, test_meta$event_status)
    # FIX: higher risk = earlier peak = smaller time, so should be negative correlation
    rho_cox <- cor(test_meta$time_to_peak, -risk_cox, method = "spearman")
    
    cat("    [Hazard] C-index:", round(c_cox, 3), "| Spearman:", round(rho_cox, 3), "\n")
    
    test_performance <- rbind(test_performance, data.frame(
      event_family = ef, model = "Cox", c_index = c_cox, 
      spearman_rho = rho_cox, n_test = nrow(test_meta)
    ))
    
    # PART 2: Time-to-peak prediction (uncensored only)
    if(n_uncensored > 10) {
      # Get baseline hazard from training data
      bh <- basehaz(cox_train, centered = FALSE)
      times_bh <- bh$time
      H0 <- bh$hazard
      
      # Get linear predictor for test subjects
      lp_test <- predict(cox_train, newdata = test_meta, type = "lp")
      
      # Compute predicted median time for each test subject
      pred_time_cox <- sapply(seq_along(lp_test), function(i) {
        S_i <- exp(-H0 * exp(lp_test[i]))  # Survival curve for subject i
        get_median_time(times_bh, S_i)
      })
      
      # Store predicted time-to-peak and predicted peak year
      test_meta$predicted_time_to_peak_Cox <- pred_time_cox
      test_meta$predicted_peak_year_Cox <- test_meta$first_year + pred_time_cox
      
      # Evaluate on uncensored only
      true_time <- test_meta$time_to_peak[uncensored_idx]
      pred_time <- pred_time_cox[uncensored_idx]
      valid_idx <- !is.na(pred_time) & !is.na(true_time) & is.finite(pred_time)
      
      if(sum(valid_idx) > 5) {
        rmse_cox <- sqrt(mean((true_time[valid_idx] - pred_time[valid_idx])^2))
        mae_cox <- mean(abs(true_time[valid_idx] - pred_time[valid_idx]))
        cat("    [Time] RMSE:", round(rmse_cox, 3), "| MAE:", round(mae_cox, 3), 
            "(n =", sum(valid_idx), "uncensored)\n")
        
        time_pred_performance <- rbind(time_pred_performance, data.frame(
          event_family = ef, model = "Cox", rmse = rmse_cox, mae = mae_cox,
          n_uncensored = sum(valid_idx)
        ))
      }
    }
    rm(cox_train); gc(verbose = FALSE)
  }, error = function(e) cat("    Error:", e$message, "\n"))
  
  # ================== RSF MODEL ==================
  cat("\n  RSF Model:\n")
  tryCatch({
    rsf_train <- rfsrc(
      Surv(time_to_peak, event_status) ~ career_length_scaled + log_n_obs,
      data = train_meta, ntree = 500, importance = FALSE
    )
    
    rsf_pred <- predict(rsf_train, newdata = test_meta)
    
    # PART 1: Hazard-based evaluation
    risk_rsf <- as.numeric(rsf_pred$predicted)
    c_rsf <- compute_cindex(risk_rsf, test_meta$time_to_peak, test_meta$event_status)
    # FIX: higher risk = earlier peak = smaller time, so should be negative correlation
    rho_rsf <- cor(test_meta$time_to_peak, -risk_rsf, method = "spearman")
    
    cat("    [Hazard] C-index:", round(c_rsf, 3), "| Spearman:", round(rho_rsf, 3), "\n")
    
    test_performance <- rbind(test_performance, data.frame(
      event_family = ef, model = "RSF", c_index = c_rsf,
      spearman_rho = rho_rsf, n_test = nrow(test_meta)
    ))
    
    # PART 2: Time-to-peak prediction (uncensored only)
    if(n_uncensored > 10 && !is.null(rsf_pred$survival) && is.matrix(rsf_pred$survival)) {
      times_rsf <- rsf_pred$time.interest
      Surv_mat <- rsf_pred$survival
      
      pred_time_rsf <- apply(Surv_mat, 1, function(S_i) {
        get_median_time(times_rsf, S_i)
      })
      
      # Store predicted time-to-peak and predicted peak year
      test_meta$predicted_time_to_peak_RSF <- pred_time_rsf
      test_meta$predicted_peak_year_RSF <- test_meta$first_year + pred_time_rsf
      
      true_time <- test_meta$time_to_peak[uncensored_idx]
      pred_time <- pred_time_rsf[uncensored_idx]
      valid_idx <- !is.na(pred_time) & !is.na(true_time) & is.finite(pred_time)
      
      if(sum(valid_idx) > 5) {
        rmse_rsf <- sqrt(mean((true_time[valid_idx] - pred_time[valid_idx])^2))
        mae_rsf <- mean(abs(true_time[valid_idx] - pred_time[valid_idx]))
        cat("    [Time] RMSE:", round(rmse_rsf, 3), "| MAE:", round(mae_rsf, 3),
            "(n =", sum(valid_idx), "uncensored)\n")
        
        time_pred_performance <- rbind(time_pred_performance, data.frame(
          event_family = ef, model = "RSF", rmse = rmse_rsf, mae = mae_rsf,
          n_uncensored = sum(valid_idx)
        ))
      }
    }
    rm(rsf_train, rsf_pred); gc(verbose = FALSE)
  }, error = function(e) cat("    Error:", e$message, "\n"))
  
  # ================== FLCM MODEL ==================
  cat("\n  FLCM Model:\n")
  tryCatch({
    # CONVENTION A: Use trapezoid weights w, not scalar L
    w_vec <- make_trap_weights(time_grid_ho)
    
    # Create training long format
    train_long <- data.frame(
      subject_id = rep(seq_len(n_train_subj), each = n_time),
      time_to_peak = rep(train_meta$time_to_peak, each = n_time),
      event_status = rep(train_meta$event_status, each = n_time),
      career_length = rep(train_meta$career_length_scaled, each = n_time),
      log_n_obs = rep(train_meta$log_n_obs, each = n_time),
      s = rep(time_grid_ho, times = n_train_subj),
      W = as.vector(t(train_func)),
      w = rep(w_vec, times = n_train_subj)
    )
    
    # Construct explicit Surv response for Cox-type GAM
    train_long$y <- with(train_long, Surv(time_to_peak, event_status))
    
    # CONVENTION A: by = I(W) WITHOUT L/w in the formula
    flcm_train <- gam(
      y ~ career_length + log_n_obs + 
          s(s, by = I(W), bs = "ps", k = 10, m = 2),
      family = cox.ph(), data = train_long,
      method = "REML"
    )
    
    # Reconstruct subject-level linear predictors (uses w column internally)
    eta_train <- build_eta_from_gam(flcm_train, train_long, weight_col = "w")
    
    # Create subject-level training data for baseline hazard estimation
    subj_train <- train_meta %>%
      mutate(eta = eta_train)
    
    # Fit Cox with offset to get baseline hazard
    cox_flcm <- coxph(Surv(time_to_peak, event_status) ~ offset(eta), data = subj_train)
    bh_flcm <- basehaz(cox_flcm, centered = FALSE)
    rm(train_long); gc(verbose = FALSE)
    
    # Create test long format
    test_long <- data.frame(
      subject_id = rep(seq_len(n_test_subj), each = n_time),
      time_to_peak = rep(test_meta$time_to_peak, each = n_time),
      event_status = rep(test_meta$event_status, each = n_time),
      career_length = rep(test_meta$career_length_scaled, each = n_time),
      log_n_obs = rep(test_meta$log_n_obs, each = n_time),
      s = rep(time_grid_ho, times = n_test_subj),
      W = as.vector(t(test_func)),
      w = rep(w_vec, times = n_test_subj)
    )
    
    # Get test predictions using subject-level reconstruction
    eta_test <- build_eta_from_gam(flcm_train, test_long, weight_col = "w")
    
    # PART 1: Hazard-based evaluation
    # FIX: Use eta directly to avoid exp() overflow; concordance only needs monotonicity
    risk_flcm <- eta_test
    c_flcm <- compute_cindex(risk_flcm, test_meta$time_to_peak, test_meta$event_status)
    # FIX: higher risk = earlier peak = smaller time, so should be negative correlation
    rho_flcm <- cor(test_meta$time_to_peak, -risk_flcm, method = "spearman")
    
    cat("    [Hazard] C-index:", round(c_flcm, 3), "| Spearman:", round(rho_flcm, 3), "\n")
    
    test_performance <- rbind(test_performance, data.frame(
      event_family = ef, model = "FLCM", c_index = c_flcm,
      spearman_rho = rho_flcm, n_test = nrow(test_meta)
    ))
    
    # PART 2: Time-to-peak prediction (uncensored only)
    if(n_uncensored > 10) {
      times_flcm <- bh_flcm$time
      H0_flcm <- bh_flcm$hazard
      
      pred_time_flcm <- sapply(seq_along(eta_test), function(i) {
        S_i <- exp(-H0_flcm * exp(eta_test[i]))
        get_median_time(times_flcm, S_i)
      })
      
      # Store predicted time-to-peak and predicted peak year
      test_meta$predicted_time_to_peak_FLCM <- pred_time_flcm
      test_meta$predicted_peak_year_FLCM <- test_meta$first_year + pred_time_flcm
      
      true_time <- test_meta$time_to_peak[uncensored_idx]
      pred_time <- pred_time_flcm[uncensored_idx]
      valid_idx <- !is.na(pred_time) & !is.na(true_time) & is.finite(pred_time)
      
      if(sum(valid_idx) > 5) {
        rmse_flcm <- sqrt(mean((true_time[valid_idx] - pred_time[valid_idx])^2))
        mae_flcm <- mean(abs(true_time[valid_idx] - pred_time[valid_idx]))
        cat("    [Time] RMSE:", round(rmse_flcm, 3), "| MAE:", round(mae_flcm, 3),
            "(n =", sum(valid_idx), "uncensored)\n")
        
        time_pred_performance <- rbind(time_pred_performance, data.frame(
          event_family = ef, model = "FLCM", rmse = rmse_flcm, mae = mae_flcm,
          n_uncensored = sum(valid_idx)
        ))
      }
    }
    rm(flcm_train, test_long); gc(verbose = FALSE)
  }, error = function(e) cat("    Error:", e$message, "\n"))
  
  # ================== AFCM MODEL ==================
  cat("\n  AFCM Model:\n")
  tryCatch({
    # CONVENTION A: Define w_vec (in case FLCM failed and didn't define it)
    w_vec <- make_trap_weights(time_grid_ho)
    
    train_long <- data.frame(
      subject_id = rep(seq_len(n_train_subj), each = n_time),
      time_to_peak = rep(train_meta$time_to_peak, each = n_time),
      event_status = rep(train_meta$event_status, each = n_time),
      career_length = rep(train_meta$career_length_scaled, each = n_time),
      log_n_obs = rep(train_meta$log_n_obs, each = n_time),
      s = rep(time_grid_ho, times = n_train_subj),
      W = as.vector(t(train_func)),
      w = rep(w_vec, times = n_train_subj)
    )
    
    # Construct explicit Surv response for Cox-type GAM
    train_long$y <- with(train_long, Surv(time_to_peak, event_status))
    
    afcm_train <- gam(
      y ~ career_length + log_n_obs + 
          te(s, W, bs = c("tp", "tp"), k = c(8, 8)),
      family = cox.ph(), data = train_long
    )
    
    # Reconstruct subject-level linear predictors (uses w column internally)
    eta_train <- build_eta_from_gam(afcm_train, train_long, weight_col = "w")
    
    subj_train <- train_meta %>% mutate(eta = eta_train)
    cox_afcm <- coxph(Surv(time_to_peak, event_status) ~ offset(eta), data = subj_train)
    bh_afcm <- basehaz(cox_afcm, centered = FALSE)
    rm(train_long); gc(verbose = FALSE)
    
    test_long <- data.frame(
      subject_id = rep(seq_len(n_test_subj), each = n_time),
      time_to_peak = rep(test_meta$time_to_peak, each = n_time),
      event_status = rep(test_meta$event_status, each = n_time),
      career_length = rep(test_meta$career_length_scaled, each = n_time),
      log_n_obs = rep(test_meta$log_n_obs, each = n_time),
      s = rep(time_grid_ho, times = n_test_subj),
      W = as.vector(t(test_func)),
      w = rep(w_vec, times = n_test_subj)
    )
    
    # Get test predictions using subject-level reconstruction
    eta_test <- build_eta_from_gam(afcm_train, test_long, weight_col = "w")
    
    # PART 1: Hazard-based evaluation
    # FIX: Use eta directly to avoid exp() overflow; concordance only needs monotonicity
    risk_afcm <- eta_test
    c_afcm <- compute_cindex(risk_afcm, test_meta$time_to_peak, test_meta$event_status)
    # FIX: higher risk = earlier peak = smaller time, so should be negative correlation
    rho_afcm <- cor(test_meta$time_to_peak, -risk_afcm, method = "spearman")
    
    cat("    [Hazard] C-index:", round(c_afcm, 3), "| Spearman:", round(rho_afcm, 3), "\n")
    
    test_performance <- rbind(test_performance, data.frame(
      event_family = ef, model = "AFCM", c_index = c_afcm,
      spearman_rho = rho_afcm, n_test = nrow(test_meta)
    ))
    
    # PART 2: Time-to-peak prediction (uncensored only)
    if(n_uncensored > 10) {
      times_afcm <- bh_afcm$time
      H0_afcm <- bh_afcm$hazard
      
      pred_time_afcm <- sapply(seq_along(eta_test), function(i) {
        S_i <- exp(-H0_afcm * exp(eta_test[i]))
        get_median_time(times_afcm, S_i)
      })
      
      # Store predicted time-to-peak and predicted peak year
      test_meta$predicted_time_to_peak_AFCM <- pred_time_afcm
      test_meta$predicted_peak_year_AFCM <- test_meta$first_year + pred_time_afcm
      
      true_time <- test_meta$time_to_peak[uncensored_idx]
      pred_time <- pred_time_afcm[uncensored_idx]
      valid_idx <- !is.na(pred_time) & !is.na(true_time) & is.finite(pred_time)
      
      if(sum(valid_idx) > 5) {
        rmse_afcm <- sqrt(mean((true_time[valid_idx] - pred_time[valid_idx])^2))
        mae_afcm <- mean(abs(true_time[valid_idx] - pred_time[valid_idx]))
        cat("    [Time] RMSE:", round(rmse_afcm, 3), "| MAE:", round(mae_afcm, 3),
            "(n =", sum(valid_idx), "uncensored)\n")
        
        time_pred_performance <- rbind(time_pred_performance, data.frame(
          event_family = ef, model = "AFCM", rmse = rmse_afcm, mae = mae_afcm,
          n_uncensored = sum(valid_idx)
        ))
      }
    }
    rm(afcm_train, test_long); gc(verbose = FALSE)
  }, error = function(e) cat("    Error:", e$message, "\n"))
  
  # Clean up
  rm(train_meta, test_meta); gc(verbose = FALSE)
  cat("\n")
}

cat("\n=== PART 1: HAZARD-BASED EVALUATION (All Test Subjects) ===\n")
cat("Metrics: C-index, Spearman correlation\n\n")
print(test_performance)

cat("\n=== PART 2: TIME-TO-PEAK PREDICTION (Uncensored Only) ===\n")
cat("Metrics: RMSE, MAE (in years)\n")
cat("Note: Evaluated ONLY on retired athletes where true peak time is known\n\n")
print(time_pred_performance)

cat("\n\n")
cat("=" %>% rep(70) %>% paste(collapse = ""), "\n")
cat("PART 3: CALIBRATED TIME-TO-PEAK PREDICTION\n")
cat("=" %>% rep(70) %>% paste(collapse = ""), "\n")
cat("Purpose: Map risk scores → time predictions via GAM calibration\n")
cat("Method: On training uncensored, fit time_to_peak ~ s(risk, k=5)\n")
cat("        Apply calibration to test uncensored for final RMSE/MAE\n")
cat("=" %>% rep(70) %>% paste(collapse = ""), "\n\n")

# Storage for calibrated performance
calibrated_performance <- data.frame()

for(ef in event_families) {
  cat("Event Family:", ef, "\n")
  
  ho_data <- holdout_results[[ef]]
  meta <- ho_data$metadata
  funcmat <- as.matrix(ho_data$func_matrix)
  train_idx <- ho_data$train_idx
  test_idx <- ho_data$test_idx
  time_grid_ho <- ho_data$time_grid
  
  rownames(meta) <- NULL
  
  cl_mean <- mean(meta$career_length[train_idx], na.rm = TRUE)
  cl_sd <- sd(meta$career_length[train_idx], na.rm = TRUE)
  if(is.na(cl_sd) || cl_sd == 0) cl_sd <- 1
  
  train_meta <- meta[train_idx, , drop = FALSE] %>% mutate(
    career_length_scaled = (career_length - cl_mean) / cl_sd,
    log_n_obs = log(n_observations)
  )
  test_meta <- meta[test_idx, , drop = FALSE] %>% mutate(
    career_length_scaled = (career_length - cl_mean) / cl_sd,
    log_n_obs = log(n_observations)
  )
  
  # Uncensored indices
  train_uncensored_idx <- which(train_meta$event_status == 1)
  test_uncensored_idx <- which(test_meta$event_status == 1)
  
  if(length(train_uncensored_idx) < 20 || length(test_uncensored_idx) < 10) {
    cat("  Skipping - insufficient uncensored data\n\n")
    next
  }
  
  n_time <- ncol(funcmat)
  train_func <- funcmat[train_idx, , drop = FALSE]
  test_func <- funcmat[test_idx, , drop = FALSE]
  n_train_subj <- nrow(train_meta)
  n_test_subj <- nrow(test_meta)
  
  cat("  Train uncensored:", length(train_uncensored_idx), 
      "| Test uncensored:", length(test_uncensored_idx), "\n\n")
  
  # ============== COX MODEL ==============
  tryCatch({
    cat("  Cox: ")
    cox_train <- coxph(
      Surv(time_to_peak, event_status) ~ career_length_scaled + log_n_obs,
      data = train_meta
    )
    
    # Risk scores
    risk_train <- predict(cox_train, newdata = train_meta, type = "risk")
    risk_test <- predict(cox_train, newdata = test_meta, type = "risk")
    
    # Calibration: fit on training uncensored
    calib_data_train <- data.frame(
      risk = risk_train[train_uncensored_idx],
      time_to_peak = train_meta$time_to_peak[train_uncensored_idx]
    )
    
    calib_gam <- gam(time_to_peak ~ s(risk, k = 5), data = calib_data_train)
    
    # Apply to test uncensored
    calib_data_test <- data.frame(risk = risk_test[test_uncensored_idx])
    pred_time_calibrated <- predict(calib_gam, newdata = calib_data_test)
    true_time <- test_meta$time_to_peak[test_uncensored_idx]
    
    valid_idx <- !is.na(pred_time_calibrated) & !is.na(true_time) & is.finite(pred_time_calibrated)
    
    if(sum(valid_idx) > 5) {
      rmse <- sqrt(mean((true_time[valid_idx] - pred_time_calibrated[valid_idx])^2))
      mae <- mean(abs(true_time[valid_idx] - pred_time_calibrated[valid_idx]))
      cat("RMSE =", round(rmse, 3), "| MAE =", round(mae, 3), "\n")
      
      calibrated_performance <- rbind(calibrated_performance, data.frame(
        event_family = ef, model = "Cox", rmse = rmse, mae = mae,
        n_uncensored = sum(valid_idx)
      ))
    }
  }, error = function(e) cat("Error:", e$message, "\n"))
  
  # ============== RSF MODEL ==============
  tryCatch({
    cat("  RSF: ")
    rsf_train <- rfsrc(
      Surv(time_to_peak, event_status) ~ career_length_scaled + log_n_obs,
      data = train_meta, ntree = 500, importance = FALSE
    )
    
    # Risk scores (mortality)
    risk_train <- rsf_train$predicted
    rsf_pred_test <- predict(rsf_train, newdata = test_meta)
    risk_test <- rsf_pred_test$predicted
    
    # Calibration
    calib_data_train <- data.frame(
      risk = risk_train[train_uncensored_idx],
      time_to_peak = train_meta$time_to_peak[train_uncensored_idx]
    )
    
    calib_gam <- gam(time_to_peak ~ s(risk, k = 5), data = calib_data_train)
    
    calib_data_test <- data.frame(risk = risk_test[test_uncensored_idx])
    pred_time_calibrated <- predict(calib_gam, newdata = calib_data_test)
    true_time <- test_meta$time_to_peak[test_uncensored_idx]
    
    valid_idx <- !is.na(pred_time_calibrated) & !is.na(true_time) & is.finite(pred_time_calibrated)
    
    if(sum(valid_idx) > 5) {
      rmse <- sqrt(mean((true_time[valid_idx] - pred_time_calibrated[valid_idx])^2))
      mae <- mean(abs(true_time[valid_idx] - pred_time_calibrated[valid_idx]))
      cat("RMSE =", round(rmse, 3), "| MAE =", round(mae, 3), "\n")
      
      calibrated_performance <- rbind(calibrated_performance, data.frame(
        event_family = ef, model = "RSF", rmse = rmse, mae = mae,
        n_uncensored = sum(valid_idx)
      ))
    }
  }, error = function(e) cat("Error:", e$message, "\n"))
  
  # ============== FLCM MODEL ==============
  tryCatch({
    cat("  FLCM: ")
    # CONVENTION A: trapezoid weights
    w_vec <- make_trap_weights(time_grid_ho)
    
    train_long <- data.frame(
      subject_id = rep(seq_len(n_train_subj), each = n_time),
      time_to_peak = rep(train_meta$time_to_peak, each = n_time),
      event_status = rep(train_meta$event_status, each = n_time),
      career_length = rep(train_meta$career_length_scaled, each = n_time),
      log_n_obs = rep(train_meta$log_n_obs, each = n_time),
      s = rep(time_grid_ho, times = n_train_subj),
      W = as.vector(t(train_func)),
      w = rep(w_vec, times = n_train_subj)
    )
    train_long$y <- with(train_long, Surv(time_to_peak, event_status))
    
    flcm_train <- gam(
      y ~ career_length + log_n_obs + 
          s(s, by = I(W), bs = "ps", k = 10, m = 2),
      family = cox.ph(), data = train_long, method = "REML"
    )
    
    eta_train <- build_eta_from_gam(flcm_train, train_long, weight_col = "w")
    
    test_long <- data.frame(
      subject_id = rep(seq_len(n_test_subj), each = n_time),
      time_to_peak = rep(test_meta$time_to_peak, each = n_time),
      event_status = rep(test_meta$event_status, each = n_time),
      career_length = rep(test_meta$career_length_scaled, each = n_time),
      log_n_obs = rep(test_meta$log_n_obs, each = n_time),
      s = rep(time_grid_ho, times = n_test_subj),
      W = as.vector(t(test_func)),
      w = rep(w_vec, times = n_test_subj)
    )
    
    eta_test <- build_eta_from_gam(flcm_train, test_long, weight_col = "w")
    
    # FIX: Use eta (log-risk) directly for calibration to avoid numerical overflow
    # exp(eta) can explode when functional effects sum to large values
    eta_train_subj <- eta_train[train_uncensored_idx]
    eta_test_subj <- eta_test[test_uncensored_idx]
    
    # Calibration using log-risk (eta) instead of risk
    calib_data_train <- data.frame(
      eta = eta_train_subj,
      time_to_peak = train_meta$time_to_peak[train_uncensored_idx]
    )
    
    calib_gam <- gam(time_to_peak ~ s(eta, k = 5), data = calib_data_train)
    
    calib_data_test <- data.frame(eta = eta_test_subj)
    pred_time_calibrated <- predict(calib_gam, newdata = calib_data_test)
    true_time <- test_meta$time_to_peak[test_uncensored_idx]
    
    valid_idx <- !is.na(pred_time_calibrated) & !is.na(true_time) & is.finite(pred_time_calibrated)
    
    if(sum(valid_idx) > 5) {
      rmse <- sqrt(mean((true_time[valid_idx] - pred_time_calibrated[valid_idx])^2))
      mae <- mean(abs(true_time[valid_idx] - pred_time_calibrated[valid_idx]))
      cat("RMSE =", round(rmse, 3), "| MAE =", round(mae, 3), "\n")
      
      calibrated_performance <- rbind(calibrated_performance, data.frame(
        event_family = ef, model = "FLCM", rmse = rmse, mae = mae,
        n_uncensored = sum(valid_idx)
      ))
    }
  }, error = function(e) cat("Error:", e$message, "\n"))
  
  # ============== AFCM MODEL ==============
  tryCatch({
    cat("  AFCM: ")
    # CONVENTION A: Define w_vec (in case FLCM failed and didn't define it)
    w_vec <- make_trap_weights(time_grid_ho)
    
    train_long <- data.frame(
      subject_id = rep(seq_len(n_train_subj), each = n_time),
      time_to_peak = rep(train_meta$time_to_peak, each = n_time),
      event_status = rep(train_meta$event_status, each = n_time),
      career_length = rep(train_meta$career_length_scaled, each = n_time),
      log_n_obs = rep(train_meta$log_n_obs, each = n_time),
      s = rep(time_grid_ho, times = n_train_subj),
      W = as.vector(t(train_func)),
      w = rep(w_vec, times = n_train_subj)
    )
    train_long$y <- with(train_long, Surv(time_to_peak, event_status))
    
    afcm_train <- gam(
      y ~ career_length + log_n_obs + 
          te(s, W, bs = c("tp", "tp"), k = c(8, 8)),
      family = cox.ph(), data = train_long
    )
    
    eta_train <- build_eta_from_gam(afcm_train, train_long, weight_col = "w")
    
    test_long <- data.frame(
      subject_id = rep(seq_len(n_test_subj), each = n_time),
      time_to_peak = rep(test_meta$time_to_peak, each = n_time),
      event_status = rep(test_meta$event_status, each = n_time),
      career_length = rep(test_meta$career_length_scaled, each = n_time),
      log_n_obs = rep(test_meta$log_n_obs, each = n_time),
      s = rep(time_grid_ho, times = n_test_subj),
      W = as.vector(t(test_func)),
      w = rep(w_vec, times = n_test_subj)
    )
    
    eta_test <- build_eta_from_gam(afcm_train, test_long, weight_col = "w")
    
    # FIX: Use eta (log-risk) directly for calibration to avoid numerical overflow
    # exp(eta) can explode when tensor product effects sum to large values
    eta_train_subj <- eta_train[train_uncensored_idx]
    eta_test_subj <- eta_test[test_uncensored_idx]
    
    # Calibration using log-risk (eta) instead of risk
    calib_data_train <- data.frame(
      eta = eta_train_subj,
      time_to_peak = train_meta$time_to_peak[train_uncensored_idx]
    )
    
    calib_gam <- gam(time_to_peak ~ s(eta, k = 5), data = calib_data_train)
    
    calib_data_test <- data.frame(eta = eta_test_subj)
    pred_time_calibrated <- predict(calib_gam, newdata = calib_data_test)
    true_time <- test_meta$time_to_peak[test_uncensored_idx]
    
    valid_idx <- !is.na(pred_time_calibrated) & !is.na(true_time) & is.finite(pred_time_calibrated)
    
    if(sum(valid_idx) > 5) {
      rmse <- sqrt(mean((true_time[valid_idx] - pred_time_calibrated[valid_idx])^2))
      mae <- mean(abs(true_time[valid_idx] - pred_time_calibrated[valid_idx]))
      cat("RMSE =", round(rmse, 3), "| MAE =", round(mae, 3), "\n")
      
      calibrated_performance <- rbind(calibrated_performance, data.frame(
        event_family = ef, model = "AFCM", rmse = rmse, mae = mae,
        n_uncensored = sum(valid_idx)
      ))
    }
  }, error = function(e) cat("Error:", e$message, "\n"))
  
  cat("\n")
}

cat("\n=== CALIBRATED TIME-TO-PEAK PERFORMANCE ===\n")
cat("Method: Risk/log-risk mapped to time via GAM(time ~ s(risk, k=5))\n")
cat("Note: FLCM/AFCM use eta (log-risk) to avoid numerical overflow\n\n")
print(calibrated_performance)

cat("\n--- Mean Calibrated Performance by Model ---\n")
calibrated_summary <- calibrated_performance %>%
  group_by(model) %>%
  summarise(
    mean_rmse = mean(rmse, na.rm = TRUE),
    mean_mae = mean(mae, na.rm = TRUE),
    .groups = "drop"
  ) %>%
  arrange(mean_rmse)

print(calibrated_summary)
```

---

## Diagnostic: Naive Baseline for Time-to-Peak Prediction

**Purpose**: Establish whether complex models beat simple mean/median predictors.  
**For manuscript**: Demonstrates that models provide value beyond constant prediction.

```{r naive-baseline-diagnostics}
cat("\n=== NAIVE BASELINE DIAGNOSTICS ===\n")
cat("Computing RMSE/MAE for always predicting mean or median time-to-peak\n\n")

baseline_performance <- data.frame()

for(ef in event_families) {
  ho_data <- holdout_results[[ef]]
  meta <- ho_data$metadata
  train_idx <- ho_data$train_idx
  test_idx <- ho_data$test_idx
  
  # Training set: uncensored only
  train_uncensored <- meta[train_idx, ] %>% filter(event_status == 1)
  mean_time_train <- mean(train_uncensored$time_to_peak, na.rm = TRUE)
  median_time_train <- median(train_uncensored$time_to_peak, na.rm = TRUE)
  
  # Test set: uncensored only
  test_uncensored <- meta[test_idx, ] %>% filter(event_status == 1)
  true_time <- test_uncensored$time_to_peak
  
  if(length(true_time) > 5) {
    # Baseline 1: Always predict mean
    rmse_mean <- sqrt(mean((true_time - mean_time_train)^2))
    mae_mean <- mean(abs(true_time - mean_time_train))
    
    # Baseline 2: Always predict median
    rmse_median <- sqrt(mean((true_time - median_time_train)^2))
    mae_median <- mean(abs(true_time - median_time_train))
    
    baseline_performance <- rbind(baseline_performance, data.frame(
      event_family = ef,
      model = c("Baseline_Mean", "Baseline_Median"),
      rmse = c(rmse_mean, rmse_median),
      mae = c(mae_mean, mae_median),
      n_uncensored = length(true_time)
    ))
    
    cat("Event Family:", ef, "\n")
    cat("  Training mean:", round(mean_time_train, 2), "| median:", round(median_time_train, 2), "\n")
    cat("  Baseline (mean): RMSE =", round(rmse_mean, 3), "| MAE =", round(mae_mean, 3), "\n")
    cat("  Baseline (median): RMSE =", round(rmse_median, 3), "| MAE =", round(mae_median, 3), "\n\n")
  }
}

cat("\n=== BASELINE PERFORMANCE SUMMARY ===\n")
print(baseline_performance)

cat("\n--- Mean Baseline Performance ---\n")
baseline_summary <- baseline_performance %>%
  group_by(model) %>%
  summarise(
    mean_rmse = mean(rmse, na.rm = TRUE),
    mean_mae = mean(mae, na.rm = TRUE),
    .groups = "drop"
  )
print(baseline_summary)
```

---

## Diagnostic: Model vs Baseline Comparison

**Purpose**: Compare calibrated models to naive baselines.  
**For manuscript**: Table showing model improvement over simple mean/median predictors.

```{r model-baseline-comparison}
cat("\n=== CALIBRATED MODEL vs BASELINE COMPARISON ===\n")
cat("Note: Using CALIBRATED predictions (risk → time via GAM)\n\n")

# Combine calibrated model performance with baseline
all_performance_calibrated <- rbind(
  calibrated_performance %>% select(event_family, model, rmse, mae, n_uncensored),
  baseline_performance
)

# Pivot to wide format for easy comparison
comparison_table_cal <- all_performance_calibrated %>%
  select(event_family, model, rmse) %>%
  pivot_wider(names_from = model, values_from = rmse) %>%
  arrange(event_family)

cat("RMSE Comparison - CALIBRATED (Lower = Better):\n")
print(comparison_table_cal)

cat("\n--- Mean RMSE: Calibrated Models vs Baseline ---\n")
mean_comparison_cal <- all_performance_calibrated %>%
  group_by(model) %>%
  summarise(
    mean_rmse = mean(rmse, na.rm = TRUE),
    mean_mae = mean(mae, na.rm = TRUE),
    .groups = "drop"
  ) %>%
  arrange(mean_rmse)

print(mean_comparison_cal)

# Identify if any model beats baseline
cat("\n--- Calibrated Models That Beat Baseline (Mean) ---\n")
baseline_mean_rmse <- mean_comparison_cal %>% 
  filter(model == "Baseline_Mean") %>% 
  pull(mean_rmse)

cat("Baseline Mean RMSE:", round(baseline_mean_rmse, 3), "\n\n")

better_than_baseline_cal <- mean_comparison_cal %>%
  filter(mean_rmse < baseline_mean_rmse, model != "Baseline_Mean", model != "Baseline_Median")

if(nrow(better_than_baseline_cal) > 0) {
  cat("These models beat naive baseline:\n")
  for(i in 1:nrow(better_than_baseline_cal)) {
    improvement <- (baseline_mean_rmse - better_than_baseline_cal$mean_rmse[i]) / baseline_mean_rmse * 100
    cat(sprintf("  %s: RMSE = %.3f (%.1f%% improvement)\n", 
                better_than_baseline_cal$model[i], 
                better_than_baseline_cal$mean_rmse[i],
                improvement))
  }
} else {
  cat("Note: No models beat the naive baseline even after calibration.\n")
}

cat("\n\n=== COMPARISON: UNCALIBRATED vs CALIBRATED ===\n\n")

cat("Before Calibration (direct median survival):\n")
uncalib_summary <- time_pred_performance %>%
  group_by(model) %>%
  summarise(mean_rmse = mean(rmse, na.rm = TRUE), .groups = "drop") %>%
  arrange(model)
print(uncalib_summary)

cat("\nAfter Calibration (GAM: risk → time):\n")
calib_summary <- calibrated_performance %>%
  group_by(model) %>%
  summarise(mean_rmse = mean(rmse, na.rm = TRUE), .groups = "drop") %>%
  arrange(model)
print(calib_summary)

cat("\nImprovement from Calibration:\n")
improvement_df <- merge(
  uncalib_summary %>% rename(rmse_uncalib = mean_rmse),
  calib_summary %>% rename(rmse_calib = mean_rmse),
  by = "model"
) %>%
  mutate(
    improvement = rmse_uncalib - rmse_calib,
    pct_improvement = (improvement / rmse_uncalib) * 100
  ) %>%
  arrange(desc(pct_improvement))

print(improvement_df)

# Create calibrated_summary_with_improvement for table export
cat("\n--- Calibrated Summary with Improvement Percentages (for Table 4) ---\n")
calibrated_summary_with_improvement <- mean_comparison_cal %>%
  mutate(
    improvement_pct = ifelse(model %in% c("Baseline_Mean", "Baseline_Median"), 
                             NA, 
                             round((baseline_mean_rmse - mean_rmse) / baseline_mean_rmse * 100, 1))
  )

print(calibrated_summary_with_improvement)
```

## Export Table 4 for Manuscript

```{r export-table4-for-manuscript}
# Export Table 4: Calibrated Summary with Baseline Comparison
if (exists("calibrated_summary_with_improvement") && nrow(calibrated_summary_with_improvement) > 0) {
  # Format the table nicely with column names for manuscript
  table4_formatted <- calibrated_summary_with_improvement %>%
    mutate(
      Model = model,
      `RMSE (years)` = round(mean_rmse, 3),
      `MAE (years)` = round(mean_mae, 3),
      `Improvement (%)` = ifelse(is.na(improvement_pct), "—", as.character(improvement_pct))
    ) %>%
    select(Model, `RMSE (years)`, `MAE (years)`, `Improvement (%)`)
  
  export_table(table4_formatted, 
               "table4_calibrated_summary",
               "Mean Calibrated Performance by Model (vs. Naive Baseline)")
  
  cat("\n✓ Table 4 exported to output/tables/table4_calibrated_summary.pdf\n")
} else {
  cat("\nWarning: calibrated_summary_with_improvement not found, table4 not exported\n")
}
```

---

## Diagnostic: Scatter Plots of Predicted vs Actual Time-to-Peak

**Purpose**: Visual inspection of model calibration - do models have any predictive slope?  
**For manuscript**: Figure showing prediction quality for each model on uncensored test athletes.

**Note**: This chunk re-fits models to extract individual predictions for plotting.  
The performance metrics above use the same methodology.

```{r predicted-vs-actual-scatter, fig.height=16, fig.width=14, cache=TRUE}
cat("\n=== GENERATING PREDICTED vs ACTUAL SCATTER PLOTS ===\n")
cat("Re-fitting models to extract subject-level predictions for visualization\n\n")
cat("NOTE: This chunk refits all 4 models across all event families.\n")
cat("      It may take 5-10 minutes. Results are cached.\n")
cat("      Set cache=TRUE in chunk options to avoid re-running on every knit.\n\n")

library(ggplot2)
library(patchwork)

plot_data_all <- data.frame()

for(ef in event_families) {
  cat("Processing:", ef, "\n")
  
  ho_data <- holdout_results[[ef]]
  meta <- ho_data$metadata
  funcmat <- as.matrix(ho_data$func_matrix)
  train_idx <- ho_data$train_idx
  test_idx <- ho_data$test_idx
  time_grid_ho <- ho_data$time_grid
  
  rownames(meta) <- NULL
  
  cl_mean <- mean(meta$career_length[train_idx], na.rm = TRUE)
  cl_sd <- sd(meta$career_length[train_idx], na.rm = TRUE)
  if(is.na(cl_sd) || cl_sd == 0) cl_sd <- 1
  
  train_meta <- meta[train_idx, , drop = FALSE] %>% mutate(
    career_length_scaled = (career_length - cl_mean) / cl_sd,
    log_n_obs = log(n_observations)
  )
  test_meta <- meta[test_idx, , drop = FALSE] %>% mutate(
    career_length_scaled = (career_length - cl_mean) / cl_sd,
    log_n_obs = log(n_observations)
  )
  
  # Filter uncensored test subjects
  uncensored_idx <- which(test_meta$event_status == 1)
  
  if(length(uncensored_idx) < 10) next
  
  n_time <- ncol(funcmat)
  train_func <- funcmat[train_idx, , drop = FALSE]
  test_func <- funcmat[test_idx, , drop = FALSE]
  n_train_subj <- nrow(train_meta)
  n_test_subj <- nrow(test_meta)
  
  # Get training mean/median for baseline
  train_uncensored <- train_meta %>% filter(event_status == 1)
  mean_time_train <- mean(train_uncensored$time_to_peak)
  median_time_train <- median(train_uncensored$time_to_peak)
  
  # Initialize predictions storage with NA columns for all models
  # CRITICAL FIX: Pre-allocate all columns to prevent pivot_longer errors
  pred_df <- data.frame(
    subject_id = test_meta$athlete_id[uncensored_idx],
    event_family = ef,
    true_time = test_meta$time_to_peak[uncensored_idx],
    baseline_mean = mean_time_train,
    baseline_median = median_time_train,
    Cox = NA_real_,
    RSF = NA_real_,
    FLCM = NA_real_,
    AFCM = NA_real_
  )
  
  # === Cox Model ===
  tryCatch({
    cox_train <- coxph(
      Surv(time_to_peak, event_status) ~ career_length_scaled + log_n_obs,
      data = train_meta
    )
    bh <- basehaz(cox_train, centered = FALSE)
    lp_test <- predict(cox_train, newdata = test_meta, type = "lp")
    
    pred_time_cox <- sapply(seq_along(lp_test), function(i) {
      S_i <- exp(-bh$hazard * exp(lp_test[i]))
      get_median_time(bh$time, S_i)
    })
    
    pred_df$Cox <- pred_time_cox[uncensored_idx]
  }, error = function(e) {})
  
  # === RSF Model ===
  tryCatch({
    rsf_train <- rfsrc(
      Surv(time_to_peak, event_status) ~ career_length_scaled + log_n_obs,
      data = train_meta, ntree = 500, importance = FALSE
    )
    rsf_pred <- predict(rsf_train, newdata = test_meta)
    
    if(!is.null(rsf_pred$survival) && is.matrix(rsf_pred$survival)) {
      pred_time_rsf <- apply(rsf_pred$survival, 1, function(S_i) {
        get_median_time(rsf_pred$time.interest, S_i)
      })
      pred_df$RSF <- pred_time_rsf[uncensored_idx]
    }
  }, error = function(e) {})
  
  # === FLCM Model ===
  tryCatch({
    # CONVENTION A FIX: Use trapezoid weights w, not scalar L
    w_vec <- make_trap_weights(time_grid_ho)
    
    train_long <- data.frame(
      subject_id = rep(seq_len(n_train_subj), each = n_time),
      time_to_peak = rep(train_meta$time_to_peak, each = n_time),
      event_status = rep(train_meta$event_status, each = n_time),
      career_length = rep(train_meta$career_length_scaled, each = n_time),
      log_n_obs = rep(train_meta$log_n_obs, each = n_time),
      s = rep(time_grid_ho, times = n_train_subj),
      W = as.vector(t(train_func)),
      w = rep(w_vec, times = n_train_subj)
    )
    train_long$y <- with(train_long, Surv(time_to_peak, event_status))
    
    flcm_train <- gam(
      y ~ career_length + log_n_obs + 
          s(s, by = I(W), bs = "ps", k = 10, m = 2),
      family = cox.ph(), data = train_long, method = "REML"
    )
    
    eta_train <- build_eta_from_gam(flcm_train, train_long, weight_col = "w")
    subj_train <- train_meta %>% mutate(eta = eta_train)
    cox_flcm <- coxph(Surv(time_to_peak, event_status) ~ offset(eta), data = subj_train)
    bh_flcm <- basehaz(cox_flcm, centered = FALSE)
    
    test_long <- data.frame(
      subject_id = rep(seq_len(n_test_subj), each = n_time),
      time_to_peak = rep(test_meta$time_to_peak, each = n_time),
      event_status = rep(test_meta$event_status, each = n_time),
      career_length = rep(test_meta$career_length_scaled, each = n_time),
      log_n_obs = rep(test_meta$log_n_obs, each = n_time),
      s = rep(time_grid_ho, times = n_test_subj),
      W = as.vector(t(test_func)),
      w = rep(w_vec, times = n_test_subj)
    )
    
    eta_test <- build_eta_from_gam(flcm_train, test_long, weight_col = "w")
    
    pred_time_flcm <- sapply(seq_along(eta_test), function(i) {
      S_i <- exp(-bh_flcm$hazard * exp(eta_test[i]))
      get_median_time(bh_flcm$time, S_i)
    })
    
    pred_df$FLCM <- pred_time_flcm[uncensored_idx]
  }, error = function(e) {})
  
  # === AFCM Model ===
  tryCatch({
    # CONVENTION A FIX: Use same w_vec (already defined for FLCM)
    train_long <- data.frame(
      subject_id = rep(seq_len(n_train_subj), each = n_time),
      time_to_peak = rep(train_meta$time_to_peak, each = n_time),
      event_status = rep(train_meta$event_status, each = n_time),
      career_length = rep(train_meta$career_length_scaled, each = n_time),
      log_n_obs = rep(train_meta$log_n_obs, each = n_time),
      s = rep(time_grid_ho, times = n_train_subj),
      W = as.vector(t(train_func)),
      w = rep(w_vec, times = n_train_subj)
    )
    train_long$y <- with(train_long, Surv(time_to_peak, event_status))
    
    afcm_train <- gam(
      y ~ career_length + log_n_obs + 
          te(s, W, bs = c("tp", "tp"), k = c(8, 8)),
      family = cox.ph(), data = train_long
    )
    
    eta_train <- build_eta_from_gam(afcm_train, train_long, weight_col = "w")
    subj_train <- train_meta %>% mutate(eta = eta_train)
    cox_afcm <- coxph(Surv(time_to_peak, event_status) ~ offset(eta), data = subj_train)
    bh_afcm <- basehaz(cox_afcm, centered = FALSE)
    
    test_long <- data.frame(
      subject_id = rep(seq_len(n_test_subj), each = n_time),
      time_to_peak = rep(test_meta$time_to_peak, each = n_time),
      event_status = rep(test_meta$event_status, each = n_time),
      career_length = rep(test_meta$career_length_scaled, each = n_time),
      log_n_obs = rep(test_meta$log_n_obs, each = n_time),
      s = rep(time_grid_ho, times = n_test_subj),
      W = as.vector(t(test_func)),
      w = rep(w_vec, times = n_test_subj)
    )
    
    eta_test <- build_eta_from_gam(afcm_train, test_long, weight_col = "w")
    
    pred_time_afcm <- sapply(seq_along(eta_test), function(i) {
      S_i <- exp(-bh_afcm$hazard * exp(eta_test[i]))
      get_median_time(bh_afcm$time, S_i)
    })
    
    pred_df$AFCM <- pred_time_afcm[uncensored_idx]
  }, error = function(e) {})
  
  plot_data_all <- rbind(plot_data_all, pred_df)
}

cat("\nPredictions extracted for all event families\n")
cat("Creating scatter plots...\n\n")

# Reshape for plotting
plot_data_long <- plot_data_all %>%
  pivot_longer(
    cols = c(baseline_mean, baseline_median, Cox, RSF, FLCM, AFCM),
    names_to = "model",
    values_to = "predicted_time"
  ) %>%
  filter(!is.na(predicted_time) & is.finite(predicted_time))

# Create scatter plots
p_scatter <- ggplot(plot_data_long, aes(x = true_time, y = predicted_time)) +
  geom_abline(intercept = 0, slope = 1, linetype = "dashed", color = "red", size = 1) +
  geom_point(alpha = 0.4, size = 1.5) +
  geom_smooth(method = "lm", se = FALSE, color = "blue", size = 0.8) +
  facet_grid(model ~ event_family, scales = "free") +
  labs(
    title = "Predicted vs Actual Time-to-Peak (Test Set, Uncensored Only)",
    subtitle = "Red dashed = perfect prediction | Blue = linear fit | Points = individual athletes",
    x = "True Time-to-Peak (years)",
    y = "Predicted Time-to-Peak (years)"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(face = "bold", size = 14),
    strip.text = element_text(face = "bold", size = 10)
  )

print(p_scatter)

# Compute correlation for each model-family combination
cat("\n=== CORRELATION: Predicted vs Actual ===\n")
correlations <- plot_data_long %>%
  group_by(event_family, model) %>%
  summarise(
    correlation = cor(true_time, predicted_time, use = "complete.obs"),
    n = n(),
    .groups = "drop"
  ) %>%
  arrange(event_family, model)

print(correlations)

cat("\n--- Mean Correlation by Model ---\n")
mean_cor <- correlations %>%
  group_by(model) %>%
  summarise(mean_cor = mean(correlation, na.rm = TRUE), .groups = "drop") %>%
  arrange(desc(mean_cor))

print(mean_cor)

cat("\nINTERPRETATION:\n")
cat("- High correlation (close to 1): Model predictions track true values\n")
cat("- Low correlation (close to 0): Model predictions are nearly constant\n")
cat("- If functional models have low correlation, they're not using trajectory info effectively\n")
```

## Visualize Test Set Performance

```{r test-performance-viz, fig.height=12}
# Create comparison plots for both evaluations

if(nrow(test_performance) == 0) {
  cat("No test performance results to visualize.\n")
} else {

# ===== PART 1: Hazard-Based Metrics (All Athletes) =====

# 1. C-index (PRIMARY METRIC)
p1 <- ggplot(test_performance, aes(x = event_family, y = c_index, fill = model)) +
  geom_col(position = position_dodge(width = 0.8), width = 0.7) +
  geom_hline(yintercept = 0.5, linetype = "dashed", color = "gray50") +
  scale_fill_brewer(palette = "Set2") +
  labs(
    title = "PART 1: C-index (All Athletes)",
    subtitle = "Model discrimination | Higher = better | 0.5 = random",
    x = "Event Family", y = "C-index", fill = "Model"
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1),
        legend.position = "bottom", plot.title = element_text(face = "bold")) +
  coord_cartesian(ylim = c(0, 1))

# 2. Spearman Correlation
p2 <- ggplot(test_performance, aes(x = event_family, y = spearman_rho, fill = model)) +
  geom_col(position = position_dodge(width = 0.8), width = 0.7) +
  geom_hline(yintercept = 0, linetype = "dashed", color = "gray50") +
  scale_fill_brewer(palette = "Set2") +
  labs(
    title = "PART 1: Spearman Correlation (All Athletes)",
    subtitle = "Rank correlation | Higher = better",
    x = "Event Family", y = "Spearman rho", fill = "Model"
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1),
        legend.position = "bottom", plot.title = element_text(face = "bold"))

# ===== PART 2: Time-to-Peak Metrics (Uncensored Only) =====

if(nrow(calibrated_performance) > 0) {
  # 3. RMSE (using calibrated predictions)
  p3 <- ggplot(calibrated_performance, aes(x = event_family, y = rmse, fill = model)) +
    geom_col(position = position_dodge(width = 0.8), width = 0.7) +
    scale_fill_brewer(palette = "Set2") +
    labs(
      title = "PART 2: RMSE (Uncensored Athletes Only) - Calibrated",
      subtitle = "Time-to-peak prediction error after GAM calibration | Lower = better",
      x = "Event Family", y = "RMSE (years)", fill = "Model"
    ) +
    theme_minimal() +
    theme(axis.text.x = element_text(angle = 45, hjust = 1),
          legend.position = "bottom", plot.title = element_text(face = "bold"))
  
  # 4. MAE (using calibrated predictions)
  p4 <- ggplot(calibrated_performance, aes(x = event_family, y = mae, fill = model)) +
    geom_col(position = position_dodge(width = 0.8), width = 0.7) +
    scale_fill_brewer(palette = "Set2") +
    labs(
      title = "PART 2: MAE (Uncensored Athletes Only) - Calibrated",
      subtitle = "Time-to-peak prediction error after GAM calibration | Lower = better",
      x = "Event Family", y = "MAE (years)", fill = "Model"
    ) +
    theme_minimal() +
    theme(axis.text.x = element_text(angle = 45, hjust = 1),
          legend.position = "bottom", plot.title = element_text(face = "bold"))
  
  # Combine all 4 plots
  library(gridExtra)
  grid.arrange(p1, p2, p3, p4, nrow = 4)
} else {
  # Only hazard-based plots if no time predictions available
  library(gridExtra)
  grid.arrange(p1, p2, nrow = 2)
}

} # end if(nrow(test_performance) > 0)
```

## Best Model by Metric

```{r best-models}
cat("\n=== BEST PERFORMING MODELS BY METRIC ===\n\n")

if(nrow(test_performance) == 0) {
  cat("No test performance results available.\n")
} else {

# ===== PART 1: Hazard-Based Evaluation (All Athletes) =====
cat("PART 1: HAZARD-BASED EVALUATION (All Athletes)\n")
cat("========================================\n\n")

# Best by C-index (PRIMARY METRIC)
best_cindex <- test_performance %>%
  group_by(event_family) %>%
  slice_max(c_index, n = 1) %>%
  ungroup() %>%
  select(event_family, model, c_index)

cat("Best by C-index (higher = better):\n")
print(best_cindex)

# Best by Spearman correlation
best_spearman <- test_performance %>%
  group_by(event_family) %>%
  slice_max(spearman_rho, n = 1) %>%
  ungroup() %>%
  select(event_family, model, spearman_rho)

cat("\nBest by Spearman Correlation (higher = better):\n")
print(best_spearman)

# ===== PART 2: Time-to-Peak Evaluation (Uncensored Only) =====
if(nrow(calibrated_performance) > 0) {
  cat("\n\nPART 2: TIME-TO-PEAK PREDICTION (Uncensored Athletes Only) - Calibrated\n")
  cat("========================================\n\n")
  
  # Best by RMSE (lower is better)
  best_rmse <- calibrated_performance %>%
    group_by(event_family) %>%
    slice_min(rmse, n = 1) %>%
    ungroup() %>%
    select(event_family, model, rmse)
  
  cat("Best by RMSE (lower = better):\n")
  print(best_rmse)
  
  # Best by MAE (lower is better)
  best_mae <- calibrated_performance %>%
    group_by(event_family) %>%
    slice_min(mae, n = 1) %>%
    ungroup() %>%
    select(event_family, model, mae)
  
  cat("\nBest by MAE (lower = better):\n")
  print(best_mae)
}

# ===== Overall Summary =====
cat("\n\n=== OVERALL MODEL WIN COUNTS ===\n")
cindex_wins <- best_cindex %>% count(model, name = "cindex_wins")
spearman_wins <- best_spearman %>% count(model, name = "spearman_wins")

if(nrow(calibrated_performance) > 0) {
  rmse_wins <- best_rmse %>% count(model, name = "rmse_wins")
  mae_wins <- best_mae %>% count(model, name = "mae_wins")
  
  model_wins <- cindex_wins %>%
    full_join(spearman_wins, by = "model") %>%
    full_join(rmse_wins, by = "model") %>%
    full_join(mae_wins, by = "model") %>%
    replace_na(list(cindex_wins = 0, spearman_wins = 0, rmse_wins = 0, mae_wins = 0)) %>%
    mutate(total_wins = cindex_wins + spearman_wins + rmse_wins + mae_wins) %>%
    arrange(desc(total_wins))
} else {
  model_wins <- cindex_wins %>%
    full_join(spearman_wins, by = "model") %>%
    replace_na(list(cindex_wins = 0, spearman_wins = 0)) %>%
    mutate(total_wins = cindex_wins + spearman_wins) %>%
    arrange(desc(total_wins))
}

cat("\nWins across event families:\n")
print(model_wins)

} # end if(nrow(test_performance) > 0)
```

## Export Test Performance Results

```{r export-test-results}
# Display final test performance tables (no file output)
cat("\n=== FINAL TEST PERFORMANCE TABLES ===\n\n")

if(nrow(test_performance) > 0) {
  cat("Hazard-based test performance:\n")
  print(test_performance)
} else {
  cat("No test performance results available.\n")
}

if(nrow(time_pred_performance) > 0) {
  cat("\nTime-to-peak predictions (uncensored only):\n")
  print(time_pred_performance)
}
```

## Export Individual Test Set Predictions

```{r export-individual-predictions}
cat("\n=== EXPORTING INDIVIDUAL TEST SET PREDICTIONS ===\n\n")

# Collect all individual predictions from test set
all_test_predictions <- data.frame()

for(ef in event_families) {
  cat("Event Family:", ef, "\n")
  
  ho_data <- holdout_results[[ef]]
  test_idx <- ho_data$test_idx
  test_meta <- ho_data$metadata[test_idx, ]
  
  # NOTE: Predictions were already computed in the holdout-evaluation chunk
  # Here we just document that individual predictions are available
  
  cat("  Test set size:", length(test_idx), "athletes\n")
  cat("  Predictions computed for: Cox, RSF, FLCM, AFCM\n\n")
}

cat("Individual risk scores for each test set athlete were computed above\n")
cat("    These risk scores are used to calculate C-index and Spearman rho.\n\n")
```

\newpage

# Step 6: Functional Insights Beyond Prediction

While functional Cox models (FLCM/AFCM) may not dramatically outperform scalar models in predictive metrics like C-index or RMSE, they provide unique scientific insights that scalar models cannot. Specifically, the functional coefficient β(s) from the FLCM reveals which career phases (early, mid, or late) have the strongest impact on the hazard of peaking. This phase-specific information tells us whether performing unusually well at a given point in an athlete's career is associated with earlier or later peak timing—insights that are scientifically relevant but inaccessible to a scalar Cox model that only uses summary statistics like career length and observation count.

## Extract Phase-Specific Functional Coefficients

```{r extract-flcm-beta}
library(dplyr)
library(tidyr)

# Helper to extract beta(s) from one FLCM
extract_flcm_beta <- function(ef) {
  res <- flcm_results[[ef]]
  if (is.null(res)) {
    cat("  Skipping", ef, "- FLCM not fitted\n")
    return(NULL)
  }
  
  fit <- res$model
  time_grid <- res$time_grid
  long_data <- res$data
  
  # CONVENTION A: Prediction grid without L, use actual mean values
  mean_log_n_obs <- mean(long_data$log_n_obs, na.rm = TRUE)
  
  pred_data <- data.frame(
    s = time_grid,
    W = 1,
    career_length = 0,  # At mean (scaled)
    log_n_obs = mean_log_n_obs  # At actual mean from training data
  )
  
  tryCatch({
    pred_terms <- predict(fit, newdata = pred_data, type = "terms", se.fit = TRUE)
    term_names <- colnames(pred_terms$fit)
    smooth_idx <- grep("s\\(s\\)", term_names)
    if (length(smooth_idx) == 0) {
      cat("  Skipping", ef, "- Functional term not found\n")
      return(NULL)
    }
    
    # CONVENTION A: No division by L, model uses by = I(W)
    beta_s <- pred_terms$fit[, smooth_idx]
    
    tibble(
      event_family = ef,
      s = time_grid,
      beta = as.numeric(beta_s)
    )
  }, error = function(e) {
    cat("  Error for", ef, ":", e$message, "\n")
    return(NULL)
  })
}

# Collect beta(s) for all event families
cat("\nExtracting functional coefficients from FLCM models...\n")
beta_all <- lapply(event_families, extract_flcm_beta) %>% 
  bind_rows()

if (nrow(beta_all) == 0) {
  cat("\nNo FLCM coefficients extracted. Check that FLCM models were fitted in Step 3.\n")
} else {
  # Bin career phase into Early / Mid / Late and summarise
  flcm_phase_summary <- beta_all %>%
    mutate(
      phase = cut(
        s,
        breaks = c(0, 1/3, 2/3, 1),
        labels = c("Early", "Mid", "Late"),
        include.lowest = TRUE,
        right = TRUE
      )
    ) %>%
    group_by(event_family, phase) %>%
    summarise(
      mean_beta = mean(beta, na.rm = TRUE),
      mean_abs_beta = mean(abs(beta), na.rm = TRUE),
      .groups = "drop"
    )
  
  cat("\n=== FLCM Phase-Specific Functional Coefficients ===\n\n")
  print(flcm_phase_summary)
}
```

## Visualize Phase-Specific Effects

```{r flcm-phase-heatmap, fig.height=6}
library(ggplot2)
library(viridis)

if (exists("flcm_phase_summary") && nrow(flcm_phase_summary) > 0) {
  flcm_phase_plot_data <- flcm_phase_summary %>%
    mutate(
      direction = case_when(
        mean_beta > 0 ~ "Earlier peak (higher hazard)",
        mean_beta < 0 ~ "Later peak (lower hazard)",
        TRUE ~ "Neutral"
      )
    )
  
  ggplot(flcm_phase_plot_data,
         aes(x = phase, y = event_family, fill = mean_abs_beta)) +
    geom_tile(color = "white") +
    geom_text(
      aes(label = ifelse(mean_beta > 0, "+", ifelse(mean_beta < 0, "-", ""))),
      color = "white", 
      size = 8,
      fontface = "bold"
    ) +
    scale_fill_viridis_c(name = "|β(s)|", option = "C", begin = 0.2, end = 0.9) +
    labs(
      title = "Phase-Specific Impact of Functional Performance on Time to Peak",
      subtitle = "Colour = strength of effect (|β|); symbols: + = earlier peak, - = later peak",
      x = "Career Phase",
      y = "Event Family"
    ) +
    theme_minimal() +
    theme(
      plot.title = element_text(face = "bold", size = 14),
      plot.subtitle = element_text(size = 11),
      axis.text.x = element_text(angle = 0, hjust = 0.5, size = 11),
      axis.text.y = element_text(size = 11),
      legend.position = "right",
      panel.grid = element_blank()
    )
} else {
  cat("No FLCM phase summary data available for plotting.\n")
  cat("Make sure FLCM models were fitted in Step 3.\n")
}
```

## Interpretation

**Phase-Specific Functional Insights:**

- **Bright tiles (large |β|)** indicate career phases where the performance trajectory carries strong information about when the athlete will peak. These are the phases where functional models can extract meaningful predictive signal beyond what scalar summaries provide.

- **Arrows indicate direction of effect:**
  - **↑ (upward arrow)**: Positive β(s) means that performing above one's own typical level during this phase is associated with **earlier peaks** (higher hazard of peaking). Athletes who excel during these phases tend to peak sooner.
  - **↓ (downward arrow)**: Negative β(s) means that performing above one's own typical level during this phase is associated with **later peaks** (lower hazard of peaking). Athletes who excel during these phases tend to peak later.

- **Scientific value of functional modeling**: A purely scalar Cox model (using only career length and log number of observations) **cannot identify which phase of the trajectory matters most** for peak timing. The FLCM, however, reveals phase-specific dynamics that are invisible to scalar models.

- **Main scientific contribution**: This phase-specific insight into career dynamics represents the primary scientific gain from functional modeling in this project. Even when overall predictive performance (C-index, RMSE) is similar between functional and scalar models, the functional models provide interpretable, phase-specific information about **when** in an athlete's career trajectory matters most for peak timing—knowledge that cannot be obtained from summary statistics alone.

---

\newpage

# Final Summary

```{r final-summary}
cat("\n========================================\n")
cat("   COMPLETE ANALYSIS SUMMARY           \n")
cat("   YEARLY SEASON-BEST ANALYSIS (Main)  \n")
cat("   UNIFIED RISK-BASED EVALUATION       \n")
cat("========================================\n\n")

cat("Dataset: fda_data.csv (event-level source)\n")
cat("Main analysis data: yearly season-best (one row per athlete-event-year)\n")
cat("Key difference: result_score used directly (already standardized)\n\n")

cat("STEP 1: Data Preparation - Complete\n")
cat("  - ", nrow(surv_ready), "athlete-event combinations processed\n")
cat("  - ", n_distinct(surv_ready$event_family), "event families\n\n")

cat("STEP 2: Exploratory Analysis - Complete\n")
cat("  - Kaplan-Meier curves by event family\n")
cat("  - Functional predictor visualization\n")
cat("  - Baseline Cox models fitted\n\n")

cat("STEP 3: Functional Models - Complete\n")
cat("  - Cox, RSF, FLCM, AFCM models fitted\n")
cat("  - Coefficient functions visualized\n\n")

cat("STEP 4: In-Sample Sanity Check - Complete\n")
cat("  - C-index computed on training data (optimistic)\n")
cat("  - Confirms all models can fit and predict\n\n")

cat("STEP 5: Hold-Out Test Set Evaluation - Complete\n")
cat("  - 80/20 train-test split\n")
cat("  - TWO-PART EVALUATION:\n\n")

cat("=== PART 1: HAZARD-BASED EVALUATION (All Athletes) ===\n")
cat("  - All models output UNIFIED RISK SCORES (higher = earlier peak)\n")
cat("  - C-index: Primary metric (discrimination)\n")
cat("  - Spearman rho: Secondary metric (rank correlation)\n\n")

cat("=== PART 2: TIME-TO-PEAK PREDICTION (Uncensored Only) ===\n")
cat("  - All models compute individual survival curves S_i(t)\n")
cat("  - Median survival time extracted as predicted time-to-peak\n")
cat("  - RMSE/MAE evaluated ONLY on uncensored (retired) athletes\n")
cat("  - This ensures we only evaluate on athletes with known true peak\n\n")

cat("=== METHODOLOGICAL FRAMEWORK ===\n\n")

cat("Censoring Logic (Data-Driven Cutoff):\n")
cat("  - Cutoff = max(data year) - 1\n")
cat("  - Athletes competing at/after cutoff = CENSORED (still active)\n")
cat("  - Athletes last seen before cutoff = UNCENSORED (retired, peak known)\n\n")

cat("Time-to-Peak Extraction:\n")
cat("  - Cox: basehaz() + S_i(t) = exp(-H0 * exp(lp))\n")
cat("  - RSF: $survival matrix directly\n")
cat("  - FLCM/AFCM: coxph(Surv ~ offset(eta)) for baseline hazard\n")
cat("  - All models: get_median_time(times, S_i)\n\n")

cat("=== METHODOLOGICAL IMPROVEMENTS ===\n\n")

cat("  1. Proper censoring: data-driven cutoff for active vs retired athletes\n")
cat("  2. Athlete-level standardization: Preserves curve shape & patterns\n")
cat("  3. Pre-smoothing: smooth.spline with df=8 reduces noise\n")
cat("  4. Fair comparison: FLCM/AFCM include ALL covariates\n")
cat("  5. Increased spline basis: k=10 for improved flexibility\n")
cat("  6. Proper test scaling: Uses training statistics (no data leakage)\n\n")

cat("Key Findings:\n")
cat("  - All 4 models now compared using TWO evaluation approaches:\n")
cat("    1. Hazard scores (C-index/Spearman) on ALL athletes\n")
cat("    2. Time predictions (RMSE/MAE) on UNCENSORED athletes only\n")
cat("  - Yearly season-best curves capture robust career progression signal\n")
cat("  - Curve shape matters: athlete-level patterns predict peak timing\n")
cat("  - Censoring essential for unbiased survival analysis\n\n")

cat("Deliverables:\n")
cat("  1. Hazard-based evaluation (C-index + Spearman) displayed in report\n")
cat("  2. Time prediction (RMSE + MAE) displayed in report\n")
cat("  3. PDF/HTML report with all visualizations\n")
cat("  4. Comprehensive model comparison on both statistical and interpretable scales\n\n")

cat("Future Work:\n")
cat("  - Add FPCA scores as functional features\n")
cat("  - Event-specific curve preprocessing\n")
cat("  - Mixed-effects functional models\n")
cat("  - External validation on new data\n\n")

cat("Analysis complete with TWO-PART evaluation framework!\n")
```

# Export All Results for Manuscript

```{r export-all-results, eval=FALSE}
cat("
===============================================
")
cat("EXPORTING ALL TABLES AND FIGURES FOR MANUSCRIPT
")
cat("===============================================

")

# ============================================================
# EXPORT KEY PERFORMANCE TABLES
# ============================================================

cat("Exporting performance tables...
")

# Table 1: Test Performance (Hazard-based)
if (exists("test_performance") && nrow(test_performance) > 0) {
  export_table(test_performance, 
               "table1_test_performance_hazard",
               "Test Set Performance: C-index and Spearman Correlation")
}

# Table 2: Time Prediction Performance (Uncalibrated)
if (exists("time_pred_performance") && nrow(time_pred_performance) > 0) {
  export_table(time_pred_performance, 
               "table2_time_prediction_uncalibrated",
               "Time-to-Peak Prediction: RMSE and MAE (Uncalibrated)")
}

# Table 3: Calibrated Performance
if (exists("calibrated_performance") && nrow(calibrated_performance) > 0) {
  export_table(calibrated_performance, 
               "table3_calibrated_performance",
               "Time-to-Peak Prediction: RMSE and MAE (Calibrated)")
}

# Table 4: Calibrated Summary (Mean by Model) - WITH BASELINE
if (exists("calibrated_summary_with_improvement") && nrow(calibrated_summary_with_improvement) > 0) {
  # Format the table nicely with column names
  table4_formatted <- calibrated_summary_with_improvement %>%
    mutate(
      Model = model,
      `RMSE (years)` = round(mean_rmse, 3),
      `MAE (years)` = round(mean_mae, 3),
      `Improvement (%)` = ifelse(is.na(improvement_pct), "—", as.character(improvement_pct))
    ) %>%
    select(Model, `RMSE (years)`, `MAE (years)`, `Improvement (%)`)
  
  export_table(table4_formatted, 
               "table4_calibrated_summary",
               "Mean Calibrated Performance by Model (vs. Naive Baseline)")
}

# Table 5: Survival Dataset Summary
if (exists("surv_ready")) {
  surv_summary <- surv_ready %>%
    group_by(event_family) %>%
    summarise(
      n_athletes = n(),
      n_censored = sum(event_status == 0),
      n_uncensored = sum(event_status == 1),
      pct_censored = 100 * mean(event_status == 0),
      mean_career_length = mean(last_year - first_year, na.rm = TRUE),
      .groups = "drop"
    )
  export_table(surv_summary, 
               "table5_survival_summary",
               "Survival Dataset Summary by Event Family")
}

cat("
")

# ============================================================
# RE-GENERATE AND EXPORT KEY FIGURES
# ============================================================

cat("Exporting key figures...

")

# Figure 1: Career length and time-to-peak distributions
if (exists("career_summary")) {
  p1 <- ggplot(career_summary, aes(x = career_length)) +
    geom_histogram(binwidth = 1, fill = "steelblue", alpha = 0.7) +
    labs(title = "Distribution of Career Lengths",
         x = "Career Length (years)", y = "Count") +
    theme_minimal(base_size = 12)
  export_plot("fig1_career_length_distribution", p1, width = 8, height = 5)
  
  p2 <- ggplot(career_summary, aes(x = time_to_peak)) +
    geom_histogram(binwidth = 1, fill = "coral", alpha = 0.7) +
    labs(title = "Distribution of Time to Peak Performance",
         x = "Years to Peak", y = "Count") +
    theme_minimal(base_size = 12)
  export_plot("fig2_time_to_peak_distribution", p2, width = 8, height = 5)
}

# Figure 2: Censoring breakdown
if (exists("surv_ready")) {
  p_censor <- surv_ready %>%
    group_by(event_family) %>%
    summarise(
      censored = sum(event_status == 0),
      uncensored = sum(event_status == 1),
      .groups = "drop"
    ) %>%
    pivot_longer(cols = c(censored, uncensored), 
                 names_to = "status", values_to = "count") %>%
    ggplot(aes(x = event_family, y = count, fill = status)) +
    geom_bar(stat = "identity", position = "dodge") +
    labs(title = "Censoring Status by Event Family",
         x = "Event Family", y = "Count",
         fill = "Status") +
    theme_minimal(base_size = 12) +
    theme(axis.text.x = element_text(angle = 45, hjust = 1))
  export_plot("fig3_censoring_by_event", p_censor, width = 10, height = 6)
}

# Figure 3: Model comparison (C-index)
if (exists("test_performance") && nrow(test_performance) > 0) {
  p_cindex <- test_performance %>%
    ggplot(aes(x = reorder(model, c_index), y = c_index, fill = model)) +
    geom_boxplot(alpha = 0.7) +
    geom_jitter(width = 0.2, alpha = 0.5) +
    coord_flip() +
    labs(title = "Model Comparison: C-index on Test Set",
         x = "Model", y = "C-index",
         caption = "Higher is better") +
    theme_minimal(base_size = 12) +
    guides(fill = "none")
  export_plot("fig4_model_comparison_cindex", p_cindex, width = 8, height = 5)
}

# Figure 4: Calibrated RMSE comparison
if (exists("calibrated_performance") && nrow(calibrated_performance) > 0) {
  p_rmse <- calibrated_performance %>%
    ggplot(aes(x = reorder(model, rmse), y = rmse, fill = model)) +
    geom_boxplot(alpha = 0.7) +
    geom_jitter(width = 0.2, alpha = 0.5) +
    coord_flip() +
    labs(title = "Model Comparison: Calibrated RMSE",
         x = "Model", y = "RMSE (years)",
         caption = "Lower is better | Evaluated on uncensored athletes only") +
    theme_minimal(base_size = 12) +
    guides(fill = "none")
  export_plot("fig5_calibrated_rmse_comparison", p_rmse, width = 8, height = 5)
}

cat("
===============================================
")
cat("EXPORT COMPLETE!
")
cat("===============================================

")
cat("All results saved to output/ folder:
")
cat("  - output/images/  (all plots and figures as PDF)
")
cat("  - output/tables/  (all tables as PDF)

")
cat("PDF format = vector graphics (perfect for papers!)
")
cat("Infinite zoom without quality loss
")
cat("Smaller file sizes
")
cat("Professional publication quality
")
```

